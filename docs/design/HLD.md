# Esper-Lite Architecture High-Level Design

Esper-Lite is a streamlined version of the full Esper morphogenetic system, focusing on the minimum set of subsystems needed for core functionality. In the full Esper architecture, there are twelve subsystems organized into three functional planes [Training, Control, and Innovation][1](2). Esper-Lite narrows this scope to seven key components: Tolaria, Kasmina, Tamiyo, Simic, Urza, Tezzeret, and Karn, and relies on three shared servicesâ€”Leyline, Oona, and Nissaâ€”for contracts, messaging, and observability. These subsystems and their interactions form the essential loop for on-the-fly model adaptation and learning. Below, we outline each componentâ€™s role and then describe the main interaction flow in Esper-Lite.

> **Runtime baseline:** All Esper-Lite training and compilation components target **PyTorch 2.8** (torch 2.8.x) as the supported framework version.

## Core Components and Their Roles

### ðŸŽ¯ Training & Execution Layer (Core Training Loop)

- **Tolaria (Training Orchestrator):** The master training loop controller responsible for running the modelâ€™s training epochs and maintaining the overall system heartbeat[3]. Tolaria coordinates with Tamiyo at defined points (e.g. epoch boundaries) to allow strategic decisions, ensuring zero-disruption to the training process. It calls Tamiyo at each epoch boundary (tamiyo.step() interface) to obtain any adaptation signals and then continues training accordingly[4]. Tolaria and Kasmina are tightly integrated for performance, as Kasminaâ€™s modules are embedded in the training loop for direct, low-latency execution[5][6].
- **Kasmina (Execution Layer Controller):** Kasmina manages the seed lifecycle and executes model modifications (kernel insertions) within the training loop. It serves as the kernel runtime engine that actually applies architectural changes decided by Tamiyo[3]. In practice, Kasmina wraps around parts of the model (implemented as special layers or â€œKasminaLayersâ€) and can load new kernel modules into the model on the fly (a process sometimes called â€œgerminationâ€ of a seed). Kasmina also collects and publishes seed telemetry (health and performance metrics of the injected modules) back to Tamiyo over the messaging fabric, so Tamiyo can assess the results of adaptations[7][8]. Importantly, Kasmina does not make independent decisions â€“ it executes strategic commands from Tamiyo and handles the mechanics of applying them (and ensuring the modelâ€™s integrity during those changes).

### ðŸ§  Strategic Control Layer (Decision Making & Learning)

- **Tamiyo (Strategic Controller & Telemetry Hub):** Tamiyo is the intelligent decision-making engine of Esper-Lite. It analyzes telemetry and state snapshots from Tolaria and Kasmina and decides if and how to adapt the modelâ€™s architecture. Tamiyoâ€™s policy (often a graph neural network policy) takes the SystemState (e.g. performance metrics, seed statuses) as input and outputs an Adaptation Command or â€œgermination direction.â€ In essence, Tamiyo decides when and where a new module (blueprint) should be injected to improve learning, acting as the brain of the control plane. It maintains safety checks and risk assessments so that any adaptation wonâ€™t destabilize training. In Esper-Lite, Tamiyo focuses on utilizing a fixed repertoire of blueprint options (no dynamic blueprint design on its own). Tamiyo sends its decisions to Kasmina in the form of commands, and it relies on Kasmina to carry out the actual changes in the model[9]. Tamiyo also owns the telemetry aggregation role for Esper-Lite and generates field reports describing the outcome of each adaptation (e.g. success or failure, performance impact), which are later used for learning in Simic.
- **Simic (Policy Trainer):** Simic is the offline training subsystem that improves Tamiyoâ€™s decision policy over time using conventional machine learning. Simic does not participate in real-time control; instead, it runs in parallel (on separate resources) to train and refine Tamiyoâ€™s models using data collected from actual training runs. Simic primarily consumes the field reports emitted by Tamiyo â€“ essentially the history of what decisions were made and how they affected training â€“ and performs experience replay and reinforcement learning to produce better policies[10][11]. This training is done with standard techniques (e.g. RL with IMPALA, policy gradient methods, possibly imitation learning), and often uses LoRA (Low-Rank Adaptation) fine-tuning to efficiently adjust Tamiyoâ€™s neural network without needing full retraining[12]. Crucially, Simicâ€™s work is offline and non-disruptive â€“ Tamiyoâ€™s policy updates are prepared in Simic and only deployed to Tamiyo between training sessions or when safe, ensuring that the live training loop in Tolaria is never paused for policy improvement[13][14]. Over time, this means Tamiyo becomes smarter at making adaptation decisions by learning from past experience, closing the loop where better decisions lead to better models.

### ðŸ”¬ Blueprint Management Layer (Innovation & Model Assets)

- **Urza (Central Library):** Urza is the central repository for all architectural assets â€“ it stores both the abstract blueprints (designs for new model components) and the compiled, ready-to-use model modules (kernels). In Esper-Lite, Urza holds a set of pre-defined blueprints that represent a range of capabilities Kasmina can inject (for example, a convolutional layer blueprint, a normalization module blueprint, an attention head blueprint, etc.). Each blueprint is an abstract design (often called a BlueprintIR) which, once compiled into an actual model component, becomes a Kernel Artifact. Urza provides query and retrieval APIs so that other subsystems can request these artifacts by name or ID[15][16]. During operation, Kasmina contacts Urza whenever it needs to load a specific kernel (blueprint instance) that Tamiyo has requested. Urza returns the compiled kernel artifact (e.g. a PyTorch module or serialized model bytes) which Kasmina then inserts into the main model[17][9]. By centralizing all designs and binaries, Urza ensures there is a single source of truth for what blueprints are available and tracks their versions and validation status.
- **Tezzeret (Compilation Engine):** Tezzeret is the asynchronous compilation forge that turns blueprint designs into executable model components. In the full system, Tezzeret continuously polls Urza for any new or uncompiled BlueprintIRs, then runs optimization passes and builds them into optimized neural network modules [kernels][18](19). In Esper-Lite, since we are using only a fixed set of pre-defined blueprints, Tezzeretâ€™s role is primarily to compile those at initialization or on system startup. Essentially, Tezzeret takes each blueprint design (defined by Karn or by configuration) and generates a compiled kernel â€“ complete with optimized weights initialization or any low-level optimizations â€“ and then registers this artifact back into Urzaâ€™s library for use[19]. This process happens in the background or before training begins, ensuring that whenever Tamiyo requests a certain blueprint, a ready-to-use module is immediately available (thus upholding the principle of zero training disruption). If Esper-Lite were extended later, Tezzeret would also handle compiling any new blueprints introduced at runtime. By performing heavy compilation tasks asynchronously, Tezzeret frees the training loop from overhead.
- **Karn (Static Blueprint Service):** Karn is the architect responsible for curating Esper-Liteâ€™s static blueprint library. Unlike the full Esper system, Karn does not generate new architectures on the fly; instead it exposes a runtime service that answers blueprint queries with one of 50 pre-approved templates grouped by safety tier[15][20]. These templates cover the adaptation strategies Tamiyo can deploy, and every request flows through Karnâ€™s circuit breakers and conservative-mode safeguards before metadata is handed back to Urza and Kasmina. Including Karn preserves the expansion path toward future dynamic blueprint design while providing a governed source of kernels today.

### ðŸ”§ Infrastructure Services (Contracts, Messaging, Observability)

> **Reference note:** Detailed legacy specifications for each subsystem remain available under `docs/design/detailed_design/old/`. Those documents capture the full lifecycle state machines and validation gates that continue to govern the Esper-Lite implementation.

- **Leyline (Shared Contracts):** Leyline distributes the Protocol Buffer schemas, enums, and performance budgets that every subsystem uses for control, telemetry, and learning feedback. Strict version gating ensures Tolariaâ€™s `SystemStatePacket`, Tamiyoâ€™s `AdaptationCommand`, Kasminaâ€™s telemetry, and Simicâ€™s `FieldReport` messages serialize in <80â€¯Âµs and remain binary compatible across releases (`docs/design/detailed_design/00-leyline.md`).
- **Oona (Message Bus):** Oona provides an at-least-once Redis Streams message fabric for Esper-Lite. It carries Leyline `EventEnvelope` payloads between producers (e.g., Tolaria checkpoints, Tamiyo field reports, Kasmina alerts) and consumers (Tamiyo, Simic, Nissa), enforces priority routing for emergency traffic, and exposes breaker-guarded health metrics (`docs/design/detailed_design/09-oona.md`).
- **Nissa (Observability Stack):** Nissa ingests Leyline `TelemetryPacket`s from Oona, stores metrics in Prometheus/Elasticsearch, evaluates lightweight alert/SLO rules, and offers a mission-control API for operators. It is the systemâ€™s window into queue depth, breaker states, and safety posture across subsystems (`docs/design/detailed_design/10-nissa.md`).

## Main Interaction Flow in Esper-Lite

The key runtime loop of Esper-Lite involves Tamiyo making decisions and Kasmina executing them within the training process, while the blueprint system supplies the necessary model components and Simic improves the decision policy over time. Below is a step-by-step overview of this Esper-Lite control loop:

1. Monitoring & Decision Trigger: As Tolaria runs the training, it reaches synchronization points (e.g. end of an epoch or a scheduled interval) where it gathers the current system state (metrics, seed statuses, etc.). Tolaria provides this state to Tamiyo (either by direct method call at an epoch boundary, or via a telemetry message) to allow Tamiyo to analyze the training progress[6][8]. Kasmina also sends real-time telemetry (e.g. health of inserted modules, performance indicators) that Tamiyo consumes through the Oona bus to build a unified view of the system state[21][22]. All payloads use Leyline contracts to guarantee consistent serialization and bounded latencies.
2. Strategic Analysis by Tamiyo: Tamiyo evaluates the incoming data to decide if an architectural adaptation is warranted. It uses its current policy (which may consider factors like gradient signals, loss stagnation, or other heuristic triggers) to determine what blueprint (if any) should be injected, and at which seed (which part of the network) to improve learning. For example, Tamiyo might decide â€œthe loss plateaus on this segment; insert a new convolutional kernel (Blueprint X) at seed #5 to increase capacity.â€ Tamiyo formulates this as an Adaptation Command (often called a germination instruction) which includes the target seed location and the identifier of the blueprint to use.
3. Tamiyo Commands Kasmina: Tamiyo sends the adaptation/germination command to Kasmina, specifying which blueprint to apply and where. Tamiyo is effectively delegating execution of the plan to Kasmina[9]. This happens immediately and synchronously within the training loop coordination (not via a long round-trip through a database or such, to keep latency low). For instance, Tamiyo might call a method on Kasmina like kasmina_layer.germinate(seed_id, blueprint_id). At this moment, Tamiyoâ€™s role in the loop is done â€“ it will wait to observe the results in the next cycle.
4. Blueprint Retrieval from Urza: Upon receiving the command, Kasmina needs to load the requested blueprintâ€™s kernel so it can be integrated. Kasmina contacts Urza (the library) to fetch the compiled kernel artifact corresponding to the blueprint ID Tamiyo requested[17][9]. Because Esper-Lite uses predefined blueprints, we assume the requested component is already compiled and stored. (If not already in memory, Urza will retrieve the artifact from its store, potentially cached from Tezzeretâ€™s prior compilation.) This request is typically done through an API call or message (e.g., Kasmina uses an Urza client to get the kernel by ID). Urza returns the ready-to-use module (for example, a PyTorch nn.Module object or a serialized file that Kasmina can load).
5. Kernel Injection (Germination): Kasmina receives the compiled kernel from Urza and proceeds to inject it into the live training model at the specified seed location. This might involve replacing a placeholder layer or attaching a new branch to the model graph. Thanks to the design of seeds, this insertion respects the interface contracts (input/output dimensions) and uses gradient isolation techniques so as not to corrupt ongoing training[23][24]. Kasmina initializes the new module (the kernel) within Tolariaâ€™s model and begins integrating it. This process is often called â€œgerminationâ€ â€“ the seed (a slot for potential growth) is now germinated into an actual functional subnetwork using the blueprint. Once inserted, training can immediately continue on the updated model. Tolaria seamlessly continues the next training iteration or epoch with the model that now includes the new component. Through this non-blocking injection, morphogenetic evolution of the network happens concurrently with training, fulfilling the zero-disruption principle.
6. Telemetry & Field Reporting: As training proceeds with the newly adapted model, Kasmina monitors the performance of the new kernel and the overall training metrics. It sends telemetry reports (e.g. the kernelâ€™s contribution, any anomalies) which Tamiyo collects to evaluate the impact of the adaptation[21][7]. Tamiyo assesses whether the injection was beneficial or if any corrective action is needed in future. Tamiyo compiles a field report for this adaptation attempt â€“ essentially a summary of the outcome (e.g. â€œBlueprint X at seed #5 improved validation accuracy by Y% over Z epochsâ€ or â€œBlueprint injection failed to improve, rolled back after 3 epochsâ€). This field report is sent to the Simic subsystem for offline learning, and the same telemetry stream feeds Nissaâ€™s dashboards and alerting so operators can track system health. The loop then repeats: Tolaria will again allow Tamiyo to make decisions at the next interval, and Tamiyo will use the latest information to possibly issue further adaptation commands.
7. Offline Policy Training (Simicâ€™s Loop): Meanwhile, Simic continuously operates on a separate track to improve Tamiyoâ€™s decision-making policy using the data from past adaptations. Simic ingests the field reports from Tamiyo (and potentially raw telemetry logs from Tolaria/Kasmina) which serve as the experience data for learning[10][25]. It uses reinforcement learning (and other ML techniques) to train Tamiyoâ€™s policy network on these experiences â€“ essentially trying to make Tamiyo better at achieving positive outcomes and avoiding negative ones. Importantly, this training is offline: Simic might be running epochs of policy gradient updates on Tamiyoâ€™s neural network (or a copy of it) using a replay buffer of field reports. Techniques like IMPALA (for distributed RL) and LoRA (for efficient fine-tuning of the large policy network) are applied to squeeze more performance out of Tamiyoâ€™s strategy[12][13]. Over time (e.g. after a certain number of field reports or training hours in Simic), a new policy checkpoint is produced. This updated Tamiyo policy is then validated and can be deployed back to the Tamiyo component in production. When Tamiyo updates its policy (for example, loading new weights or a LoRA adapter), it can make smarter or more nuanced decisions in subsequent iterations of the loop. All of this occurs without pausing the main training â€“ the new policy is swapped in only at safe points (much like a coach learning from past games and giving the player a new strategy between matches). The result is a continuously improving feedback cycle: Tamiyoâ€™s decisions lead to model changes and outcomes, which then train Tamiyo to make better decisions.
8. (No Dynamic Blueprint Generation in Lite): One notable omission in Esper-Liteâ€™s flow is the generative blueprint design step. In the full Esper system, a component (Karn) would eventually propose brand new blueprint ideas (via neural architecture search or generative algorithms), kicking off an asynchronous pipeline of design->compile->validate [handled by Karn, Tezzeret, Urza, Urabrask, etc.][20](18). In Esper-Lite, this is not active. All blueprints used are from a predefined set available in Urzaâ€™s library. This means Tamiyoâ€™s choices are constrained to known blueprint options, and Tezzeretâ€™s compilation happens mostly upfront (or only for that fixed set). This simplification avoids the complexity of continuously generating and validating new architectures, and lets the system focus on using the existing blueprints effectively (a Phase 1 goal). Once Tamiyo demonstrates proficiency in deploying the predefined blueprints, dynamic blueprint generation can be introduced as a Phase 2 enhancement. In the current loop, the absence of new blueprint generation and Urabraskâ€™s validation implies that the innovation plane is largely static during operation â€“ a trade-off that reduces risk and complexity for this minimal viable system.

By integrating these components in the loop described above, Esper-Lite achieves a foundational form of morphogenetic AI training: the model can evolve during training under the guidance of an intelligent controller (Tamiyo), using a library of building-block improvements (blueprints), without interrupting training. Kasmina and Tolaria ensure those changes happen safely in real-time, while Simic ensures the controller itself keeps learning to make better choices. Even without the full roster of twelve subsystems, this pared-down architecture retains the essential capability of continuous self-optimization that defines the Esper platform. Each piece plays a critical part in this synergy: Tamiyo as the brain, Kasmina+Tolaria as the body executing changes, Urza+Tezzeret (and Karnâ€™s designs) as the toolbox of new parts, and Simic as the coach that refines the strategy. Together, these enable Esper-Lite to adapt and improve a neural network on the fly â€“ achieving the core promise of adaptive, resilient AI model training.

## References

- Esper High-Level Design Documents â€“ Reference Architecture Overview[1][2][20] and Service Boundary ADR [Tolaria-Kasmina-Tamiyo][9](17)
- Esper Component Design Specs â€“ Tamiyo Unified Design, Kasmina Execution Layer design, Simic Unified Design [offline policy trainer][10](13)
- Esper R&D Pipeline â€“ Blueprint & Kernel separation and pipeline[18][19] (Karn/Tezzeret/Urza roles in design vs execution)
- C-016 External Review Fixes â€“ Ensuring zero-disruption training and safety [integrated in Tamiyo v4.1 and Simic v3.0][26](14) (context for reliability and non-interference of control loops)
