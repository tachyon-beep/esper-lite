# Tolaria - Rollback Systems and Emergency Procedures

**Parent Document**: [01-tolaria-unified-design.md](01-tolaria-unified-design.md)  
**Component Type**: Emergency Recovery and State Management  
**Version**: 3.0 (Split from v2.2)  
**Date**: 2025-01-10

## Overview

This document details Tolaria's comprehensive rollback and emergency recovery systems. The implementation features a two-tier rollback architecture (500ms fast path, 12s full recovery) with distributed coordination protocols and Write-Ahead Logging for checkpoint atomicity. These systems ensure the morphogenetic platform can recover from any failure condition while maintaining state consistency.

## Two-Tier Rollback System

### Fast Rollback System (500ms)

**[C-016 FIX] Enhanced with memory leak prevention:**

```python
class FastRollbackCoordinator:
    """
    Fast rollback for control plane emergencies.
    Operates on in-memory checkpoints with 500ms total budget.
    """
    
    def __init__(self):
        # Fast rollback configuration
        self.prepare_timeout_ms = 150   # Phase 1: Gather participants
        self.commit_timeout_ms = 250    # Phase 2: Execute rollback
        self.confirm_timeout_ms = 100   # Phase 3: Verify completion
        
        # [C-016 FIX] Enhanced memory management
        self.checkpoint_cache = {}
        self.cache_max_size = 5  # Keep last 5 checkpoints in memory
        
        # [C-016 FIX] Garbage collection for cache management
        self.cache_access_times = {}  # Track LRU for eviction
        self.gc_interval_seconds = 300  # Clean up every 5 minutes
        self.last_gc_time = time.time()
        
        # Shared memory for emergency signaling
        self.emergency_signal = SharedMemorySignal('esper_emergency_fast')
    
    async def initiate_fast_rollback(self, 
                                    checkpoint_epoch: int,
                                    reason: str) -> bool:
        """Execute fast rollback within 500ms budget"""
        
        start_time = time.perf_counter()
        participants = ['tolaria', 'kasmina', 'tamiyo']
        
        try:
            # [C-016 FIX] Garbage collect before operation to prevent memory bloat
            self._gc_checkpoint_cache_if_needed()
            
            # Phase 1: PREPARE (150ms)
            prepare_success = await self._prepare_phase(
                checkpoint_epoch, participants, self.prepare_timeout_ms
            )
            if not prepare_success:
                return False
            
            # Phase 2: COMMIT (250ms) 
            commit_success = await self._commit_phase(
                checkpoint_epoch, participants, self.commit_timeout_ms
            )
            if not commit_success:
                await self._abort_rollback(participants)
                return False
            
            # Phase 3: CONFIRM (100ms)
            confirm_success = await self._confirm_phase(
                participants, self.confirm_timeout_ms
            )
            
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            
            # [C-016 FIX] Circuit breaker validation instead of assert
            if elapsed_ms > 500.0:
                self._trigger_conservative_mode(
                    f"Fast rollback exceeded budget: {elapsed_ms:.2f}ms > 500ms"
                )
            
            # Log performance metrics
            self.telemetry_collector.collect_telemetry(
                priority=TelemetryPriority.EMERGENCY,
                source='tolaria_fast_rollback',
                event_type='fast_rollback_complete',
                payload={
                    'success': confirm_success,
                    'elapsed_ms': elapsed_ms,
                    'budget_ms': 500,
                    'reason': reason,
                    'participants': len(participants)
                }
            )
            
            return confirm_success
            
        except Exception as e:
            # Emergency fallback to full rollback
            logger.error(f"Fast rollback failed: {e}, escalating to full rollback")
            return await self.full_rollback_coordinator.initiate_rollback(
                checkpoint_epoch, f"Fast rollback failed: {reason}"
            )
```

### Memory Management and Garbage Collection

**[C-016 FIX] LRU cache eviction to prevent memory leaks:**

```python
def _gc_checkpoint_cache_if_needed(self):
    """Garbage collect cache to prevent memory leaks"""
    current_time = time.time()
    
    # Run GC if interval has passed
    if current_time - self.last_gc_time > self.gc_interval_seconds:
        self._gc_checkpoint_cache()
        self.last_gc_time = current_time
        
    # Emergency GC if cache is too large
    if len(self.checkpoint_cache) > self.cache_max_size * 2:
        self._gc_checkpoint_cache()

def _gc_checkpoint_cache(self):
    """LRU eviction of checkpoint cache"""
    if len(self.checkpoint_cache) <= self.cache_max_size:
        return
        
    # Sort by access time (LRU first)
    sorted_checkpoints = sorted(
        self.cache_access_times.items(),
        key=lambda x: x[1]
    )
    
    # Remove oldest entries beyond max size
    to_remove = len(self.checkpoint_cache) - self.cache_max_size
    for i in range(to_remove):
        checkpoint_epoch = sorted_checkpoints[i][0]
        if checkpoint_epoch in self.checkpoint_cache:
            del self.checkpoint_cache[checkpoint_epoch]
            del self.cache_access_times[checkpoint_epoch]
            
    logging.info(f"GC removed {to_remove} cached checkpoints")
```

## Four-Level Emergency Protocol

### Emergency Response Levels

```python
class EmergencyProtocolHandler:
    """
    Four-level emergency protocol implementation.
    CRITICAL(100ms) -> SEVERE(500ms) -> MAJOR(2s) -> MINOR(5s)
    """
    
    EMERGENCY_LEVELS = {
        'CRITICAL': {
            'response_time_ms': 100,
            'actions': ['freeze_training', 'signal_all_subsystems'],
            'coordination': 'shared_memory',  # Bypass message bus
            'rollback': False
        },
        'SEVERE': {
            'response_time_ms': 500, 
            'actions': ['fast_rollback', 'alert_operators'],
            'coordination': 'fast_path',
            'rollback': True,
            'rollback_type': 'fast'
        },
        'MAJOR': {
            'response_time_ms': 2000,
            'actions': ['full_rollback', 'checkpoint_save'],
            'coordination': 'message_bus',
            'rollback': True,
            'rollback_type': 'full'
        },
        'MINOR': {
            'response_time_ms': 5000,
            'actions': ['log_incident', 'adjust_parameters'],
            'coordination': 'standard',
            'rollback': False
        }
    }
```

### Critical Fast Path (100ms)

```python
async def _critical_fast_path(self, source: str, details: dict, deadline: float):
    """Ultra-fast response for critical emergencies (100ms budget)"""
    
    # Shared memory signaling for <1ms coordination
    freeze_msg = EmergencyMessage(
        level='CRITICAL',
        action='FREEZE',
        source=source,
        timestamp_ns=time.time_ns()
    )
    
    # Bypass message bus - use shared memory
    self.emergency_signal.broadcast_critical(freeze_msg)
    
    # Wait for acknowledgments (max 90ms)
    acks = await self._collect_fast_acks(
        timeout_ms=90,
        required=['tolaria', 'kasmina', 'tamiyo']
    )
    
    return {
        'action': 'FREEZE',
        'acks': acks,
        'time_ms': (time.time() - deadline + 0.1) * 1000
    }
```

## Distributed Rollback Coordination

### Three-Phase Protocol Implementation

```python
class DistributedRollbackCoordinator:
    """
    Coordinates distributed rollback across Tolaria, Kasmina, and Tamiyo.
    Ensures atomic state restoration with proper ordering and verification.
    """
    
    def __init__(self, subsystem_id: str, oona_bus, checkpoint_manager):
        self.subsystem_id = subsystem_id
        self.oona_bus = oona_bus
        self.checkpoint_manager = checkpoint_manager
        
        # Participating subsystems
        self.core_subsystems = {"tolaria", "kasmina", "tamiyo"}
        self.auxiliary_subsystems = {"simic", "emrakul", "nissa"}
        self.all_subsystems = self.core_subsystems | self.auxiliary_subsystems
        
        # Timing parameters per consensus
        self.prepare_timeout_ms = 2000  # 2 seconds for prepare phase
        self.commit_timeout_ms = 5000   # 5 seconds for commit phase  
        self.heartbeat_interval_ms = 500  # 500ms heartbeat during rollback
        self.quorum_threshold = 0.66  # 2/3 majority required
        
        # Rollback state tracking
        self.active_rollback: Optional[RollbackRequest] = None
        self.rollback_votes: Dict[str, RollbackVote] = {}
        self.subsystem_states: Dict[str, SubsystemState] = {
            s: SubsystemState.ACTIVE for s in self.all_subsystems
        }
    
    async def initiate_rollback(self, 
                               checkpoint_epoch: int,
                               reason: str,
                               severity: str = "HIGH") -> bool:
        """
        Initiate distributed rollback protocol.
        Returns True if rollback succeeded, False otherwise.
        """
        
        # Generate unique rollback ID
        rollback_id = self._generate_rollback_id(checkpoint_epoch, reason)
        
        # Get checkpoint hash for validation
        checkpoint = await self.checkpoint_manager.get_checkpoint(checkpoint_epoch)
        if not checkpoint:
            raise ValueError(f"Checkpoint {checkpoint_epoch} not available")
        
        checkpoint_hash = self._calculate_checkpoint_hash(checkpoint)
        
        # Create rollback request
        self.active_rollback = RollbackRequest(
            rollback_id=rollback_id,
            initiator=self.subsystem_id,
            checkpoint_epoch=checkpoint_epoch,
            checkpoint_hash=checkpoint_hash,
            reason=reason,
            severity=severity,
            timestamp=datetime.utcnow(),
            affected_subsystems=self.core_subsystems.copy(),
            recovery_deadline=datetime.utcnow() + timedelta(seconds=30)
        )
        
        # Execute three-phase protocol
        try:
            # Phase 1: PREPARE (2s timeout)
            prepare_success = await self._prepare_phase()
            if not prepare_success:
                await self._abort_rollback("Prepare phase failed - no quorum")
                return False
            
            # Phase 2: COMMIT (5s timeout)
            commit_success = await self._commit_phase()
            if not commit_success:
                await self._abort_rollback("Commit phase failed")
                return False
            
            # Phase 3: COMPLETE
            await self._complete_phase()
            return True
            
        except Exception as e:
            await self._abort_rollback(f"Rollback failed: {str(e)}")
            return False
```

### Deterministic Rollback Order

```python
def _determine_rollback_order(self) -> List[str]:
    """
    Determine deterministic rollback order to prevent inconsistencies.
    Order: Tamiyo (controller) -> Kasmina (execution) -> Tolaria (orchestrator) -> Others
    """
    order = []
    
    # Fixed order for core subsystems
    if "tamiyo" in self.active_rollback.affected_subsystems:
        order.append("tamiyo")
    if "kasmina" in self.active_rollback.affected_subsystems:
        order.append("kasmina")
    if "tolaria" in self.active_rollback.affected_subsystems:
        order.append("tolaria")
    
    # Auxiliary subsystems in alphabetical order for determinism
    auxiliary = sorted(
        self.active_rollback.affected_subsystems - self.core_subsystems
    )
    order.extend(auxiliary)
    
    return order
```

## Write-Ahead Logging (WAL)

### Enhanced WAL with Durability Semantics

**[C-016 FIX] Proper durability guarantees:**

```python
import os
import fcntl

class CheckpointWAL:
    """Write-Ahead Logging with proper durability semantics"""
    
    # Configuration constants
    WAL_MAGIC_NUMBER = b'ESPERWAL'
    WAL_VERSION = 2  # Version 2 with durability enhancements
    ENTRY_HEADER_SIZE = 256  # Fixed size for WAL entry headers
    MAX_WAL_SIZE = 100 * 1024 * 1024  # 100MB before rotation
    CHECKPOINT_CHUNK_SIZE = 1024 * 1024 * 1024  # 1GB chunks for large tensors
    
    def __init__(self, wal_path: str, filesystem_type: str = "ext4"):
        self.wal_path = wal_path
        self.filesystem_type = filesystem_type
        
        # Open with O_DSYNC for immediate durability
        flags = os.O_WRONLY | os.O_CREAT | os.O_APPEND
        if hasattr(os, 'O_DSYNC'):
            flags |= os.O_DSYNC  # Linux direct synchronous writes
        
        self.wal_fd = os.open(wal_path, flags, 0o644)
        
        # Document filesystem requirements
        self._validate_filesystem_config()
```

### Filesystem Configuration Validation

```python
def _validate_filesystem_config(self):
    """Validate filesystem mount options for durability"""
    required_options = {
        "ext4": ["data=ordered", "barrier=1"],  # Write ordering + barriers
        "xfs": ["logbsize=256k", "wsync"]       # Large log buffer + sync writes
    }
    
    if self.filesystem_type in required_options:
        # Check mount options via /proc/mounts
        # Implementation would verify filesystem is mounted with required options
        pass
```

### Atomic Checkpoint Operations

```python
def begin_checkpoint(self, checkpoint_id: str, epoch: int) -> str:
    """Begin atomic checkpoint transaction"""
    with self.wal_lock:
        if self.active_transaction:
            raise RuntimeError(f"Transaction {self.active_transaction} already active")
        
        self.active_transaction = checkpoint_id
        self.transaction_entries = []
        
        # Write BEGIN entry with execution context
        execution_context = ExecutionContext(
            model_hash=self._compute_model_hash(),
            toolchain_version=get_protocol_version(),
            training_run_id=get_current_training_run_id(),
            hardware_profile=get_hardware_fingerprint()
        )
        
        entry = self._write_wal_entry(
            operation=WALOperationType.BEGIN_CHECKPOINT,
            transaction_id=checkpoint_id,
            metadata={
                'epoch': epoch,
                'timestamp': datetime.now(UTC).isoformat(),
                'node_id': self.node_id,
                'execution_context': execution_context.serialize()
            }
        )
        
        return checkpoint_id

def commit_checkpoint(self, checkpoint_id: str) -> bool:
    """Atomically commit checkpoint transaction"""
    with self.wal_lock:
        if checkpoint_id != self.active_transaction:
            return False
        
        # Verify all entries written successfully
        if not self._verify_transaction_integrity(checkpoint_id):
            self.abort_checkpoint(checkpoint_id)
            return False
        
        # Write COMMIT entry
        self._write_wal_entry(
            operation=WALOperationType.COMMIT_CHECKPOINT,
            transaction_id=checkpoint_id,
            metadata={
                'entry_count': len(self.transaction_entries),
                'commit_time': datetime.now(UTC).isoformat()
            }
        )
        
        # Force to disk with appropriate sync method
        if hasattr(os, 'O_DSYNC') and (os.O_DSYNC & fcntl.fcntl(self.wal_fd, fcntl.F_GETFL)):
            # O_DSYNC ensures immediate sync, no additional fsync needed
            pass
        else:
            os.fsync(self.wal_fd)  # Fallback to explicit fsync
        
        # Update committed checkpoints
        self.committed_checkpoints[checkpoint_id] = self.sequence_number
        
        # Clear transaction state
        self.active_transaction = None
        self.transaction_entries = []
        
        return True
```

## Emergency Response Matrix

### Detection and Response Thresholds

| Condition | Detection Threshold | Response Time | Recovery Action |
|-----------|-------------------|---------------|-----------------|
| **CRITICAL** | System freeze/deadlock | 100ms | Shared memory freeze signal |
| **SEVERE** | Loss explosion (>15x) | 500ms | Fast rollback (in-memory) |
| **MAJOR** | Accuracy collapse | 2s | Full rollback (persistent) |
| **MINOR** | Performance degradation | 5s | Parameter adjustment |

### Fast Rollback Sequence (500ms)

1. **PREPARE** (150ms): Signal participants, check cache
2. **COMMIT** (250ms): Execute from in-memory checkpoint
3. **CONFIRM** (100ms): Verify completion, resume training

### Full Rollback Sequence (12s)

1. **Detection** (0.1s): Any monitoring system triggers
2. **Pause Training** (0.2s): Immediate training loop halt
3. **Log Critical Event** (0.1s): Emergency telemetry
4. **Distributed Coordination** (2.0s): Three-phase protocol initiation
5. **Load Checkpoint** (3.5s): WAL-protected checkpoint restoration
6. **Model State Restoration** (2.8s): PyTorch state_dict loading
7. **Optimizer Restoration** (2.2s): Momentum preservation
8. **Controller Restoration** (1.5s): Tamiyo state restoration
9. **Seed Reset** (1.2s): Kasmina layer cleanup
10. **System Coordination** (0.8s): Cross-subsystem synchronization
11. **Validation** (0.3s): State integrity verification
12. **Resume Training** (0.1s): Normal operation restoration

## Performance Requirements

### Timing Budgets

| Operation | Budget | Critical Path |
|-----------|--------|--------------|
| Fast Rollback | 500ms | Yes |
| Full Rollback | 12s | No |
| Critical Response | 100ms | Yes |
| WAL Write | 10ms | No |
| Checkpoint Cache GC | 50ms | No |

### Memory Limits

- **Checkpoint Cache**: 5 checkpoints maximum (LRU eviction)
- **WAL Size**: 100MB before rotation
- **Tensor Chunks**: 1GB maximum per chunk

## Integration Contract

### Dependencies

- **Shared Memory**: For critical emergency signaling
- **Oona Message Bus**: For distributed coordination
- **Checkpoint Manager**: For state persistence
- **Circuit Breakers**: For timing violation handling

### Outputs

- **Rollback Status**: Success/failure indication
- **Emergency Telemetry**: Critical event logging
- **Performance Metrics**: Timing and success rates

## C-016 Safety Enhancements

1. **Circuit Breakers**: Replace all assert statements
2. **Memory Management**: LRU cache with garbage collection
3. **WAL Durability**: O_DSYNC flags and fsync barriers
4. **Conservative Mode**: Graceful degradation on timing violations
5. **Execution Context**: Include in checkpoint metadata

## References

- Parent: [01-tolaria-unified-design.md](01-tolaria-unified-design.md)
- Related: [01.1-tolaria-epoch-lifecycle.md](01.1-tolaria-epoch-lifecycle.md) for epoch management
- Related: [01.3-tolaria-optimizer-lr.md](01.3-tolaria-optimizer-lr.md) for optimizer state
- Integration: [01.4-tolaria-integration-protocols.md](01.4-tolaria-integration-protocols.md) for protocols