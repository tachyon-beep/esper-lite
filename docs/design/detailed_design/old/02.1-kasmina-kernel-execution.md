# Kasmina - Kernel Execution and GPU Management

**Parent Document**: [02-kasmina-unified-design.md](./02-kasmina-unified-design.md)
**Component Type**: Algorithm|Core
**Version**: 4.0
**Status**: PRODUCTION - C-022 Hardened + C-024 KD Enhanced
**C-022 Updates**: Critical gradient isolation fix, backward hook monitoring, HMAC authentication
**C-024 Updates**: Gradient checkpointed teacher integration, memory-efficient KD implementation

---

## Overview

This component provides the core specification for Kasmina's GPU kernel management and execution pipeline. Kasmina serves as a pure executor that loads pre-compiled, pre-validated kernels from Urza and executes them with sub-millisecond latency targets while maintaining complete gradient isolation.

**C-022 Production Hardening**: Enhanced gradient isolation with backward hook monitoring, HMAC authentication for optimizer commands, and improved circuit breaker patterns for production reliability.

**C-024 Knowledge Distillation**: Gradient checkpointed teacher model integration with 14GB → 7GB memory reduction for A100 40GB deployment viability.

**Leyline Integration**: All message handling now uses performance-optimized Leyline contracts with native map<> support, achieving 57% smaller messages and 73% faster serialization.

## 1. GPU Kernel Management

### 1.1 Kernel Loading Architecture

```python
class KasminaKernelManager:
    """GPU-native kernel management with Leyline integration, C-022 security, and C-024 KD support"""

    def __init__(self, config: KasminaConfig):
        self.config = config
        self.kernel_cache = GPUKernelCache(config.cache_size_mb)
        self.urza_client = UrzaLibraryClient()

        # Leyline imports for message handling
        from esper.leyline.contracts import (
            AdaptationCommand,
            TelemetryPacket,
            MessagePriority
        )
        self.adaptation_handler = LeylineAdaptationHandler()

        # C-022: HMAC key for authentication
        self.hmac_key = secrets.token_bytes(32)
        self.processed_nonces = set()  # Replay protection

        # C-024: Teacher model for knowledge distillation
        self.teacher_model = None
        self.checkpointed_teacher = None
        if config.kd_enabled:
            self._initialize_teacher_model()

    def _initialize_teacher_model(self):
        """C-024: Initialize checkpointed teacher model for knowledge distillation"""
        if not self.config.teacher_checkpoint_path:
            logger.warning("KD enabled but no teacher checkpoint path provided")
            return

        try:
            # Load teacher model architecture (must match student architecture)
            from esper.models import create_teacher_model
            self.teacher_model = create_teacher_model(self.config)

            # Wrap with checkpointing for memory efficiency (14GB → 7GB)
            from esper.kasmina.kd import CheckpointedTeacher
            self.checkpointed_teacher = CheckpointedTeacher(
                self.teacher_model,
                checkpoint_path=self.config.teacher_checkpoint_path
            )

            # Move to GPU and set eval mode
            self.checkpointed_teacher.teacher.cuda()
            self.checkpointed_teacher.teacher.eval()

            # Pre-allocate memory to prevent fragmentation
            self._preallocate_teacher_memory()

            logger.info(f"Teacher model loaded from {self.config.teacher_checkpoint_path}")
            logger.info("Gradient checkpointing enabled: 14GB → 7GB memory reduction")

        except Exception as e:
            logger.error(f"Failed to initialize teacher model: {e}")
            self.config.kd_enabled = False

    def _preallocate_teacher_memory(self):
        """C-024: Pre-allocate teacher memory to prevent fragmentation"""
        if not self.checkpointed_teacher:
            return

        # Estimate teacher memory requirement with checkpointing
        expected_memory_gb = 7.0  # With gradient checkpointing

        # Check available GPU memory
        available_gb = torch.cuda.memory_reserved() / 1e9
        if available_gb < expected_memory_gb:
            logger.warning(f"Insufficient GPU memory for teacher: {available_gb:.1f}GB < {expected_memory_gb}GB")

    async def load_kernel_with_teacher(self, kernel_artifact_id: str) -> Tuple[GPUKernel, Optional[torch.Tensor]]:
        """C-024: Load kernel and optionally get teacher predictions for KD"""

        # Load the kernel as before
        kernel = await self.load_kernel(kernel_artifact_id)

        # If KD is enabled, prepare teacher predictions
        teacher_logits = None
        if self.config.kd_enabled and self.checkpointed_teacher:
            teacher_logits = await self._get_teacher_predictions(kernel)

        return kernel, teacher_logits

    async def _get_teacher_predictions(self, kernel: GPUKernel) -> Optional[torch.Tensor]:
        """C-024: Get teacher predictions with gradient checkpointing"""
        if not self.checkpointed_teacher:
            return None

        try:
            # Get input batch for teacher (must match student input)
            input_batch = kernel.get_input_batch()

            # Teacher forward pass with checkpointing (no gradients)
            with torch.no_grad():
                teacher_logits = self.checkpointed_teacher.forward(input_batch)

            # CUDA sync for multi-GPU consistency
            if torch.cuda.device_count() > 1:
                torch.cuda.synchronize()

            return teacher_logits.detach()  # Ensure complete detachment

        except Exception as e:
            logger.error(f"Failed to get teacher predictions: {e}")
            return None

    async def load_kernel(self, kernel_artifact_id: str) -> GPUKernel:
        """Load pre-compiled kernel from Urza with GPU caching"""

        # Check GPU-resident cache first
        cached_kernel = self.kernel_cache.get(kernel_artifact_id)
        if cached_kernel is not None:
            return cached_kernel

        # Fetch from Urza (pre-validated by Urabrask)
        kernel_binary = await self.urza_client.fetch_kernel(kernel_artifact_id)

        # Load to GPU with performance profiling
        gpu_kernel = self._load_to_gpu(kernel_binary)

        # Cache for subsequent executions
        self.kernel_cache.put(kernel_artifact_id, gpu_kernel)

        return gpu_kernel

    def _load_to_gpu(self, kernel_binary: bytes) -> GPUKernel:
        """Load kernel to GPU with telemetry"""
        start_time = time.perf_counter()

        # Load kernel to GPU device
        gpu_kernel = GPUKernel.from_binary(kernel_binary)

        # Record performance metrics
        load_time_ms = (time.perf_counter() - start_time) * 1000
        self._record_kernel_load_metric(load_time_ms)

        return gpu_kernel
```

### 1.2 GPU-Resident Cache

```python
class GPUKernelCache:
    """High-performance GPU-resident kernel cache"""

    def __init__(self, cache_size_mb: int):
        self.max_size_bytes = cache_size_mb * 1024 * 1024
        self.cache: Dict[str, GPUKernel] = {}
        self.access_times: Dict[str, float] = {}
        self.current_size_bytes = 0

    def get(self, kernel_id: str) -> Optional[GPUKernel]:
        """Get kernel from GPU cache with LRU tracking"""
        if kernel_id in self.cache:
            self.access_times[kernel_id] = time.time()
            return self.cache[kernel_id]
        return None

    def put(self, kernel_id: str, kernel: GPUKernel) -> None:
        """Put kernel in GPU cache with LRU eviction"""
        kernel_size = kernel.get_memory_size()

        # Evict if necessary
        while (self.current_size_bytes + kernel_size > self.max_size_bytes
               and len(self.cache) > 0):
            self._evict_lru()

        # Store kernel
        self.cache[kernel_id] = kernel
        self.access_times[kernel_id] = time.time()
        self.current_size_bytes += kernel_size

    def _evict_lru(self) -> None:
        """Evict least recently used kernel"""
        lru_kernel_id = min(self.access_times, key=self.access_times.get)

        # Remove from GPU memory
        evicted_kernel = self.cache[lru_kernel_id]
        self.current_size_bytes -= evicted_kernel.get_memory_size()
        evicted_kernel.release_gpu_memory()

        # Remove from cache
        del self.cache[lru_kernel_id]
        del self.access_times[lru_kernel_id]
```

## 2. Leyline Protocol Buffer Integration with C-022 Security

### 2.1 AdaptationCommand Handler with HMAC Authentication

```python
class LeylineAdaptationHandler:
    """Process AdaptationCommands using Leyline contracts with C-022 security"""

    def __init__(self, hmac_key: bytes):
        # Import Leyline contracts
        from esper.leyline.contracts import (
            AdaptationCommand,
            CommandType,
            SeedOperation,
            TelemetryPacket,
            MessagePriority
        )

        self.command_processor = CommandProcessor()
        self.telemetry_reporter = LeylineTelemetryReporter()

        # C-022: Security enhancements
        self.hmac_key = hmac_key
        self.processed_nonces = set()
        self.nonce_expiry_time = 300  # 5 minutes
        self.nonce_timestamps = {}

    def _verify_message_auth(self, command: AdaptationCommand) -> bool:
        """C-022: Verify HMAC authentication and replay protection"""
        # Check nonce for replay protection
        if command.metadata.nonce in self.processed_nonces:
            logger.error(f"Replay attack detected - nonce already used")
            return False

        # Check timestamp freshness
        current_time = time.time()
        if abs(current_time - command.metadata.timestamp) > 60:
            logger.error("Stale message detected")
            return False

        # Verify HMAC
        message_copy = command.__class__()
        message_copy.CopyFrom(command)
        message_copy.metadata.ClearField('signature')
        message_bytes = message_copy.SerializeToString()

        expected_signature = hmac.new(
            self.hmac_key, message_bytes, hashlib.sha256
        ).digest()

        if not hmac.compare_digest(expected_signature, command.metadata.signature):
            logger.error("Authentication failed - invalid HMAC")
            return False

        # Mark nonce as used
        self.processed_nonces.add(command.metadata.nonce)
        self.nonce_timestamps[command.metadata.nonce] = current_time
        self._clean_old_nonces(current_time)

        return True

    async def handle_adaptation_command(self, raw_message: bytes) -> bool:
        """Process AdaptationCommand using Leyline format with authentication"""
        try:
            # Deserialize using Leyline contracts (optimized format)
            command = AdaptationCommand()
            command.ParseFromString(raw_message)

            # C-022: Verify authentication
            if not self._verify_message_auth(command):
                return False

            # Validate command (Leyline provides validation)
            if not self._validate_leyline_command(command):
                return False

            # Convert to internal KasminaCommand
            kasmina_command = self._convert_from_leyline(command)

            # Send acknowledgment using Leyline TelemetryPacket
            await self._send_leyline_acknowledgment(command.command_id)

            # Execute command
            result = await self.command_processor.execute(kasmina_command)

            # Send completion using Leyline format
            await self._send_leyline_completion(command.command_id, result)

            return result.success

        except Exception as e:
            logger.error(f"Failed to handle Leyline AdaptationCommand: {e}")
            return False

    def _convert_from_leyline(self, leyline_command: AdaptationCommand) -> KasminaCommand:
        """Convert Leyline AdaptationCommand to internal format"""

        # Extract command from oneof field
        if leyline_command.HasField('seed_command'):
            seed_cmd = leyline_command.seed_command
            return KasminaCommand(
                command_type=self._map_seed_operation(seed_cmd.operation),
                seed_id=seed_cmd.seed_id,
                # Use native map access (C-018 Option B performance benefit)
                parameters=dict(seed_cmd.parameters),
                priority=leyline_command.priority,
                timeout_ms=leyline_command.timeout.total_seconds() * 1000
            )

        elif leyline_command.HasField('rollback_command'):
            rollback_cmd = leyline_command.rollback_command
            return KasminaCommand(
                command_type=CommandType.ROLLBACK,
                target_epoch=rollback_cmd.target_epoch,
                emergency=rollback_cmd.emergency,
                reason=rollback_cmd.reason
            )

        # Handle other command types...
```

### 2.2 Leyline Message Performance (Option B Benefits)

**Performance Improvements from C-018 Option B:**

```python
class LeylineMessageBenchmark:
    """Demonstrate Leyline Option B performance benefits"""

    def benchmark_serialization(self):
        """Compare Option B vs compatibility approach"""

        # Option B: Native map usage
        system_state = SystemStatePacket()
        system_state.version = 1  # Single uint32 field
        system_state.current_epoch = 1000
        system_state.validation_accuracy = 0.987

        # Native map access (88% fewer GC allocations)
        system_state.training_metrics["loss"] = 0.045
        system_state.training_metrics["accuracy"] = 0.987
        system_state.training_metrics["lr"] = 0.001

        # Measure serialization
        start_time = time.perf_counter()
        serialized = system_state.SerializeToString()
        end_time = time.perf_counter()

        serialization_time_us = (end_time - start_time) * 1_000_000
        message_size_bytes = len(serialized)

        # C-018 Option B targets
        assert serialization_time_us < 80, f"Serialization too slow: {serialization_time_us}μs"
        assert message_size_bytes < 280, f"Message too large: {message_size_bytes} bytes"

        return {
            'serialization_time_us': serialization_time_us,
            'message_size_bytes': message_size_bytes,
            'performance_improvement': '73% faster vs compatibility approach',
            'size_improvement': '57% smaller vs compatibility approach'
        }
```

## 3. Enhanced Gradient Isolation with C-022 Fixes and C-024 KD Support

### 3.1 Gradient Isolated Seed with Backward Hook Monitoring and KD Integration

```python
class GradientIsolatedSeed(nn.Module):
    """C-022 Enhanced + C-024 KD: Lifecycle-aware gradient isolation with backward hook monitoring and KD support"""

    def __init__(self, chunk_size: int, seed_id: str, kd_config: Optional[KDConfig] = None):
        super().__init__()
        self.seed_id = seed_id
        self.state = SeedLifecycleStage.SEED_DORMANT  # Leyline enum
        self.current_kernel = None
        self.alpha = 0.0  # Blending parameter for alpha blending
        self.isolation_verified = False

        # Performance monitoring
        self.isolation_timer = MonotonicTimer()

        # C-022: Gradient isolation monitoring
        self.gradient_monitor = GradientIsolationMonitor(seed_id)
        self.violation_count = 0
        self.circuit_breaker_threshold = 3

        # C-024: Knowledge distillation support
        self.kd_config = kd_config
        self.kd_loss_fn = None
        if kd_config and kd_config.enabled:
            from esper.kasmina.kd import StaticKDLoss
            self.kd_loss_fn = StaticKDLoss()

    def forward(self, host_activations: torch.Tensor, teacher_logits: Optional[torch.Tensor] = None) -> torch.Tensor:
        """Execute with guaranteed gradient isolation - C-022 FIXED + C-024 KD"""
        isolation_start = self.isolation_timer.current_time_ms()

        if (self.state == SeedLifecycleStage.SEED_DORMANT
            or self.current_kernel is None):
            return host_activations  # Pass-through mode

        try:
            # CRITICAL C-022 FIX: Detach to prevent gradient flow to host
            isolated_input = host_activations.detach()

            # Verify computational graph isolation
            assert isolated_input.grad_fn is None, "Gradient isolation violated"

            # Seed processes isolated activations
            seed_output = self.current_kernel(isolated_input)

            # C-024: Apply KD loss if teacher predictions available
            if teacher_logits is not None and self.kd_loss_fn is not None:
                # Teacher logits are already detached from CheckpointedTeacher
                kd_loss = self.kd_loss_fn(seed_output, teacher_logits)
                # KD loss will be added to the main loss in the training loop
                self._store_kd_loss(kd_loss)

            # Alpha blending during grafting phase
            if self.state == SeedLifecycleStage.SEED_GRAFTING:
                # C-022 CRITICAL FIX (Line 293): Detach host_activations in blending
                # This prevents gradients from flowing back through host during seed training
                output = self.alpha * seed_output + (1 - self.alpha) * host_activations.detach()

            elif self.state in [
                SeedLifecycleStage.SEED_STABILIZATION,
                SeedLifecycleStage.SEED_EVALUATING,
                SeedLifecycleStage.SEED_FINE_TUNING,
                SeedLifecycleStage.SEED_FOSSILIZED
            ]:
                # Full seed output after grafting complete
                output = seed_output

            else:
                # Training phase - isolated seed training
                output = host_activations  # Host unmodified during seed training

            # Record isolation performance
            isolation_time_ms = self.isolation_timer.elapsed_ms(isolation_start)
            self._record_isolation_timing(isolation_time_ms)

            return output

        except Exception as e:
            logger.error(f"Gradient isolation failed for seed {self.seed_id}: {e}")
            # Conservative fallback
            return host_activations

    def _store_kd_loss(self, kd_loss: torch.Tensor):
        """C-024: Store KD loss for later aggregation in training loop"""
        # Store in a way that's accessible to the training loop
        # This avoids modifying the main loss computation
        if not hasattr(self, '_kd_losses'):
            self._kd_losses = []
        self._kd_losses.append(kd_loss.detach())

    def get_and_clear_kd_losses(self) -> Optional[torch.Tensor]:
        """C-024: Retrieve accumulated KD losses and clear buffer"""
        if not hasattr(self, '_kd_losses') or not self._kd_losses:
            return None

        # Average the accumulated KD losses
        kd_loss = torch.stack(self._kd_losses).mean()
        self._kd_losses = []
        return kd_loss

    def register_backward_hooks(self, host_model: nn.Module, seed_model: nn.Module):
        """C-022: Register backward hooks for gradient leak detection"""
        self.gradient_monitor.register_hooks(host_model, seed_model)

    def update_alpha_blending(self, step: int, total_steps: int, temperature: float = 1.0):
        """Update alpha parameter for smooth grafting transition"""
        if self.state == SeedLifecycleStage.SEED_GRAFTING:
            t_mid = total_steps // 2
            self.alpha = torch.sigmoid((step - t_mid) / temperature).item()

    def verify_gradient_isolation(self,
                                host_grads: torch.Tensor,
                                seed_grads: torch.Tensor) -> bool:
        """Mathematical verification of gradient isolation"""

        # Check for NaN gradients
        if torch.any(torch.isnan(host_grads)) or torch.any(torch.isnan(seed_grads)):
            self.isolation_verified = False
            return False

        # Verify disjoint computation graphs
        if (host_grads.requires_grad and seed_grads.requires_grad
            and host_grads.grad_fn is not None and seed_grads.grad_fn is not None):

            # Check for shared computational graph nodes
            host_graph_ids = self._get_computation_graph_ids(host_grads)
            seed_graph_ids = self._get_computation_graph_ids(seed_grads)

            # Mathematical invariant: ∇L_host ∩ ∇L_seed = ∅
            intersection = host_graph_ids & seed_graph_ids
            if len(intersection) > 0:
                self.isolation_verified = False
                self.violation_count += 1
                logger.error(f"Gradient isolation violation: shared nodes {intersection}")

                # C-022: Circuit breaker activation
                if self.violation_count >= self.circuit_breaker_threshold:
                    self._trigger_circuit_breaker()

                return False

        self.isolation_verified = True
        return True

    def _trigger_circuit_breaker(self):
        """C-022: Emergency stop when repeated violations detected"""
        logger.critical(f"CIRCUIT BREAKER: Seed {self.seed_id} - {self.violation_count} violations")

        # Save emergency checkpoint
        torch.save({
            'seed_id': self.seed_id,
            'violation_count': self.violation_count,
            'timestamp': datetime.now().isoformat()
        }, f'emergency_gradient_violation_{self.seed_id}.pt')

        # Halt seed operation
        self.state = SeedLifecycleStage.SEED_QUARANTINE
        raise GradientIsolationViolationError(
            f"Critical: {self.violation_count} gradient isolation violations for seed {self.seed_id}"
        )

    def _get_computation_graph_ids(self, tensor: torch.Tensor) -> Set[int]:
        """Extract computation graph node IDs for isolation verification"""
        node_ids = set()

        def traverse_graph(node):
            if node is not None:
                node_ids.add(id(node))
                if hasattr(node, 'next_functions'):
                    for fn, _ in node.next_functions:
                        traverse_graph(fn)

        if tensor.grad_fn is not None:
            traverse_graph(tensor.grad_fn)

        return node_ids

    def _record_isolation_timing(self, duration_ms: float) -> None:
        """Record gradient isolation performance metrics"""
        # Target: < 8.0ms overhead per seed operation
        if duration_ms > 8.0:
            logger.warning(f"Gradient isolation exceeded target: {duration_ms}ms > 8.0ms")

        # Send to Leyline telemetry
        self._emit_isolation_metric(duration_ms)
```

### 3.2 C-022 Gradient Isolation Monitor

```python
class GradientIsolationMonitor:
    """C-022: Runtime verification of gradient isolation using backward hooks"""

    def __init__(self, seed_id: str):
        self.seed_id = seed_id
        self.host_grad_params = set()
        self.seed_grad_params = set()
        self.violation_count = 0
        self.circuit_breaker_threshold = 3
        self.backward_hooks = []
        self.in_seed_computation = False
        self.in_host_computation = False

    def register_hooks(self, host_model: nn.Module, seed_model: nn.Module):
        """Register backward hooks to monitor gradient flow during backward pass"""

        # Clear any existing hooks
        self._clear_hooks()

        # Register backward hooks on host model layers
        for name, module in host_model.named_modules():
            if len(list(module.children())) == 0:  # Leaf modules only
                hook = module.register_full_backward_hook(
                    lambda module, grad_input, grad_output, name=name:
                    self._detect_host_gradient_leak(name, grad_output)
                )
                self.backward_hooks.append(hook)

        # Register backward hooks on seed model layers
        for name, module in seed_model.named_modules():
            if len(list(module.children())) == 0:  # Leaf modules only
                hook = module.register_full_backward_hook(
                    lambda module, grad_input, grad_output, name=name:
                    self._detect_seed_gradient_leak(name, grad_output)
                )
                self.backward_hooks.append(hook)

    def _detect_host_gradient_leak(self, layer_name: str, grad_output):
        """Detect gradients in host network during seed backward pass"""
        if grad_output[0] is not None and grad_output[0].abs().sum() > 1e-10:
            self.host_grad_params.add(layer_name)

            # Check if we're in a seed backward pass (violation!)
            if self.in_seed_computation:
                logger.critical(f"GRADIENT LEAK: Host layer {layer_name} during seed backward")
                self.violation_count += 1
                if self.violation_count >= self.circuit_breaker_threshold:
                    self._trigger_circuit_breaker()

    def _detect_seed_gradient_leak(self, layer_name: str, grad_output):
        """Detect gradients in seed network during host backward pass"""
        if grad_output[0] is not None and grad_output[0].abs().sum() > 1e-10:
            self.seed_grad_params.add(layer_name)

            # Check if we're in a host backward pass (violation!)
            if self.in_host_computation:
                logger.critical(f"GRADIENT LEAK: Seed layer {layer_name} during host backward")
                self.violation_count += 1
                if self.violation_count >= self.circuit_breaker_threshold:
                    self._trigger_circuit_breaker()

    def begin_host_backward(self):
        """Signal start of host backward pass"""
        self.in_host_computation = True
        self.in_seed_computation = False
        self.host_grad_params.clear()

    def end_host_backward(self):
        """Signal end of host backward pass"""
        self.in_host_computation = False

    def begin_seed_backward(self):
        """Signal start of seed backward pass"""
        self.in_seed_computation = True
        self.in_host_computation = False
        self.seed_grad_params.clear()

    def end_seed_backward(self):
        """Signal end of seed backward pass"""
        self.in_seed_computation = False

    def verify_isolation_after_step(self) -> bool:
        """Verify gradient isolation after optimizer steps"""
        intersection = self.host_grad_params & self.seed_grad_params

        if intersection:
            self.violation_count += 1
            logger.error(f"POST-STEP VIOLATION: Shared params {intersection}")

            if self.violation_count >= self.circuit_breaker_threshold:
                self._trigger_circuit_breaker()

            return False

        # Reset for next iteration
        self.host_grad_params.clear()
        self.seed_grad_params.clear()
        return True

    def _clear_hooks(self):
        """Remove all registered hooks"""
        for hook in self.backward_hooks:
            hook.remove()
        self.backward_hooks = []

    def _trigger_circuit_breaker(self):
        """Emergency stop when repeated violations detected"""
        logger.critical(f"GRADIENT MONITOR CIRCUIT BREAKER - Seed {self.seed_id}")

        # Save emergency checkpoint
        torch.save({
            'seed_id': self.seed_id,
            'violation_count': self.violation_count,
            'host_params_with_grads': list(self.host_grad_params),
            'seed_params_with_grads': list(self.seed_grad_params),
            'timestamp': datetime.now().isoformat()
        }, f'emergency_gradient_monitor_{self.seed_id}.pt')

        # Halt training
        raise GradientIsolationViolationError(
            f"Critical: {self.violation_count} gradient isolation violations detected"
        )
```

### 3.3 Isolated Optimizer Manager with C-022 Two-Optimizer Pattern and C-024 Teacher Support

```python
class IsolatedOptimizerManager:
    """C-022: Separate optimizers for host and seed with Tolaria ownership + C-024 teacher support"""

    def __init__(self):
        # C-022: Optimizers owned by Tolaria, executed by Kasmina
        self.host_optimizer_ref = None  # Reference to Tolaria-owned optimizer
        self.seed_optimizer_refs = {}   # References to Tolaria-owned optimizers
        self.parameter_registry = {}    # Track parameter ownership

        # Leyline integration for telemetry
        from esper.leyline.contracts import TelemetryPacket, MetricType
        self.telemetry_reporter = LeylineTelemetryReporter()

        # C-022: Message-based coordination
        self.message_handler = OptimizerMessageHandler()

        # C-024: Teacher model tracking (no optimizer needed - eval only)
        self.teacher_params_registered = False

    async def handle_optimizer_command(self, command: OptimizerCommand) -> bool:
        """C-022: Handle optimizer commands from Tolaria with authentication"""

        # Verify HMAC authentication
        if not self.message_handler.verify_auth(command):
            logger.error("Optimizer command authentication failed")
            return False

        # Handle command types
        if command.command_type == OptimizerCommandType.INITIALIZE_HOST:
            return await self._initialize_host_optimizer(command)
        elif command.command_type == OptimizerCommandType.CREATE_SEED:
            return await self._create_seed_optimizer(command)
        elif command.command_type == OptimizerCommandType.STEP:
            return await self._step_optimizer(command)
        elif command.command_type == OptimizerCommandType.RESET_STATE:
            return await self._reset_optimizer_state(command)
        elif command.command_type == OptimizerCommandType.REGISTER_TEACHER:  # C-024
            return await self._register_teacher_params(command)

        return False

    async def _register_teacher_params(self, command: OptimizerCommand) -> bool:
        """C-024: Register teacher parameters without creating optimizer (eval only)"""

        if self.teacher_params_registered:
            logger.warning("Teacher parameters already registered")
            return True

        try:
            # Extract teacher model reference from command
            teacher_model_ref = command.teacher_model_ref

            # Verify teacher is in eval mode
            if teacher_model_ref.training:
                logger.error("Teacher model must be in eval mode")
                return False

            # Register parameters for tracking (no gradients)
            teacher_params = list(teacher_model_ref.parameters())

            # Verify no gradients on teacher
            for param in teacher_params:
                if param.requires_grad:
                    param.requires_grad = False  # Force no gradients
                    logger.warning("Disabled gradients on teacher parameter")

            # Store parameter count for telemetry
            param_count = sum(p.numel() for p in teacher_params)

            # Report registration
            await self._report_teacher_registration(param_count)

            self.teacher_params_registered = True
            logger.info(f"Registered {param_count:,} teacher parameters (eval only)")

            return True

        except Exception as e:
            logger.error(f"Failed to register teacher parameters: {e}")
            return False

    async def _report_teacher_registration(self, param_count: int):
        """C-024: Report teacher parameter registration to telemetry"""
        telemetry = TelemetryPacket()
        telemetry.packet_id = f"teacher_registered_{time.time()}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add metric for teacher registration
        metric = telemetry.metrics.add()
        metric.name = "teacher_params_registered"
        metric.type = MetricType.METRIC_GAUGE
        metric.value = float(param_count)
        metric.labels["eval_only"] = "true"
        metric.labels["gradient_checkpointing"] = "true"

        await self.telemetry_reporter.send_telemetry_async(telemetry)

    async def _step_optimizer(self, command: OptimizerCommand) -> bool:
        """Execute optimizer step command from Tolaria"""
        optimizer_id = command.optimizer_id

        # Apply gradient clipping if requested
        if command.step_params.grad_clip_norm > 0:
            if optimizer_id == "host":
                params = self.parameter_registry.get_host_parameters()
            else:
                params = self.parameter_registry.get_seed_parameters(optimizer_id)

            torch.nn.utils.clip_grad_norm_(params, command.step_params.grad_clip_norm)

        # Execute step (optimizer owned by Tolaria)
        # This is a reference execution - actual state management in Tolaria
        if optimizer_id == "host":
            # Signal host optimizer step
            self.gradient_monitor.begin_host_backward()
            # Execute step logic here
            self.gradient_monitor.end_host_backward()
        else:
            # Signal seed optimizer step
            self.gradient_monitor.begin_seed_backward()
            # Execute step logic here
            self.gradient_monitor.end_seed_backward()

        # Verify isolation after step
        self.gradient_monitor.verify_isolation_after_step()

        # Send confirmation back to Tolaria
        await self._send_step_confirmation(command.optimizer_id)

        return True

    def _report_optimizer_creation(self, seed_id: str, param_count: int) -> None:
        """Report optimizer creation to Leyline telemetry"""
        telemetry = TelemetryPacket()
        telemetry.packet_id = f"optimizer_created_{seed_id}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add metric for optimizer creation
        metric = telemetry.metrics.add()
        metric.name = "seed_optimizer_created"
        metric.type = MetricType.METRIC_COUNTER
        metric.value = 1.0
        # Use native map for labels (C-018 Option B performance)
        metric.labels["seed_id"] = seed_id
        metric.labels["parameter_count"] = str(param_count)

        self.telemetry_reporter.send_telemetry_async(telemetry)
```

### 3.4 C-024 Teacher Forward Pass Integration

```python
class TeacherForwardPassManager:
    """C-024: Manage teacher forward passes with gradient checkpointing"""

    def __init__(self, checkpointed_teacher: Optional[CheckpointedTeacher] = None):
        self.checkpointed_teacher = checkpointed_teacher
        self.forward_pass_timer = MonotonicTimer()
        self.checkpoint_overhead_tracker = []

    @torch.no_grad()  # Critical: Teacher never needs gradients
    def get_teacher_predictions(self, input_batch: torch.Tensor) -> Optional[torch.Tensor]:
        """C-024: Get teacher predictions with checkpointing and timing"""

        if not self.checkpointed_teacher:
            return None

        start_time = self.forward_pass_timer.current_time_ms()

        try:
            # Forward pass through checkpointed teacher
            teacher_logits = self.checkpointed_teacher.forward(input_batch)

            # CUDA synchronization for multi-GPU
            if torch.cuda.device_count() > 1:
                torch.cuda.synchronize()

            # Track checkpoint overhead
            elapsed_ms = self.forward_pass_timer.elapsed_ms(start_time)
            self.checkpoint_overhead_tracker.append(elapsed_ms)

            # Monitor if overhead exceeds threshold (20% of budget)
            if elapsed_ms > 10.0:  # 10ms budget for teacher forward
                logger.warning(f"Teacher forward pass slow: {elapsed_ms:.1f}ms")

            return teacher_logits.detach()

        except torch.cuda.OutOfMemoryError as e:
            logger.critical(f"OOM during teacher forward pass: {e}")
            logger.critical("Checkpoint segments may need adjustment")
            # Emergency cleanup
            torch.cuda.empty_cache()
            return None

        except Exception as e:
            logger.error(f"Teacher forward pass failed: {e}")
            return None

    def get_checkpoint_effectiveness(self) -> Dict[str, float]:
        """C-024: Measure checkpoint effectiveness metrics"""

        if not self.checkpoint_overhead_tracker:
            return {}

        overhead_ms = np.mean(self.checkpoint_overhead_tracker)
        overhead_std = np.std(self.checkpoint_overhead_tracker)

        # Estimate memory saved (should be ~7GB for 14GB model)
        memory_before_gb = 14.0  # Baseline teacher memory
        memory_with_checkpoint_gb = torch.cuda.memory_allocated() / 1e9
        memory_saved_gb = memory_before_gb - memory_with_checkpoint_gb

        return {
            'checkpoint_overhead_ms': overhead_ms,
            'checkpoint_overhead_std': overhead_std,
            'memory_saved_gb': memory_saved_gb,
            'effectiveness_ratio': memory_saved_gb / memory_before_gb,
            'within_target': overhead_ms < 10.0  # 10ms target
        }
```

## 4. Data Structures

### 4.1 GPU-Resident State Tensor with C-022 11-State Support

```python
class GPUStateTensor:
    """GPU-resident state management for C-022 11-state seed lifecycle"""

    def __init__(self, num_seeds: int, device: str = 'cuda'):
        self.device = device
        self.num_seeds = num_seeds

        # Shape: (num_seeds, state_variables)
        # Optimized for GPU memory layout
        self.state_tensor = torch.zeros(
            (num_seeds, 10),  # C-022: Expanded for 11-state system
            dtype=torch.int32,
            device=device,
            memory_format=torch.contiguous_format
        )

        # Column definitions for state tensor (C-022 11-state):
        self.STATE_COLUMNS = {
            'LIFECYCLE_STAGE': 0,      # 0-10 for 11 states (C-022)
            'BLUEPRINT_ID': 1,         # Kernel artifact ID hash
            'EPOCHS_IN_STATE': 2,      # Counter for current stage
            'LAST_GATE': 3,            # C-022: Last gate passed (G1-G5)
            'ALPHA_BLEND': 4,          # 0-1000, scaled to 0.0-1.0
            'PERFORMANCE_GATE': 5,     # Threshold value (scaled)
            'EMBARGO_COUNTER': 6,      # Cooldown after CULLED
            'READY_FLAG': 7,           # 0/1 for transition readiness
            'REGION_ID': 8,            # C-022: GPU region for aggregation
            'GATE_SCORE': 9            # C-022: Gate evaluation score
        }

        # C-022: 11-state lifecycle enum
        self.LIFECYCLE_STATES = {
            'DORMANT': 0,
            'ISOLATED_INIT': 1,
            'COMPATIBILITY_CHECK': 2,
            'GRAFTING': 3,
            'STABILIZATION': 4,
            'ACTIVE': 5,
            'COOLDOWN': 6,
            'HARVESTING': 7,
            'RECYCLING': 8,
            'QUARANTINE': 9,
            'TERMINATED': 10
        }

    def update_seed_state(self,
                         seed_idx: int,
                         lifecycle_stage: str,
                         epochs_in_state: int = None,
                         last_gate: str = None) -> None:
        """Update seed state on GPU tensor with C-022 11-state support"""

        # Update lifecycle stage using C-022 11-state values
        stage_value = self.LIFECYCLE_STATES.get(lifecycle_stage, 0)
        self.state_tensor[seed_idx, self.STATE_COLUMNS['LIFECYCLE_STAGE']] = stage_value

        # Update epochs in state if provided
        if epochs_in_state is not None:
            self.state_tensor[seed_idx, self.STATE_COLUMNS['EPOCHS_IN_STATE']] = epochs_in_state

        # C-022: Update gate information
        if last_gate is not None:
            gate_map = {'G1': 1, 'G2': 2, 'G3': 3, 'G4': 4, 'G5': 5}
            self.state_tensor[seed_idx, self.STATE_COLUMNS['LAST_GATE']] = gate_map.get(last_gate, 0)

    def get_ready_seeds(self) -> torch.Tensor:
        """Get indices of seeds ready for state transition"""
        ready_flags = self.state_tensor[:, self.STATE_COLUMNS['READY_FLAG']]
        return torch.nonzero(ready_flags, as_tuple=False).squeeze(-1)

    def batch_state_update(self, updates: List[Tuple[int, str]]) -> None:
        """Efficient batch update of multiple seed states"""

        if not updates:
            return

        # Convert updates to tensors for vectorized operation
        seed_indices = torch.tensor([idx for idx, _ in updates], device=self.device)
        new_stages = torch.tensor(
            [self.LIFECYCLE_STATES.get(stage, 0) for _, stage in updates],
            device=self.device
        )

        # Vectorized update
        self.state_tensor[seed_indices, self.STATE_COLUMNS['LIFECYCLE_STAGE']] = new_stages
```

## 5. Integration Contract

This component integrates with the main Kasmina architecture by providing:

### 5.1 Kernel Management Interface with C-024 KD Support

```python
@dataclass
class KernelExecutionContract:
    """Interface contract for kernel execution component with C-022 enhancements and C-024 KD"""

    # Required methods that must be implemented
    async def load_kernel(self, kernel_artifact_id: str) -> GPUKernel
    async def execute_kernel(self, kernel: GPUKernel, input_tensor: torch.Tensor) -> torch.Tensor
    def cache_kernel(self, kernel_artifact_id: str, kernel: GPUKernel) -> None
    def evict_kernel(self, kernel_artifact_id: str) -> bool

    # C-024: Knowledge distillation methods
    async def load_kernel_with_teacher(self, kernel_artifact_id: str) -> Tuple[GPUKernel, Optional[torch.Tensor]]
    def get_teacher_predictions(self, input_batch: torch.Tensor) -> Optional[torch.Tensor]
    def get_checkpoint_effectiveness(self) -> Dict[str, float]

    # Leyline integration methods
    async def handle_leyline_command(self, command: AdaptationCommand) -> bool
    def export_leyline_telemetry(self) -> TelemetryPacket

    # C-022: Security and monitoring methods
    def verify_message_auth(self, message: Any) -> bool
    def register_gradient_monitors(self, host_model: nn.Module, seed_model: nn.Module) -> None
    def check_gradient_isolation(self) -> bool

    # C-022: Optimizer coordination
    async def handle_optimizer_command(self, command: OptimizerCommand) -> bool

    # Performance validation methods
    def validate_performance_targets(self) -> Dict[str, bool]
    def get_performance_metrics(self) -> Dict[str, float]
```

### 5.2 Component Coordination

This component coordinates with other Kasmina components:

- **[02.2-kasmina-memory-pools.md](./02.2-kasmina-memory-pools.md)**: GPU memory coordination and cache management + C-024 teacher memory
- **[02.3-kasmina-parameter-registration.md](./02.3-kasmina-parameter-registration.md)**: Parameter isolation enforcement with C-022 optimizer migration + C-024 teacher params
- **[02.4-kasmina-safety-mechanisms.md](./02.4-kasmina-safety-mechanisms.md)**: Circuit breaker integration for gradient violations + C-024 checkpoint failures
- **[02.5-kasmina-performance-validation.md](./02.5-kasmina-performance-validation.md)**: Comprehensive performance testing and validation + C-024 KD metrics
- **C-022 Distributed Coordination**: Epoch-aligned barriers and Byzantine detection

## 6. References

- **Parent Document**: [02-kasmina-unified-design.md](./02-kasmina-unified-design.md)
- **Memory Pools**: [02.2-kasmina-memory-pools.md](./02.2-kasmina-memory-pools.md)
- **Parameter Registration**: [02.3-kasmina-parameter-registration.md](./02.3-kasmina-parameter-registration.md)
- **Safety Mechanisms**: [02.4-kasmina-safety-mechanisms.md](./02.4-kasmina-safety-mechanisms.md)
- **Performance Validation**: [02.5-kasmina-performance-validation.md](./02.5-kasmina-performance-validation.md)
- **Leyline Contracts**: [00-leyline-shared-contracts.md](./00-leyline-shared-contracts.md)
- **C-018 Final Consensus**: Option B (Performance-First) implementation
- **C-022 Production Hardening**: Critical gradient isolation and security enhancements
- **C-024 KD Amendment**: Gradient checkpointing for teacher models
- **Conclave C-004**: Gradient Isolation mathematical formulation
- **ADR-010**: Service Boundary Architecture

---

**COMPONENT STATUS**: COMPLETE - C-022 Production Hardened + C-024 KD Enhanced
**Version**: 4.0 (Major update from 3.3)
**Core Functionality**: Kernel loading, caching, and enhanced gradient isolation
**C-022 Enhancements**: Backward hook monitoring, HMAC authentication, 11-state support
**C-024 Enhancements**: Checkpointed teacher integration, 14GB → 7GB memory optimization
**Integration Points**: Fully coordinated with memory management and safety systems
**Next Steps**: Production deployment with enhanced monitoring