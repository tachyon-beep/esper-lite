# 13.1 Elesh Importance Tracking - Enhanced Count-Min Sketch Implementation

## Document Metadata

| Field | Value |
|-------|-------|
| **Version** | 3.0 - Structured Pruning Enhancement |
| **Status** | APPROVED |
| **Date** | 2025-01-14 |
| **Author** | C-020 Round 6 Algorithm Specialist |
| **Parent** | 13-elesh-unified-design.md |
| **Purpose** | Multi-Level Importance Tracking with Enhanced Offline Analysis |

## Executive Summary

This document specifies the enhanced Count-Min Sketch implementation for Elesh's multi-level importance tracking system. The C-020 structured pruning design extends basic parameter importance to comprehensive structural analysis covering channels, attention heads, and layers with enhanced offline accuracy through larger probabilistic data structures.

**Key Innovation**: Transforms importance tracking from runtime-constrained approximation to comprehensive offline analysis with unlimited compute budget during checkpoint saves.

## Enhanced Count-Min Sketch Architecture

### Offline Analysis Benefits

The checkpoint-based approach enables significantly enhanced Count-Min Sketch parameters for improved accuracy:

```python
class OfflineImportanceTracker:
    """
    Enhanced importance tracking with offline compute budget

    C-020 ENHANCEMENT: 10x larger sketches with improved collision resistance
    """

    def __init__(self, num_params: int, analysis_type: str = "multi_level"):
        # Enhanced parameters for offline analysis (10x runtime improvement)
        self.sketch_width = max(100000, math.ceil(num_params / 100))   # 10x larger than runtime
        self.sketch_depth = max(10, math.ceil(math.log(1 / 0.0001)))   # Higher accuracy target (99.99%)

        # Multi-level tracking for structured pruning
        self.analysis_levels = ["channel", "attention_head", "layer"] if analysis_type == "multi_level" else ["parameter"]

        # Memory allocation (acceptable offline)
        self.analysis_memory_mb = self.sketch_width * self.sketch_depth * 4 / 1024 / 1024

        logger.info(f"Enhanced offline analysis: {self.sketch_width}x{self.sketch_depth} sketch, "
                   f"{self.analysis_memory_mb:.1f}MB memory, {len(self.analysis_levels)} levels")
```

### Multi-Level Importance Calculation

```python
def calculate_multi_level_importance(
    self,
    layer: nn.Module,
    activations: torch.Tensor,
    gradients: torch.Tensor,
    config: Dict[str, float]
) -> Dict[str, torch.Tensor]:
    """
    Comprehensive importance calculation at multiple structural levels

    Args:
        layer: Neural network layer to analyze
        activations: Forward pass activations [batch, ...]
        gradients: Backward pass gradients [batch, ...]
        config: Analysis configuration parameters

    Returns:
        Multi-level importance scores for different structural elements
    """
    importance_results = {}

    # 1. Channel-Level Importance (for Conv2d, Linear layers)
    if isinstance(layer, (nn.Conv2d, nn.Linear)):
        importance_results["channel"] = self._calculate_channel_importance(
            layer, activations, gradients, config
        )

    # 2. Attention Head Importance (for MultiheadAttention layers)
    if isinstance(layer, nn.MultiheadAttention):
        importance_results["attention_head"] = self._calculate_attention_head_importance(
            layer, activations, gradients, config
        )

    # 3. Layer-Level Importance (for all layers)
    importance_results["layer"] = self._calculate_layer_importance(
        layer, activations, gradients, config
    )

    return importance_results

def _calculate_channel_importance(
    self,
    layer: nn.Module,
    activations: torch.Tensor,
    gradients: torch.Tensor,
    config: Dict[str, float]
) -> Dict[str, torch.Tensor]:
    """
    Channel importance using Taylor expansion: |∂L/∂a_c · a_c|

    Enhanced with multi-metric scoring system:
    - Taylor importance: |gradient * activation|
    - Weight magnitude: L2 norm of channel weights
    - Activation frequency: Sparsity-aware activation rates
    - Channel correlation: Redundancy detection via cosine similarity
    """
    batch_size = activations.shape[0]

    if isinstance(layer, nn.Conv2d):
        # Convolutional layer channel analysis
        num_channels = activations.shape[1]

        # Taylor importance per channel
        taylor_scores = torch.abs(gradients * activations)
        taylor_importance = taylor_scores.mean(dim=(0, 2, 3))  # Average over batch, H, W

        # Weight magnitude per output channel
        weight_magnitude = torch.norm(layer.weight, dim=(1, 2, 3))  # L2 norm per channel

        # Activation frequency (sparsity-aware)
        activation_threshold = config.get('activation_threshold', 1e-3)
        activation_mask = torch.abs(activations) > activation_threshold
        activation_frequency = activation_mask.float().mean(dim=(0, 2, 3))

        # Channel correlation matrix for redundancy detection
        channel_correlations = self._calculate_channel_correlations(activations)

        return {
            "taylor_importance": taylor_importance,
            "weight_magnitude": weight_magnitude,
            "activation_frequency": activation_frequency,
            "channel_correlations": channel_correlations,
            "num_channels": num_channels
        }

    elif isinstance(layer, nn.Linear):
        # Linear layer channel analysis
        num_features = activations.shape[-1]

        # Taylor importance per feature
        taylor_scores = torch.abs(gradients * activations)
        taylor_importance = taylor_scores.mean(dim=0)  # Average over batch

        # Weight magnitude per output feature
        weight_magnitude = torch.norm(layer.weight, dim=0)

        # Activation frequency
        activation_threshold = config.get('activation_threshold', 1e-3)
        activation_mask = torch.abs(activations) > activation_threshold
        activation_frequency = activation_mask.float().mean(dim=0)

        return {
            "taylor_importance": taylor_importance,
            "weight_magnitude": weight_magnitude,
            "activation_frequency": activation_frequency,
            "num_features": num_features
        }

def _calculate_channel_correlations(self, activations: torch.Tensor) -> torch.Tensor:
    """
    Calculate channel correlation matrix for redundancy detection

    Args:
        activations: [batch, channels, height, width] for Conv2d

    Returns:
        Correlation matrix [channels, channels]
    """
    batch_size, num_channels, height, width = activations.shape

    # Flatten spatial dimensions
    activations_flat = activations.reshape(batch_size, num_channels, -1)

    # Calculate mean activation per channel
    channel_vectors = activations_flat.mean(dim=0)  # [channels, H*W]

    # Normalize for cosine similarity
    channel_vectors_norm = torch.nn.functional.normalize(channel_vectors, dim=1)

    # Compute correlation matrix
    correlation = torch.matmul(channel_vectors_norm, channel_vectors_norm.t())

    return correlation

def _calculate_attention_head_importance(
    self,
    layer: nn.MultiheadAttention,
    activations: Dict[str, torch.Tensor],
    gradients: Dict[str, torch.Tensor],
    config: Dict[str, float]
) -> Dict[str, torch.Tensor]:
    """
    Attention head importance using pattern analysis

    Multi-factor scoring:
    - Attention entropy: Uniformity of attention patterns
    - Pattern diversity: Jensen-Shannon divergence from mean
    - Gradient sensitivity: Impact on loss function
    """
    # Extract attention weights from activations dict
    attention_weights = activations.get("attention_weights")  # [batch, num_heads, seq_len, seq_len]
    if attention_weights is None:
        return {}

    batch_size, num_heads, seq_len, _ = attention_weights.shape

    # 1. Attention entropy per head
    attention_entropy = self._calculate_attention_entropy(attention_weights)

    # 2. Pattern diversity using JS divergence
    pattern_diversity = self._calculate_pattern_diversity(attention_weights)

    # 3. Gradient sensitivity (approximation)
    head_gradients = gradients.get("attention_weights", torch.zeros_like(attention_weights))
    gradient_sensitivity = torch.abs(head_gradients * attention_weights).mean(dim=(0, 2, 3))

    # 4. Head similarity for redundancy detection
    head_similarities = self._calculate_head_similarities(attention_weights)

    return {
        "attention_entropy": attention_entropy,
        "pattern_diversity": pattern_diversity,
        "gradient_sensitivity": gradient_sensitivity,
        "head_similarities": head_similarities,
        "num_heads": num_heads
    }

def _calculate_attention_entropy(self, attention_weights: torch.Tensor) -> torch.Tensor:
    """Calculate entropy of attention distributions per head"""
    # Add small epsilon for numerical stability
    attention_weights = attention_weights + 1e-10

    # Calculate entropy: -∑ p * log(p)
    entropy = -torch.sum(attention_weights * torch.log(attention_weights), dim=-1)

    # Average over batch and sequence positions
    avg_entropy = entropy.mean(dim=(0, 2))  # [num_heads]

    return avg_entropy

def _calculate_pattern_diversity(self, attention_weights: torch.Tensor) -> torch.Tensor:
    """Calculate pattern diversity using Jensen-Shannon divergence"""
    batch_size, num_heads, seq_len, _ = attention_weights.shape

    diversity_scores = torch.zeros(num_heads)

    for h in range(num_heads):
        head_patterns = attention_weights[:, h, :, :].reshape(batch_size, -1)

        # Calculate mean pattern
        mean_pattern = head_patterns.mean(dim=0, keepdim=True)

        # JS divergence from mean
        js_divergences = []
        for b in range(batch_size):
            pattern = head_patterns[b:b+1]
            m = 0.5 * (pattern + mean_pattern)

            # KL divergences
            kl_pm = torch.nn.functional.kl_div(
                torch.log(pattern + 1e-10), m, reduction='sum'
            )
            kl_mp = torch.nn.functional.kl_div(
                torch.log(m + 1e-10), pattern, reduction='sum'
            )

            js_div = 0.5 * (kl_pm + kl_mp)
            js_divergences.append(js_div)

        diversity_scores[h] = torch.tensor(js_divergences).mean()

    return diversity_scores

def _calculate_head_similarities(self, attention_weights: torch.Tensor) -> torch.Tensor:
    """Calculate pairwise head similarities for redundancy detection"""
    num_heads = attention_weights.shape[1]

    # Flatten attention patterns per head
    patterns = attention_weights.mean(dim=0).reshape(num_heads, -1)  # [num_heads, seq_len^2]

    # Normalize for cosine similarity
    patterns_norm = torch.nn.functional.normalize(patterns, dim=1)

    # Compute similarity matrix
    similarity = torch.matmul(patterns_norm, patterns_norm.t())

    return similarity

def _calculate_layer_importance(
    self,
    layer: nn.Module,
    activations: torch.Tensor,
    gradients: torch.Tensor,
    config: Dict[str, float]
) -> Dict[str, float]:
    """
    Layer-level importance for potential removal

    Factors:
    - Taylor importance at layer level
    - Gradient flow strength
    - Input/output feature similarity
    - Skip connection potential
    """
    # Layer-level Taylor importance
    taylor_importance = torch.abs(gradients * activations).mean().item()

    # Gradient flow strength (if input gradients available)
    input_grad_norm = 0.0
    if hasattr(activations, 'grad') and activations.grad is not None:
        input_grad_norm = torch.norm(activations.grad).item()
    output_grad_norm = torch.norm(gradients).item()
    gradient_flow = output_grad_norm / (input_grad_norm + 1e-8)

    # Feature similarity (for skip connection potential)
    if activations.shape == gradients.shape:
        # Direct similarity possible
        cosine_sim = torch.nn.functional.cosine_similarity(
            activations.flatten(), gradients.flatten(), dim=0
        ).item()
        feature_similarity = cosine_sim
    else:
        # Dimensional mismatch - limited skip potential
        feature_similarity = 0.0

    return {
        "taylor_importance": taylor_importance,
        "gradient_flow": gradient_flow,
        "feature_similarity": feature_similarity,
        "can_skip": feature_similarity > config.get('skip_threshold', 0.8)
    }
```

## Enhanced Probabilistic Data Structure

### Count-Min Sketch Parameters

```python
@dataclass
class OfflineSketchConfig:
    """Configuration for enhanced offline Count-Min Sketch"""

    # Enhanced parameters for offline analysis
    sketch_width: int = 100000      # 10x larger than runtime (10K → 100K)
    sketch_depth: int = 10          # Enhanced depth for collision resistance
    hash_functions: int = 10        # Multiple hash functions

    # Accuracy targets
    epsilon: float = 0.0001         # Error tolerance (0.01%)
    delta: float = 0.001           # Failure probability (0.1%)

    # Memory allocation
    max_memory_mb: int = 500        # Acceptable offline memory usage

    # Multi-level tracking
    track_channels: bool = True
    track_attention_heads: bool = True
    track_layers: bool = True

    # Historical tracking
    importance_history_epochs: int = 500  # Long-term trend analysis
    ema_momentum: float = 0.99           # Exponential moving average

    def __post_init__(self):
        # Validate memory constraints
        estimated_memory = (self.sketch_width * self.sketch_depth * 4) / (1024 * 1024)
        if estimated_memory > self.max_memory_mb:
            logger.warning(f"Estimated memory {estimated_memory:.1f}MB exceeds limit {self.max_memory_mb}MB")
```

### Multi-Level Sketch Implementation

```python
class MultiLevelCountMinSketch:
    """
    Enhanced Count-Min Sketch supporting multi-level importance tracking

    C-020 INNOVATION: Separate sketches for channels, heads, and layers
    """

    def __init__(self, config: OfflineSketchConfig):
        self.config = config
        self.sketches = {}

        # Initialize separate sketches for each structural level
        if config.track_channels:
            self.sketches["channel"] = self._create_sketch("channel")

        if config.track_attention_heads:
            self.sketches["attention_head"] = self._create_sketch("attention_head")

        if config.track_layers:
            self.sketches["layer"] = self._create_sketch("layer")

        # Historical tracking for trend analysis
        self.importance_history = defaultdict(list)
        self.ema_estimates = {}

    def _create_sketch(self, level: str) -> torch.Tensor:
        """Create Count-Min Sketch tensor for specific structural level"""
        sketch = torch.zeros(
            (self.config.sketch_depth, self.config.sketch_width),
            dtype=torch.float32
        )

        logger.info(f"Created {level} sketch: {self.config.sketch_depth}x{self.config.sketch_width}")
        return sketch

    def update_importance(
        self,
        level: str,
        element_id: str,
        importance_score: float,
        epoch: int
    ):
        """Update importance score for structural element"""
        if level not in self.sketches:
            return

        sketch = self.sketches[level]

        # Hash element_id to sketch positions
        hash_positions = self._hash_element(element_id, level)

        # Update all hash positions (Count-Min Sketch property)
        for i, pos in enumerate(hash_positions):
            sketch[i, pos] += importance_score

        # Update EMA estimate
        ema_key = f"{level}:{element_id}"
        if ema_key not in self.ema_estimates:
            self.ema_estimates[ema_key] = importance_score
        else:
            self.ema_estimates[ema_key] = (
                self.config.ema_momentum * self.ema_estimates[ema_key] +
                (1 - self.config.ema_momentum) * importance_score
            )

        # Store in history for trend analysis
        self.importance_history[ema_key].append((epoch, importance_score))

        # Limit history size
        max_history = self.config.importance_history_epochs
        if len(self.importance_history[ema_key]) > max_history:
            self.importance_history[ema_key] = self.importance_history[ema_key][-max_history:]

    def query_importance(self, level: str, element_id: str) -> float:
        """Query importance estimate for structural element"""
        if level not in self.sketches:
            return 0.0

        sketch = self.sketches[level]
        hash_positions = self._hash_element(element_id, level)

        # Return minimum across all hash positions (Count-Min Sketch property)
        estimates = [sketch[i, pos].item() for i, pos in enumerate(hash_positions)]
        return min(estimates)

    def get_ema_importance(self, level: str, element_id: str) -> float:
        """Get EMA-smoothed importance estimate"""
        ema_key = f"{level}:{element_id}"
        return self.ema_estimates.get(ema_key, 0.0)

    def get_importance_trend(self, level: str, element_id: str, window: int = 50) -> Dict[str, float]:
        """Analyze importance trend over recent epochs"""
        ema_key = f"{level}:{element_id}"
        history = self.importance_history.get(ema_key, [])

        if len(history) < 2:
            return {"trend": 0.0, "stability": 0.0, "recent_avg": 0.0}

        # Get recent window
        recent_history = history[-window:] if len(history) > window else history
        recent_scores = [score for epoch, score in recent_history]

        # Calculate trend (simple linear regression)
        if len(recent_scores) > 1:
            x = torch.arange(len(recent_scores), dtype=torch.float32)
            y = torch.tensor(recent_scores, dtype=torch.float32)

            # Linear regression: y = mx + b
            mean_x, mean_y = x.mean(), y.mean()
            numerator = ((x - mean_x) * (y - mean_y)).sum()
            denominator = ((x - mean_x) ** 2).sum()

            trend = numerator / (denominator + 1e-8)

            # Calculate stability (inverse of variance)
            variance = y.var().item()
            stability = 1.0 / (1.0 + variance)

            return {
                "trend": trend.item(),
                "stability": stability,
                "recent_avg": y.mean().item(),
                "num_samples": len(recent_scores)
            }

        return {"trend": 0.0, "stability": 1.0, "recent_avg": recent_scores[-1]}

    def _hash_element(self, element_id: str, level: str) -> List[int]:
        """Hash element ID to sketch positions using multiple hash functions"""
        positions = []

        # Use different hash seeds for different levels and depths
        base_seed = hash(f"{level}:{element_id}")

        for depth in range(self.config.sketch_depth):
            # Create unique hash for each depth level
            seed = base_seed + depth * 1000007  # Large prime for good distribution
            hash_val = hash(f"{seed}:{element_id}")
            position = hash_val % self.config.sketch_width
            positions.append(position)

        return positions

    def get_memory_usage(self) -> Dict[str, float]:
        """Calculate memory usage of all sketches"""
        memory_usage = {}
        total_mb = 0.0

        for level, sketch in self.sketches.items():
            bytes_used = sketch.numel() * sketch.element_size()
            mb_used = bytes_used / (1024 * 1024)
            memory_usage[level] = mb_used
            total_mb += mb_used

        # Add EMA and history memory
        ema_memory = len(self.ema_estimates) * 8 / (1024 * 1024)  # 8 bytes per float
        history_memory = sum(len(h) * 16 for h in self.importance_history.values()) / (1024 * 1024)  # 16 bytes per (epoch, score)

        memory_usage["ema"] = ema_memory
        memory_usage["history"] = history_memory
        memory_usage["total"] = total_mb + ema_memory + history_memory

        return memory_usage
```

## Adaptive Threshold Selection

```python
class AdaptiveThresholdSelector:
    """
    Dynamic threshold selection based on importance distribution analysis

    C-020 ENHANCEMENT: Training phase-aware thresholds with safety constraints
    """

    def __init__(self, config: Dict[str, float]):
        self.config = config
        self.phase_thresholds = {
            "early": {"conservative": 0.001, "moderate": 0.01, "aggressive": 0.05},
            "mid": {"conservative": 0.005, "moderate": 0.02, "aggressive": 0.1},
            "late": {"conservative": 0.01, "moderate": 0.05, "aggressive": 0.2}
        }

    def select_threshold(
        self,
        importance_scores: torch.Tensor,
        training_phase: str,  # "early", "mid", "late"
        safety_level: str,    # "conservative", "moderate", "aggressive"
        target_sparsity: float = 0.1
    ) -> float:
        """
        Select optimal threshold based on importance distribution and training phase

        Args:
            importance_scores: Tensor of importance values
            training_phase: Current training phase
            safety_level: Required safety level
            target_sparsity: Target pruning ratio

        Returns:
            Optimal threshold for pruning decisions
        """
        # Get base threshold for phase and safety level
        base_threshold = self.phase_thresholds[training_phase][safety_level]

        # Analyze importance distribution
        sorted_scores, _ = torch.sort(importance_scores, descending=False)

        # Calculate quantile-based threshold
        quantile_idx = int(len(sorted_scores) * target_sparsity)
        quantile_threshold = sorted_scores[quantile_idx].item() if quantile_idx < len(sorted_scores) else sorted_scores[-1].item()

        # Statistical constraints
        mean_importance = importance_scores.mean().item()
        std_importance = importance_scores.std().item()

        # Conservative threshold: mean - 2*std
        conservative_threshold = max(0, mean_importance - 2 * std_importance)

        # Adaptive threshold: weighted combination
        weights = self.config.get('threshold_weights', {
            'base': 0.3,
            'quantile': 0.4,
            'conservative': 0.3
        })

        adaptive_threshold = (
            weights['base'] * base_threshold +
            weights['quantile'] * quantile_threshold +
            weights['conservative'] * conservative_threshold
        )

        # Ensure minimum threshold
        min_threshold = self.config.get('min_threshold', 1e-8)
        final_threshold = max(min_threshold, adaptive_threshold)

        return final_threshold
```

## Performance Metrics

### Accuracy Validation

```python
class ImportanceTrackingValidator:
    """Validate accuracy of importance tracking against ground truth"""

    def validate_channel_ranking(
        self,
        predicted_importance: torch.Tensor,
        ground_truth_importance: torch.Tensor
    ) -> Dict[str, float]:
        """Validate channel importance ranking accuracy"""

        # Kendall's Tau for ranking correlation
        kendall_tau = self._kendall_tau(predicted_importance, ground_truth_importance)

        # Spearman correlation
        spearman_corr = self._spearman_correlation(predicted_importance, ground_truth_importance)

        # Top-k precision (most important channels)
        top_k_precision = self._top_k_precision(predicted_importance, ground_truth_importance, k=20)

        # Mean Absolute Percentage Error
        mape = torch.abs((predicted_importance - ground_truth_importance) / (ground_truth_importance + 1e-8)).mean().item()

        return {
            "kendall_tau": kendall_tau,
            "spearman_correlation": spearman_corr,
            "top_20_precision": top_k_precision,
            "mape": mape,
            "accuracy_target_met": kendall_tau > 0.85 and mape < 0.05
        }
```

## Integration with Structured Pruning

```python
class StructuredImportanceIntegration:
    """Integration layer for structured pruning decision making"""

    def __init__(self, sketch: MultiLevelCountMinSketch, selector: AdaptiveThresholdSelector):
        self.sketch = sketch
        self.selector = selector

    def generate_pruning_recommendations(
        self,
        layer: nn.Module,
        layer_id: str,
        training_epoch: int,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate comprehensive pruning recommendations for all structural levels
        """
        recommendations = {}

        # Determine training phase
        training_phase = self._get_training_phase(training_epoch, config)
        safety_level = config.get('safety_level', 'conservative')

        # Channel-level recommendations
        if isinstance(layer, (nn.Conv2d, nn.Linear)):
            channel_importance = self._get_channel_importance(layer_id)
            channel_threshold = self.selector.select_threshold(
                channel_importance, training_phase, safety_level,
                config.get('channel_target_sparsity', 0.1)
            )

            recommendations["channels"] = {
                "importance_scores": channel_importance,
                "threshold": channel_threshold,
                "pruning_candidates": (channel_importance < channel_threshold).nonzero().flatten().tolist(),
                "safety_margin": config.get('channel_safety_margin', 0.1)
            }

        # Attention head recommendations
        if isinstance(layer, nn.MultiheadAttention):
            head_importance = self._get_attention_head_importance(layer_id)
            head_threshold = self.selector.select_threshold(
                head_importance, training_phase, safety_level,
                config.get('head_target_sparsity', 0.2)
            )

            recommendations["attention_heads"] = {
                "importance_scores": head_importance,
                "threshold": head_threshold,
                "pruning_candidates": (head_importance < head_threshold).nonzero().flatten().tolist(),
                "redundancy_groups": self._get_head_redundancy_groups(layer_id),
                "safety_margin": config.get('head_safety_margin', 0.15)
            }

        # Layer-level recommendations
        layer_importance = self.sketch.get_ema_importance("layer", layer_id)
        layer_trend = self.sketch.get_importance_trend("layer", layer_id)

        recommendations["layer"] = {
            "importance_score": layer_importance,
            "trend_analysis": layer_trend,
            "can_remove": layer_importance < config.get('layer_removal_threshold', 0.001),
            "skip_potential": layer_trend.get("stability", 0.0) > 0.8,
            "safety_margin": config.get('layer_safety_margin', 0.2)
        }

        return recommendations
```

## Cross-References

- **Parent Document**: [13-elesh-unified-design.md] - Main Elesh architecture
- **Related Algorithm**: [13.2-elesh-analysis-algorithms.md] - Structured pruning algorithms
- **Message Contracts**: [00-leyline-shared-contracts.md] - Importance data contracts
- **Integration**: [12-emrakul-unified-design.md] - Strategic coordination

---

*Last Updated: 2025-01-14 | Version: 3.0 | Status: PRODUCTION READY*