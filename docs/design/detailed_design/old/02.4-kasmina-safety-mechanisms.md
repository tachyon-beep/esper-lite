# Kasmina - Safety Mechanisms and Production Controls

**Parent Document**: [02-kasmina-unified-design.md](./02-kasmina-unified-design.md)
**Component Type**: System|Safety
**Version**: 3.3
**Status**: PRODUCTION - Critical Safety Controls + Leyline Integration + C-024 Checkpoint Safety
**C-024 Updates**: Checkpoint recompilation circuit breaker, teacher memory overflow protection, torch.compile stability monitoring

---

## Overview

This component provides comprehensive safety mechanisms and production control systems for Kasmina. It implements circuit breaker patterns to replace ALL assert-based crashes, hardware-aware timing constraints, and enhanced pause semantics with identity kernels for production stability.

**CRITICAL IMPORTANCE**: These safety mechanisms prevent the production-killing issues identified in C-016 Emergency Response:
- Assert-based crashes requiring immediate circuit breaker replacement
- Hardware timing failures across different GPU architectures
- Uncontrolled pause states causing training disruption
- C-024: Checkpoint recompilation failures and teacher model OOM

**Leyline Integration**: All safety events and circuit breaker activations are reported through Leyline contracts with optimal performance.

## 1. Circuit Breaker Implementation

### 1.1 Circuit Breaker System with C-024 Checkpoint Protection

```python
import time
from enum import Enum
from typing import Optional, Callable, Any
from dataclasses import dataclass

class CircuitBreakerState(Enum):
    CLOSED = "closed"        # Normal operation
    OPEN = "open"           # Circuit breaker tripped
    HALF_OPEN = "half_open" # Testing recovery

@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5
    timeout_ms: int = 60000  # All timing uses _ms suffix
    success_threshold: int = 3

class MonotonicTimer:
    """Monotonic timer for timing validation"""

    @staticmethod
    def current_time_ms() -> int:
        """Get current time in milliseconds using monotonic clock"""
        return int(time.monotonic() * 1000)

    @staticmethod
    def elapsed_ms(start_time_ms: int) -> int:
        """Calculate elapsed time in milliseconds"""
        return MonotonicTimer.current_time_ms() - start_time_ms

class KasminaCircuitBreaker:
    """Production-grade circuit breaker to replace assert statements"""

    def __init__(self, name: str, config: CircuitBreakerConfig):
        self.name = name
        self.config = config
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time_ms = 0
        self.timer = MonotonicTimer()

        # Telemetry tracking
        self.total_calls = 0
        self.total_failures = 0
        self.total_successes = 0
        self.state_transitions = []

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

    def call(self, func: Callable[[], Any]) -> Optional[Any]:
        """Call function through circuit breaker protection"""

        self.total_calls += 1
        current_time_ms = self.timer.current_time_ms()

        # Check circuit breaker state
        if self.state == CircuitBreakerState.OPEN:
            # Check if timeout has elapsed
            if self.timer.elapsed_ms(self.last_failure_time_ms) >= self.config.timeout_ms:
                self._transition_to_half_open(current_time_ms)
            else:
                # Circuit still open - return None instead of executing
                return None

        if self.state == CircuitBreakerState.HALF_OPEN:
            # Limited testing in half-open state
            if self.success_count >= self.config.success_threshold:
                self._transition_to_closed(current_time_ms)

        # Execute function
        try:
            result = func()
            self._record_success(current_time_ms)
            return result

        except Exception as e:
            self._record_failure(current_time_ms, str(e))
            return None

    def _record_success(self, timestamp_ms: int) -> None:
        """Record successful execution"""
        self.total_successes += 1

        if self.state == CircuitBreakerState.HALF_OPEN:
            self.success_count += 1

        # Reset failure count on success
        self.failure_count = 0

    def _record_failure(self, timestamp_ms: int, error: str) -> None:
        """Record failed execution"""
        self.total_failures += 1
        self.failure_count += 1
        self.last_failure_time_ms = timestamp_ms

        # Reset success count on failure
        self.success_count = 0

        # Check if we should open the circuit
        if (self.state == CircuitBreakerState.CLOSED and
            self.failure_count >= self.config.failure_threshold):
            self._transition_to_open(timestamp_ms)

        elif self.state == CircuitBreakerState.HALF_OPEN:
            # Any failure in half-open immediately opens circuit
            self._transition_to_open(timestamp_ms)

        # Report failure to Leyline
        self._report_failure(error, timestamp_ms)

    def _transition_to_open(self, timestamp_ms: int) -> None:
        """Transition circuit breaker to OPEN state"""
        old_state = self.state
        self.state = CircuitBreakerState.OPEN
        self.state_transitions.append((old_state, self.state, timestamp_ms))

        # Report state transition to Leyline
        self._report_state_transition(old_state, self.state, timestamp_ms)

    def _transition_to_half_open(self, timestamp_ms: int) -> None:
        """Transition circuit breaker to HALF_OPEN state"""
        old_state = self.state
        self.state = CircuitBreakerState.HALF_OPEN
        self.success_count = 0
        self.state_transitions.append((old_state, self.state, timestamp_ms))

        # Report state transition to Leyline
        self._report_state_transition(old_state, self.state, timestamp_ms)

    def _transition_to_closed(self, timestamp_ms: int) -> None:
        """Transition circuit breaker to CLOSED state"""
        old_state = self.state
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.state_transitions.append((old_state, self.state, timestamp_ms))

        # Report state transition to Leyline
        self._report_state_transition(old_state, self.state, timestamp_ms)

    def get_stats(self) -> Dict[str, Any]:
        """Get circuit breaker statistics"""
        success_rate = (self.total_successes / self.total_calls) if self.total_calls > 0 else 0.0

        return {
            'name': self.name,
            'state': self.state.value,
            'total_calls': self.total_calls,
            'total_successes': self.total_successes,
            'total_failures': self.total_failures,
            'current_failure_count': self.failure_count,
            'current_success_count': self.success_count,
            'success_rate': success_rate,
            'state_transition_count': len(self.state_transitions),
            'last_failure_time_ms': self.last_failure_time_ms
        }

    def _report_failure(self, error: str, timestamp_ms: int) -> None:
        """Report failure to Leyline telemetry"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"circuit_breaker_failure_{self.name}_{timestamp_ms}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add failure event
        event = telemetry.events.add()
        event.event_name = "circuit_breaker_failure"
        event.severity = TelemetryLevel.TELEMETRY_ERROR
        event.message = f"Circuit breaker {self.name} recorded failure: {error}"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes (C-018 Option B)
        event.attributes["circuit_breaker_name"] = self.name
        event.attributes["error"] = error
        event.attributes["failure_count"] = str(self.failure_count)
        event.attributes["current_state"] = self.state.value

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_state_transition(self, old_state: CircuitBreakerState, new_state: CircuitBreakerState, timestamp_ms: int) -> None:
        """Report state transition to Leyline telemetry"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"circuit_breaker_transition_{self.name}_{timestamp_ms}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add transition event
        event = telemetry.events.add()
        event.event_name = "circuit_breaker_state_transition"
        event.severity = TelemetryLevel.TELEMETRY_WARN
        event.message = f"Circuit breaker {self.name} transitioned from {old_state.value} to {new_state.value}"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["circuit_breaker_name"] = self.name
        event.attributes["old_state"] = old_state.value
        event.attributes["new_state"] = new_state.value
        event.attributes["failure_count"] = str(self.failure_count)

        self.telemetry_reporter.send_telemetry_async(telemetry)

# Global circuit breakers for common Kasmina operations
gradient_isolation_breaker = KasminaCircuitBreaker(
    "gradient_isolation",
    CircuitBreakerConfig(failure_threshold=3, timeout_ms=30000)
)

memory_bounds_breaker = KasminaCircuitBreaker(
    "memory_bounds",
    CircuitBreakerConfig(failure_threshold=5, timeout_ms=60000)
)

kernel_loading_breaker = KasminaCircuitBreaker(
    "kernel_loading",
    CircuitBreakerConfig(failure_threshold=10, timeout_ms=30000)
)

# C-024: Circuit breaker for checkpoint recompilation failures
checkpoint_recompilation_breaker = KasminaCircuitBreaker(
    "checkpoint_recompilation",
    CircuitBreakerConfig(failure_threshold=3, timeout_ms=120000)  # 2 minute timeout
)

# C-024: Circuit breaker for teacher memory overflow
teacher_memory_breaker = KasminaCircuitBreaker(
    "teacher_memory_overflow",
    CircuitBreakerConfig(failure_threshold=2, timeout_ms=180000)  # 3 minute timeout
)

def safe_assert_replacement(condition: bool, message: str, circuit_breaker: KasminaCircuitBreaker) -> bool:
    """Replace assert with circuit breaker pattern"""

    def check_condition():
        if not condition:
            raise AssertionError(message)
        return True

    result = circuit_breaker.call(check_condition)
    return result is True
```

### 1.2 C-024 Checkpoint Safety Manager

```python
class CheckpointSafetyManager:
    """C-024: Manage checkpoint-related safety mechanisms"""

    def __init__(self):
        self.checkpoint_breaker = checkpoint_recompilation_breaker
        self.teacher_memory_breaker = teacher_memory_breaker
        self.recompilation_count = 0
        self.max_recompilations = 5  # Per session
        self.checkpoint_overhead_ms = []
        self.acceptable_overhead_ratio = 0.20  # 20% overhead acceptable

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

    def monitor_checkpoint_recompilation(self) -> bool:
        """C-024: Monitor torch.compile recompilation with checkpointing"""

        def check_recompilation():
            self.recompilation_count += 1

            if self.recompilation_count > self.max_recompilations:
                raise RuntimeError(
                    f"Excessive checkpoint recompilations: {self.recompilation_count} > {self.max_recompilations}"
                )

            # Report recompilation
            self._report_checkpoint_recompilation()
            return True

        return self.checkpoint_breaker.call(check_recompilation)

    def validate_checkpoint_overhead(self, forward_time_ms: float, checkpoint_time_ms: float) -> bool:
        """C-024: Validate checkpoint overhead is within acceptable limits"""

        overhead_ratio = (checkpoint_time_ms - forward_time_ms) / forward_time_ms if forward_time_ms > 0 else 0
        self.checkpoint_overhead_ms.append(checkpoint_time_ms)

        if overhead_ratio > self.acceptable_overhead_ratio:
            # Report excessive overhead
            self._report_excessive_checkpoint_overhead(overhead_ratio)

            # Trigger circuit breaker if pattern continues
            def check_overhead():
                if overhead_ratio > 0.30:  # 30% is critical
                    raise RuntimeError(f"Critical checkpoint overhead: {overhead_ratio:.1%}")
                return False

            return self.checkpoint_breaker.call(check_overhead)

        return True

    def monitor_teacher_memory(self, current_usage_gb: float, limit_gb: float = 7.0) -> bool:
        """C-024: Monitor teacher model memory usage with checkpointing"""

        def check_memory():
            if current_usage_gb > limit_gb:
                raise MemoryError(
                    f"Teacher memory exceeded limit: {current_usage_gb:.1f}GB > {limit_gb}GB"
                )

            # Warning threshold at 90%
            if current_usage_gb > (limit_gb * 0.9):
                self._report_teacher_memory_warning(current_usage_gb, limit_gb)

            return True

        return self.teacher_memory_breaker.call(check_memory)

    def handle_checkpoint_failure(self, error: Exception) -> bool:
        """C-024: Handle checkpoint-related failures with fallback"""

        error_type = type(error).__name__
        error_msg = str(error)

        # Determine if recoverable
        recoverable_errors = [
            "RuntimeError",  # torch.compile issues
            "AssertionError",  # use_reentrant issues
            "ValueError"  # configuration issues
        ]

        if error_type in recoverable_errors:
            # Attempt recovery
            self._report_checkpoint_recovery_attempt(error_type, error_msg)

            # Apply fallback (disable checkpointing temporarily)
            return self._apply_checkpoint_fallback()

        # Non-recoverable - let circuit breaker handle
        return False

    def _apply_checkpoint_fallback(self) -> bool:
        """C-024: Apply fallback mechanism when checkpointing fails"""

        # Report fallback activation
        self._report_checkpoint_fallback()

        # Fallback options:
        # 1. Disable checkpointing temporarily
        # 2. Reduce checkpoint segments
        # 3. Switch to CPU offloading
        # Return True to continue, False to halt

        return True

    def get_checkpoint_safety_stats(self) -> Dict[str, Any]:
        """C-024: Get checkpoint safety statistics"""

        import numpy as np
        avg_overhead = np.mean(self.checkpoint_overhead_ms) if self.checkpoint_overhead_ms else 0

        return {
            'recompilation_count': self.recompilation_count,
            'max_recompilations': self.max_recompilations,
            'avg_checkpoint_overhead_ms': avg_overhead,
            'acceptable_overhead_ratio': self.acceptable_overhead_ratio,
            'checkpoint_breaker_state': self.checkpoint_breaker.state.value,
            'teacher_memory_breaker_state': self.teacher_memory_breaker.state.value
        }

    def _report_checkpoint_recompilation(self) -> None:
        """C-024: Report checkpoint recompilation to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"checkpoint_recompilation_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        event = telemetry.events.add()
        event.event_name = "checkpoint_recompilation"
        event.severity = TelemetryLevel.TELEMETRY_WARN
        event.message = f"Checkpoint recompilation #{self.recompilation_count}"
        event.timestamp.GetCurrentTime()

        event.attributes["recompilation_count"] = str(self.recompilation_count)
        event.attributes["max_allowed"] = str(self.max_recompilations)

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_excessive_checkpoint_overhead(self, overhead_ratio: float) -> None:
        """C-024: Report excessive checkpoint overhead to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"checkpoint_overhead_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        event = telemetry.events.add()
        event.event_name = "excessive_checkpoint_overhead"
        event.severity = TelemetryLevel.TELEMETRY_WARN
        event.message = f"Checkpoint overhead {overhead_ratio:.1%} exceeds limit"
        event.timestamp.GetCurrentTime()

        event.attributes["overhead_ratio"] = str(overhead_ratio)
        event.attributes["acceptable_ratio"] = str(self.acceptable_overhead_ratio)

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_teacher_memory_warning(self, current_gb: float, limit_gb: float) -> None:
        """C-024: Report teacher memory warning to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"teacher_memory_warning_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        event = telemetry.events.add()
        event.event_name = "teacher_memory_warning"
        event.severity = TelemetryLevel.TELEMETRY_WARN
        event.message = f"Teacher memory approaching limit: {current_gb:.1f}/{limit_gb}GB"
        event.timestamp.GetCurrentTime()

        event.attributes["current_usage_gb"] = str(current_gb)
        event.attributes["limit_gb"] = str(limit_gb)
        event.attributes["usage_ratio"] = str(current_gb / limit_gb)

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_checkpoint_fallback(self) -> None:
        """C-024: Report checkpoint fallback activation"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"checkpoint_fallback_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        event = telemetry.events.add()
        event.event_name = "checkpoint_fallback_activated"
        event.severity = TelemetryLevel.TELEMETRY_ERROR
        event.message = "Checkpoint fallback mechanism activated"
        event.timestamp.GetCurrentTime()

        event.attributes["recompilation_count"] = str(self.recompilation_count)

        self.telemetry_reporter.send_telemetry_async(telemetry)
```

## 2. Hardware-Aware Timing System

### 2.1 Hardware Timing Profiles with C-024 Checkpoint Constraints

```python
import time
import platform
from typing import Dict, Optional
from dataclasses import dataclass

@dataclass
class HardwareTimingProfile:
    """Hardware-specific timing profiles with C-024 checkpoint constraints"""
    epoch_boundary_ms: int = 18      # Hardware-aware 18ms epoch boundary
    gpu_kernel_launch_overhead_ms: float = 0.02  # 20μs
    pcie_transfer_latency_ms: float = 0.01       # 10μs
    memory_allocation_overhead_ms: float = 0.1   # 100μs

    # C-024: Checkpoint-specific timing constraints
    checkpoint_forward_overhead_ms: float = 2.0  # Expected checkpoint overhead
    teacher_loading_timeout_ms: int = 5000       # 5 seconds to load teacher
    checkpoint_recompilation_timeout_ms: int = 10000  # 10 seconds for recompilation

    # Hardware-specific adjustments
    cpu_architecture: str = "unknown"
    gpu_architecture: str = "unknown"
    timing_multiplier: float = 1.0  # Adjust all timings by this factor

class HardwareAwareTimingValidator:
    """Validate timing constraints with hardware awareness and C-024 checkpoint support"""

    def __init__(self):
        self.hardware_profile = self._detect_hardware_profile()

        # C-024: Checkpoint timing tracker
        self.checkpoint_safety_manager = CheckpointSafetyManager()

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

        # Report detected hardware profile
        self._report_hardware_profile()

    def _detect_hardware_profile(self) -> HardwareTimingProfile:
        """Detect hardware characteristics and create timing profile"""

        profile = HardwareTimingProfile()

        # Detect CPU architecture
        try:
            cpu_info = platform.processor()
            if 'Intel' in cpu_info or 'AMD' in cpu_info:
                profile.cpu_architecture = cpu_info
        except:
            pass

        # Detect GPU if available
        try:
            import torch
            if torch.cuda.is_available():
                profile.gpu_architecture = torch.cuda.get_device_name(0)

                # Adjust timing for different GPU generations
                if 'A100' in profile.gpu_architecture:
                    profile.timing_multiplier = 0.8  # Faster
                    # C-024: A100 specific checkpoint timing
                    profile.checkpoint_forward_overhead_ms = 1.5
                elif 'V100' in profile.gpu_architecture:
                    profile.timing_multiplier = 1.2  # Slower
                    profile.checkpoint_forward_overhead_ms = 2.5
                elif 'RTX' in profile.gpu_architecture:
                    profile.timing_multiplier = 1.0  # Baseline
                    profile.checkpoint_forward_overhead_ms = 2.0
        except:
            pass

        return profile

    def validate_checkpoint_timing(self, checkpoint_time_ms: float, base_time_ms: float) -> bool:
        """C-024: Validate checkpoint timing constraints"""

        # Calculate overhead
        overhead_ms = checkpoint_time_ms - base_time_ms
        expected_overhead = self.hardware_profile.checkpoint_forward_overhead_ms

        # Adjust for hardware
        adjusted_expected = expected_overhead * self.hardware_profile.timing_multiplier

        # Allow 20% variance
        max_acceptable = adjusted_expected * 1.2

        if overhead_ms > max_acceptable:
            # Report to checkpoint safety manager
            return self.checkpoint_safety_manager.validate_checkpoint_overhead(
                base_time_ms, checkpoint_time_ms
            )

        return True

    def validate_teacher_loading_time(self, loading_time_ms: float) -> bool:
        """C-024: Validate teacher model loading time"""

        timeout = self.hardware_profile.teacher_loading_timeout_ms

        if loading_time_ms > timeout:
            logger.error(f"Teacher loading timeout: {loading_time_ms}ms > {timeout}ms")
            self._report_teacher_loading_timeout(loading_time_ms, timeout)
            return False

        return True

    def validate_timing_constraint(self,
                                 actual_duration_ms: float,
                                 constraint_ms: float,
                                 operation_name: str) -> bool:
        """Validate timing constraint with hardware adjustment"""

        # Adjust constraint based on hardware profile
        adjusted_constraint = constraint_ms * self.hardware_profile.timing_multiplier

        validation_passed = actual_duration_ms <= adjusted_constraint

        if not validation_passed:
            # Report timing violation
            logger.warning(
                f"Timing constraint violation for {operation_name}: "
                f"{actual_duration_ms:.2f}ms > {adjusted_constraint:.2f}ms "
                f"(hardware profile: {self.hardware_profile.cpu_architecture})"
            )

            # Report timing violation to Leyline
            self._report_timing_violation(operation_name, actual_duration_ms, constraint_ms)

        return validation_passed

    def _report_hardware_profile(self) -> None:
        """Report detected hardware profile to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"hardware_profile_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add hardware profile event
        event = telemetry.events.add()
        event.event_name = "hardware_profile_detected"
        event.severity = TelemetryLevel.TELEMETRY_INFO
        event.message = f"Hardware timing profile established"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes (C-018 Option B)
        event.attributes["cpu_architecture"] = self.hardware_profile.cpu_architecture
        event.attributes["gpu_architecture"] = self.hardware_profile.gpu_architecture
        event.attributes["timing_multiplier"] = str(self.hardware_profile.timing_multiplier)
        event.attributes["epoch_boundary_ms"] = str(self.hardware_profile.epoch_boundary_ms)
        # C-024: Checkpoint timing attributes
        event.attributes["checkpoint_overhead_ms"] = str(self.hardware_profile.checkpoint_forward_overhead_ms)
        event.attributes["teacher_loading_timeout_ms"] = str(self.hardware_profile.teacher_loading_timeout_ms)

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_teacher_loading_timeout(self, actual_ms: float, timeout_ms: int) -> None:
        """C-024: Report teacher loading timeout to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"teacher_loading_timeout_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        event = telemetry.events.add()
        event.event_name = "teacher_loading_timeout"
        event.severity = TelemetryLevel.TELEMETRY_ERROR
        event.message = f"Teacher model loading exceeded timeout"
        event.timestamp.GetCurrentTime()

        event.attributes["loading_time_ms"] = str(actual_ms)
        event.attributes["timeout_ms"] = str(timeout_ms)
        event.attributes["gpu_architecture"] = self.hardware_profile.gpu_architecture

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_timing_violation(self, operation_name: str,
                               actual_ms: float, constraint_ms: float) -> None:
        """Report timing constraint violation to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"timing_violation_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add timing violation event
        event = telemetry.events.add()
        event.event_name = "timing_constraint_violation"
        event.severity = TelemetryLevel.TELEMETRY_WARN
        event.message = f"Timing violation: {operation_name} exceeded constraint"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["operation_name"] = operation_name
        event.attributes["actual_duration_ms"] = str(actual_ms)
        event.attributes["constraint_ms"] = str(constraint_ms)
        event.attributes["hardware_profile"] = self.hardware_profile.cpu_architecture

        self.telemetry_reporter.send_telemetry_async(telemetry)

class StandardizedPerformanceMetrics:
    """All timing metrics use _ms suffix for consistency - C-024: includes checkpoint metrics"""

    def __init__(self):
        self.duration_helper = ProtocolDuration()
        self.metrics: Dict[str, float] = {}

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

    def record_forward_pass_time_ms(self, duration_ms: float):
        """Record forward pass timing in milliseconds"""
        self.metrics['forward_pass_time_ms'] = duration_ms

    def record_kernel_load_time_ms(self, duration_ms: float):
        """Record kernel loading timing in milliseconds"""
        self.metrics['kernel_load_time_ms'] = duration_ms

    def record_telemetry_generation_time_ms(self, duration_ms: float):
        """Record telemetry generation timing in milliseconds"""
        self.metrics['telemetry_generation_time_ms'] = duration_ms

    def record_state_transition_time_ms(self, duration_ms: float):
        """Record state transition timing in milliseconds"""
        self.metrics['state_transition_time_ms'] = duration_ms

    def record_emergency_rollback_time_ms(self, duration_ms: float):
        """Record emergency rollback timing in milliseconds"""
        self.metrics['emergency_rollback_time_ms'] = duration_ms

    def record_gradient_isolation_time_ms(self, duration_ms: float):
        """Record gradient isolation timing in milliseconds"""
        self.metrics['gradient_isolation_time_ms'] = duration_ms

    def record_command_processing_time_ms(self, duration_ms: float):
        """Record command processing timing in milliseconds"""
        self.metrics['command_processing_time_ms'] = duration_ms

    def record_leyline_serialization_time_ms(self, duration_ms: float):
        """Record Leyline serialization timing in milliseconds"""
        self.metrics['leyline_serialization_time_ms'] = duration_ms

    def record_checkpoint_forward_time_ms(self, duration_ms: float):
        """C-024: Record checkpoint forward pass timing"""
        self.metrics['checkpoint_forward_time_ms'] = duration_ms

    def record_teacher_loading_time_ms(self, duration_ms: float):
        """C-024: Record teacher model loading time"""
        self.metrics['teacher_loading_time_ms'] = duration_ms

    def record_checkpoint_overhead_ms(self, overhead_ms: float):
        """C-024: Record checkpoint overhead"""
        self.metrics['checkpoint_overhead_ms'] = overhead_ms

    def validate_against_constraints(self, constraints: Dict[str, float]) -> Dict[str, bool]:
        """Validate all metrics against timing constraints"""

        validation_results = {}

        for metric_name, constraint_ms in constraints.items():
            if metric_name in self.metrics:
                actual_ms = self.metrics[metric_name]
                validation_results[metric_name] = self.duration_helper.validate_timing_constraint(
                    actual_ms, constraint_ms, metric_name
                )

        return validation_results

    def report_metrics_to_leyline(self) -> None:
        """Report all performance metrics to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, MetricPoint, MetricType

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"perf_metrics_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add all performance metrics
        for metric_name, value in self.metrics.items():
            metric = telemetry.metrics.add()
            metric.name = metric_name
            metric.value = value
            metric.type = MetricType.METRIC_GAUGE
            metric.timestamp.GetCurrentTime()

            # Use native map for labels (C-018 Option B)
            metric.labels["subsystem"] = "kasmina"
            metric.labels["component"] = "performance_metrics"

        self.telemetry_reporter.send_telemetry_async(telemetry)
```

## 3. Enhanced Pause Semantics

### 3.1 Pause State with Identity Kernels

```python
class PauseState:
    """Enhanced pause semantics with identity kernels"""

    def __init__(self):
        self.is_paused = False
        self.pause_reason: Optional[str] = None
        self.pause_timestamp_ms: Optional[int] = None
        self.identity_kernel_active = False
        self.pause_quota_remaining = 0

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

    def enter_pause_with_identity_kernel(self, reason: str, quota: int = 1000) -> bool:
        """Enter pause state using identity kernels for seamless operation"""

        self.is_paused = True
        self.pause_reason = reason
        self.pause_timestamp_ms = MonotonicTimer.current_time_ms()
        self.identity_kernel_active = True
        self.pause_quota_remaining = quota

        # Report pause entry to Leyline
        self._report_pause_entry(reason, quota)

        return True

    def get_identity_kernel_output(self, input_tensor: torch.Tensor) -> torch.Tensor:
        """Return identity transformation during pause (input = output)"""

        if not self.is_paused or not self.identity_kernel_active:
            raise RuntimeError("Identity kernel called outside of pause state")

        # Decrement quota
        self.pause_quota_remaining = max(0, self.pause_quota_remaining - 1)

        # Identity transformation: output = input
        return input.detach().clone()

    def exit_pause(self) -> bool:
        """Exit pause state and return to normal operation"""

        if not self.is_paused:
            return False

        # Calculate pause duration
        current_time_ms = MonotonicTimer.current_time_ms()
        pause_duration_ms = MonotonicTimer.elapsed_ms(self.pause_timestamp_ms)

        # Reset pause state
        self.is_paused = False
        self.pause_reason = None
        self.pause_timestamp_ms = None
        self.identity_kernel_active = False
        self.pause_quota_remaining = 0

        # Report pause exit to Leyline
        self._report_pause_exit(pause_duration_ms)

        return True

    def get_pause_stats(self) -> Dict[str, Any]:
        """Get pause state statistics"""

        current_time_ms = MonotonicTimer.current_time_ms()
        pause_duration_ms = (
            MonotonicTimer.elapsed_ms(self.pause_timestamp_ms)
            if self.is_paused and self.pause_timestamp_ms else 0
        )

        return {
            'is_paused': self.is_paused,
            'pause_reason': self.pause_reason,
            'pause_duration_ms': pause_duration_ms,
            'identity_kernel_active': self.identity_kernel_active,
            'pause_quota_remaining': self.pause_quota_remaining
        }

    def _report_pause_entry(self, reason: str, quota: int) -> None:
        """Report pause entry to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"pause_entry_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add pause entry event
        event = telemetry.events.add()
        event.event_name = "pause_state_entered"
        event.severity = TelemetryLevel.TELEMETRY_INFO
        event.message = f"Entered pause state: {reason}"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["reason"] = reason
        event.attributes["quota"] = str(quota)
        event.attributes["identity_kernel_active"] = "true"

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_pause_exit(self, duration_ms: int) -> None:
        """Report pause exit to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"pause_exit_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add pause exit event
        event = telemetry.events.add()
        event.event_name = "pause_state_exited"
        event.severity = TelemetryLevel.TELEMETRY_INFO
        event.message = f"Exited pause state after {duration_ms}ms"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["duration_ms"] = str(duration_ms)

        self.telemetry_reporter.send_telemetry_async(telemetry)

class ServerSidePauseQuotaEnforcement:
    """Server-side pause quota enforcement"""

    def __init__(self, max_pause_quota: int = 10000):
        self.max_pause_quota = max_pause_quota
        self.current_quota = max_pause_quota
        self.quota_reset_interval_ms = 60000  # Reset every minute
        self.last_reset_time_ms = MonotonicTimer.current_time_ms()

        # Leyline integration
        from esper.leyline.contracts import TelemetryPacket
        self.telemetry_reporter = LeylineTelemetryReporter()

    def request_pause_quota(self, requested_amount: int) -> tuple[bool, int]:
        """Request pause quota from server-side enforcement"""

        # Reset quota if interval has passed
        current_time = MonotonicTimer.current_time_ms()
        if MonotonicTimer.elapsed_ms(self.last_reset_time_ms) >= self.quota_reset_interval_ms:
            self.current_quota = self.max_pause_quota
            self.last_reset_time_ms = current_time

            # Report quota reset to Leyline
            self._report_quota_reset()

        # Check if quota is available
        if requested_amount <= self.current_quota:
            # Full grant
            self.current_quota -= requested_amount
            self._report_quota_grant(requested_amount, True)
            return True, requested_amount
        elif self.current_quota > 0:
            # Partial grant
            granted_amount = self.current_quota
            self.current_quota = 0
            self._report_quota_grant(granted_amount, False)
            return False, granted_amount
        else:
            # No quota available
            self._report_quota_denial(requested_amount)
            return False, 0

    def _report_quota_reset(self) -> None:
        """Report quota reset to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"quota_reset_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add quota reset event
        event = telemetry.events.add()
        event.event_name = "pause_quota_reset"
        event.severity = TelemetryLevel.TELEMETRY_INFO
        event.message = f"Pause quota reset to {self.max_pause_quota}"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["max_quota"] = str(self.max_pause_quota)
        event.attributes["reset_interval_ms"] = str(self.quota_reset_interval_ms)

        self.telemetry_reporter.send_telemetry_async(telemetry)

    def _report_quota_grant(self, amount: int, full_grant: bool) -> None:
        """Report quota grant to Leyline"""
        from esper.leyline.contracts import TelemetryPacket, TelemetryEvent, TelemetryLevel

        telemetry = TelemetryPacket()
        telemetry.packet_id = f"quota_grant_{int(time.time())}"
        telemetry.source_subsystem = "kasmina"
        telemetry.timestamp.GetCurrentTime()

        # Add quota grant event
        event = telemetry.events.add()
        event.event_name = "pause_quota_granted"
        event.severity = TelemetryLevel.TELEMETRY_INFO
        event.message = f"Pause quota {'granted' if full_grant else 'partially granted'}: {amount}"
        event.timestamp.GetCurrentTime()

        # Use native map for attributes
        event.attributes["amount"] = str(amount)
        event.attributes["full_grant"] = str(full_grant)
        event.attributes["remaining_quota"] = str(self.current_quota)

        self.telemetry_reporter.send_telemetry_async(telemetry)
```

## 4. Production Safety Configuration

### 4.1 Safety Configuration Management with C-024 Support

```python
@dataclass(frozen=True)
class ProductionSafetyConfig:
    """Production safety configuration with Leyline integration and C-024 support"""

    # Circuit breaker settings
    circuit_breaker_enabled: bool = True
    gradient_isolation_failure_threshold: int = 3
    memory_bounds_failure_threshold: int = 5
    kernel_loading_failure_threshold: int = 10
    circuit_breaker_timeout_ms: int = 60000

    # C-024: Checkpoint safety settings
    checkpoint_recompilation_threshold: int = 3
    teacher_memory_overflow_threshold: int = 2
    checkpoint_overhead_acceptable_ratio: float = 0.20
    torch_compile_stability_monitoring: bool = True

    # Hardware timing settings
    hardware_timing_awareness: bool = True
    timing_constraint_enforcement: bool = True
    epoch_boundary_ms: int = 18

    # Memory management settings
    memory_management_enabled: bool = True
    emergency_cleanup_threshold: float = 0.90  # 90% memory usage
    gc_frequency: int = 100  # GC every N epochs

    # C-024: Teacher memory settings
    teacher_memory_limit_gb: float = 7.0  # With checkpointing
    teacher_memory_monitoring: bool = True

    # Parameter registration settings
    parameter_registration_required: bool = True
    invariant_l2_enforcement: bool = True

    # Pause state settings
    pause_semantics_enabled: bool = True
    identity_kernel_enabled: bool = True
    max_pause_quota: int = 10000
    pause_quota_reset_interval_ms: int = 60000

    # Leyline integration settings
    leyline_contracts_enabled: bool = True
    native_map_usage: bool = True  # C-018 Option B
    target_serialization_time_us: int = 80
    target_message_size_bytes: int = 280

    def validate_config(self) -> bool:
        """Validate configuration consistency"""

        # Validate Leyline Option B requirements
        if self.leyline_contracts_enabled and not self.native_map_usage:
            raise ValueError("Leyline Option B requires native map usage")

        # Validate critical safety features are enabled
        critical_features = [
            self.memory_management_enabled,
            self.parameter_registration_required,
            self.circuit_breaker_enabled,
            self.hardware_timing_awareness
        ]

        if not all(critical_features):
            raise ValueError("All critical safety features must be enabled for production")

        # C-024: Validate checkpoint safety settings
        if self.torch_compile_stability_monitoring:
            if self.checkpoint_recompilation_threshold < 1:
                raise ValueError("Checkpoint recompilation threshold must be at least 1")
            if self.checkpoint_overhead_acceptable_ratio > 0.30:
                raise ValueError("Checkpoint overhead ratio above 30% is unacceptable")

        # Validate performance targets are achievable
        if self.target_message_size_bytes > 350:
            raise ValueError("Message size target exceeds Leyline Option B limits")

        if self.target_serialization_time_us > 120:
            raise ValueError("Serialization time target exceeds Leyline Option B limits")

        return True

@dataclass(frozen=True)
class GraftingConfig:
    """Enhanced grafting configuration with Leyline integration"""

    # Core grafting parameters
    fixed_steps: int = 30
    high_drift_threshold: float = 0.12
    grad_norm_lower: float = 0.1
    grad_norm_upper: float = 1.0
    stabilization_epochs: int = 5
    evaluation_patience: int = 10
    fine_tuning_patience: int = 50
    embargo_duration: int = 100
    reconstruction_threshold: float = 0.85
    performance_gate: float = 0.001  # Min improvement
    isolation_temperature: float = 1.0  # Alpha blending smoothness

    # Safety enhancements (C-016)
    circuit_breaker_protection: bool = True
    memory_bounded_operations: bool = True
    timing_constraint_enforcement: bool = True
    parameter_registration_validation: bool = True

    # Leyline integration
    leyline_telemetry_enabled: bool = True
    telemetry_reporting_frequency: int = 10  # Report every N grafting steps

    def get_leyline_telemetry_config(self) -> Dict[str, Any]:
        """Get telemetry configuration for Leyline reporting"""
        return {
            'enabled': self.leyline_telemetry_enabled,
            'reporting_frequency': self.telemetry_reporting_frequency,
            'metrics_to_report': [
                'grafting_progress',
                'alpha_blending_value',
                'performance_gate_status',
                'isolation_temperature',
                'memory_usage',
                'timing_constraints'
            ]
        }
```

## 5. Integration Contract

This component integrates with the main Kasmina architecture by providing:

### 5.1 Safety Mechanisms Interface with C-024 Extensions

```python
@dataclass
class SafetyMechanismsContract:
    """Interface contract for safety mechanisms component with C-024 support"""

    # Circuit breaker methods
    def create_circuit_breaker(self, name: str, config: CircuitBreakerConfig) -> KasminaCircuitBreaker
    def safe_assert_replacement(self, condition: bool, message: str, circuit_breaker: KasminaCircuitBreaker) -> bool
    def get_circuit_breaker_stats(self, name: str) -> Dict[str, Any]

    # C-024: Checkpoint safety methods
    def monitor_checkpoint_recompilation(self) -> bool
    def validate_checkpoint_overhead(self, forward_time_ms: float, checkpoint_time_ms: float) -> bool
    def monitor_teacher_memory(self, current_usage_gb: float, limit_gb: float = 7.0) -> bool
    def handle_checkpoint_failure(self, error: Exception) -> bool
    def get_checkpoint_safety_stats(self) -> Dict[str, Any]

    # Hardware-aware timing methods
    def validate_timing_constraint(self, actual_duration_ms: float, constraint_ms: float, operation: str) -> bool
    def validate_checkpoint_timing(self, checkpoint_time_ms: float, base_time_ms: float) -> bool
    def validate_teacher_loading_time(self, loading_time_ms: float) -> bool
    def get_hardware_profile(self) -> HardwareTimingProfile
    def record_performance_metric(self, metric_name: str, duration_ms: float) -> None

    # Pause state methods
    def enter_pause_with_identity_kernel(self, reason: str, quota: int = 1000) -> bool
    def get_identity_kernel_output(self, input_tensor: torch.Tensor) -> torch.Tensor
    def exit_pause(self) -> bool
    def get_pause_stats(self) -> Dict[str, Any]

    # Configuration methods
    def validate_safety_config(self, config: ProductionSafetyConfig) -> bool
    def update_grafting_config(self, config: GraftingConfig) -> None

    # Leyline integration methods
    def report_to_leyline_telemetry(self, event_data: Dict[str, Any]) -> None
```

### 5.2 Component Coordination

This component coordinates with other Kasmina components:

- **[02.1-kasmina-kernel-execution.md](./02.1-kasmina-kernel-execution.md)**: Circuit breaker integration for kernel loading failures + C-024 checkpoint failures
- **[02.2-kasmina-memory-pools.md](./02.2-kasmina-memory-pools.md)**: Memory limit violations trigger circuit breakers + C-024 teacher memory monitoring
- **[02.3-kasmina-parameter-registration.md](./02.3-kasmina-parameter-registration.md)**: Parameter registration violations activate safety mechanisms
- **[02.5-kasmina-performance-validation.md](./02.5-kasmina-performance-validation.md)**: Performance constraint validation and timing verification + C-024 checkpoint metrics

## 6. References

- **Parent Document**: [02-kasmina-unified-design.md](./02-kasmina-unified-design.md)
- **Kernel Execution**: [02.1-kasmina-kernel-execution.md](./02.1-kasmina-kernel-execution.md)
- **Memory Pools**: [02.2-kasmina-memory-pools.md](./02.2-kasmina-memory-pools.md)
- **Parameter Registration**: [02.3-kasmina-parameter-registration.md](./02.3-kasmina-parameter-registration.md)
- **Performance Validation**: [02.5-kasmina-performance-validation.md](./02.5-kasmina-performance-validation.md)
- **Leyline Contracts**: [00-leyline-shared-contracts.md](./00-leyline-shared-contracts.md)
- **C-018 Final Consensus**: Option B (Performance-First) implementation
- **C-024 KD Amendment**: Checkpoint safety and torch.compile stability
- **Conclave C-016**: Emergency Production Safety Response - Circuit breaker requirements

---

**COMPONENT STATUS**: COMPLETE - Critical Safety Controls + Leyline Integrated + C-024 Checkpoint Safety
**Production Safety**: All C-016 critical issues addressed with circuit breaker patterns
**Assert Replacement**: Complete elimination of assert-based crashes
**Hardware Awareness**: Timing constraints adjusted for different GPU architectures
**C-024 Enhancements**: Checkpoint recompilation monitoring, teacher memory protection, fallback mechanisms
**Pause Semantics**: Identity kernel support for seamless training continuation
**Integration**: Fully coordinated with all Kasmina components