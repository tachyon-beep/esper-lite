# 13.2 Elesh Analysis Algorithms - Structured Pruning Implementation

## Document Metadata

| Field | Value |
|-------|-------|
| **Version** | 3.0 - Complete Structured Pruning Algorithms |
| **Status** | APPROVED |
| **Date** | 2025-01-14 |
| **Author** | C-020 Round 6 Algorithm Specialist |
| **Parent** | 13-elesh-unified-design.md |
| **Purpose** | Channel, Attention Head, and Layer Pruning Algorithms |

## Executive Summary

This document provides complete, implementable algorithms for structured pruning of channels, attention heads, and layers within the Elesh analysis framework. All algorithms are designed for checkpoint-based offline execution with comprehensive safety validation and the "measure twice, cut once" approach.

**C-020 INNOVATION**: Multi-level structural analysis using Taylor expansion importance, attention pattern diversity, and skip connection evaluation with progressive safety schedules.

## 1. Channel Pruning Algorithms

### 1.1 Taylor Expansion Importance Calculation

```python
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple
from dataclasses import dataclass

@dataclass
class ChannelImportance:
    """Channel importance metrics for structured pruning"""
    index: int
    taylor_importance: float          # |∂L/∂a_c · a_c| - Primary metric
    magnitude_importance: float       # L2 norm of channel weights
    activation_frequency: float       # Sparsity-aware activation rate
    combined_score: float            # Weighted combination
    is_redundant: bool              # Correlation-based redundancy flag
    correlation_partners: List[int]  # Highly correlated channels

def calculate_channel_importance(
    layer: nn.Conv2d,
    activations: torch.Tensor,
    gradients: torch.Tensor,
    config: Dict[str, float]
) -> Dict[int, ChannelImportance]:
    """
    Calculate structured importance scores for each channel in a convolutional layer

    Taylor expansion approximation: ΔL ≈ ∑_c |∂L/∂a_c · a_c|
    Enhanced with multi-metric scoring for robust importance estimation

    Args:
        layer: Convolutional layer to analyze
        activations: Cached activations [batch, channels, height, width]
        gradients: Cached gradients [batch, channels, height, width]
        config: Algorithm configuration parameters

    Returns:
        Dictionary mapping channel index to comprehensive importance metrics
    """
    batch_size, num_channels, height, width = activations.shape

    # 1. Taylor importance: |gradient * activation|
    taylor_scores = torch.abs(gradients * activations)
    taylor_importance = taylor_scores.mean(dim=(0, 2, 3))  # Average over batch, H, W

    # 2. Weight magnitude importance (proxy for parameter significance)
    weight_magnitude = torch.norm(layer.weight, dim=(1, 2, 3))  # L2 norm per output channel

    # 3. Activation frequency (sparsity-aware importance)
    activation_threshold = config.get('activation_threshold', 1e-3)
    activation_mask = torch.abs(activations) > activation_threshold
    activation_frequency = activation_mask.float().mean(dim=(0, 2, 3))

    # 4. Channel redundancy detection via correlation analysis
    channel_correlations = calculate_channel_correlation_matrix(activations)
    redundancy_threshold = config.get('redundancy_threshold', 0.95)

    # 5. Adaptive phase-based weighting
    training_phase = config.get('training_phase', 'mid')
    phase_weights = get_phase_weights(training_phase)

    importance_scores = {}
    redundancy_groups = find_redundancy_groups(channel_correlations, redundancy_threshold)

    for c in range(num_channels):
        # Normalized importance scores
        taylor_norm = taylor_importance[c] / (taylor_importance.max() + 1e-8)
        magnitude_norm = weight_magnitude[c] / (weight_magnitude.max() + 1e-8)
        frequency_norm = activation_frequency[c] / (activation_frequency.max() + 1e-8)

        # Phase-adaptive weighted combination
        combined = (
            phase_weights['taylor'] * taylor_norm +
            phase_weights['magnitude'] * magnitude_norm +
            phase_weights['frequency'] * frequency_norm
        )

        # Redundancy analysis
        is_redundant = c in redundancy_groups and len(redundancy_groups[c]) > 1
        correlation_partners = redundancy_groups.get(c, [])

        importance_scores[c] = ChannelImportance(
            index=c,
            taylor_importance=taylor_norm.item(),
            magnitude_importance=magnitude_norm.item(),
            activation_frequency=frequency_norm.item(),
            combined_score=combined.item(),
            is_redundant=is_redundant,
            correlation_partners=[p for p in correlation_partners if p != c]
        )

    return importance_scores

def calculate_channel_correlation_matrix(activations: torch.Tensor) -> torch.Tensor:
    """
    Calculate pairwise channel correlations using cosine similarity

    Enhanced for structured pruning with spatial averaging and batch normalization
    """
    batch_size, num_channels, height, width = activations.shape

    # Flatten spatial dimensions and normalize per channel
    activations_flat = activations.reshape(batch_size, num_channels, -1)

    # Calculate channel-wise statistics
    channel_means = activations_flat.mean(dim=(0, 2), keepdim=True)  # [1, channels, 1]
    channel_stds = activations_flat.std(dim=(0, 2), keepdim=True) + 1e-8

    # Z-score normalization per channel
    normalized_activations = (activations_flat - channel_means) / channel_stds

    # Average activation patterns across batch and spatial dimensions
    channel_vectors = normalized_activations.mean(dim=0)  # [channels, spatial]

    # Compute cosine similarity matrix
    channel_vectors_norm = torch.nn.functional.normalize(channel_vectors, dim=1)
    correlation_matrix = torch.matmul(channel_vectors_norm, channel_vectors_norm.t())

    return correlation_matrix

def get_phase_weights(training_phase: str) -> Dict[str, float]:
    """Adaptive weighting based on training phase"""
    phase_weights = {
        'early': {'taylor': 0.3, 'magnitude': 0.5, 'frequency': 0.2},   # Weight-focused early
        'mid': {'taylor': 0.5, 'magnitude': 0.3, 'frequency': 0.2},     # Gradient-focused mid
        'late': {'taylor': 0.6, 'magnitude': 0.2, 'frequency': 0.2}     # Activity-focused late
    }
    return phase_weights.get(training_phase, phase_weights['mid'])

def find_redundancy_groups(correlation_matrix: torch.Tensor, threshold: float) -> Dict[int, List[int]]:
    """Identify groups of highly correlated (redundant) channels"""
    num_channels = correlation_matrix.shape[0]
    redundancy_groups = {}

    # Find all pairs above threshold
    high_corr_pairs = (correlation_matrix > threshold).nonzero()

    # Group correlated channels
    for i, j in high_corr_pairs:
        i, j = i.item(), j.item()
        if i != j:  # Skip diagonal
            if i not in redundancy_groups:
                redundancy_groups[i] = [i]
            if j not in redundancy_groups:
                redundancy_groups[j] = [j]

            # Merge groups
            group_i = redundancy_groups[i]
            group_j = redundancy_groups[j]
            merged_group = list(set(group_i + group_j))

            # Update all members to point to merged group
            for member in merged_group:
                redundancy_groups[member] = merged_group

    return redundancy_groups
```

### 1.2 Progressive Channel Pruning Schedule

```python
@dataclass
class PruningSchedule:
    """Progressive pruning schedule configuration for safe channel removal"""
    initial_sparsity: float = 0.0
    target_sparsity: float = 0.15      # Conservative 15% channel removal
    num_pruning_steps: int = 10
    schedule_type: str = "polynomial"   # polynomial, linear, exponential
    polynomial_power: float = 3.0      # For polynomial schedule
    safety_margin: float = 0.1         # Additional safety buffer

def generate_progressive_pruning_schedule(
    current_epoch: int,
    total_training_epochs: int,
    schedule: PruningSchedule,
    safety_phase: str = "conservative"
) -> float:
    """
    Generate progressive channel pruning ratio with safety constraints

    Implements Conservative → Moderate → Aggressive progression
    """
    # Safety phase constraints
    safety_limits = {
        'conservative': 0.05,   # 5% maximum in conservative phase
        'moderate': 0.10,       # 10% maximum in moderate phase
        'aggressive': 0.20      # 20% maximum in aggressive phase
    }

    max_allowed_sparsity = min(schedule.target_sparsity, safety_limits[safety_phase])

    # Skip initial epochs for telemetry collection
    warmup_epochs = 30  # Pure analysis phase
    if current_epoch < warmup_epochs:
        return schedule.initial_sparsity

    # Calculate pruning progress
    pruning_epochs = total_training_epochs - warmup_epochs
    current_pruning_epoch = current_epoch - warmup_epochs
    progress = min(1.0, current_pruning_epoch / pruning_epochs)

    # Apply schedule function
    if schedule.schedule_type == "linear":
        base_sparsity = schedule.initial_sparsity + (
            max_allowed_sparsity - schedule.initial_sparsity
        ) * progress

    elif schedule.schedule_type == "polynomial":
        base_sparsity = schedule.initial_sparsity + (
            max_allowed_sparsity - schedule.initial_sparsity
        ) * (progress ** schedule.polynomial_power)

    elif schedule.schedule_type == "exponential":
        # Exponential approach to target
        decay_rate = -np.log(1 - max_allowed_sparsity) / pruning_epochs
        base_sparsity = 1 - np.exp(-decay_rate * current_pruning_epoch)

    else:
        raise ValueError(f"Unknown schedule type: {schedule.schedule_type}")

    # Apply safety margin
    final_sparsity = base_sparsity * (1 - schedule.safety_margin)

    return min(final_sparsity, max_allowed_sparsity)

def select_channels_to_prune(
    importance_scores: Dict[int, ChannelImportance],
    target_sparsity: float,
    min_channels: int = 16,
    prefer_redundant: bool = True
) -> List[int]:
    """
    Intelligent channel selection prioritizing redundant channels

    Strategy:
    1. First remove from redundant groups (keep best from each group)
    2. Then select globally least important channels
    3. Enforce minimum channel constraints
    """
    num_channels = len(importance_scores)
    num_to_prune = int(num_channels * target_sparsity)
    num_to_keep = max(min_channels, num_channels - num_to_prune)

    if num_to_keep >= num_channels:
        return []  # Cannot prune without violating constraints

    channels_to_prune = []

    # Phase 1: Prune from redundant groups
    if prefer_redundant:
        redundancy_groups = {}
        for c, importance in importance_scores.items():
            if importance.is_redundant and importance.correlation_partners:
                # Group channels by their correlation partners
                group_key = tuple(sorted([c] + importance.correlation_partners))
                if group_key not in redundancy_groups:
                    redundancy_groups[group_key] = []
                redundancy_groups[group_key].append((c, importance))

        # From each redundant group, keep only the most important channel
        for group_channels in redundancy_groups.values():
            if len(group_channels) > 1:
                # Sort by combined score (descending)
                group_channels.sort(key=lambda x: x[1].combined_score, reverse=True)

                # Add all but the best to pruning candidates
                for c, _ in group_channels[1:]:
                    if len(channels_to_prune) < num_to_prune:
                        channels_to_prune.append(c)

    # Phase 2: Global importance-based selection for remaining quota
    remaining_channels = [
        (c, importance) for c, importance in importance_scores.items()
        if c not in channels_to_prune
    ]

    # Sort by combined importance (ascending - least important first)
    remaining_channels.sort(key=lambda x: x[1].combined_score)

    for c, _ in remaining_channels:
        if len(channels_to_prune) >= num_to_prune:
            break
        if num_channels - len(channels_to_prune) <= min_channels:
            break
        if c not in channels_to_prune:
            channels_to_prune.append(c)

    return channels_to_prune
```

## 2. Attention Head Pruning Algorithms

### 2.1 Multi-Factor Head Importance Analysis

```python
@dataclass
class HeadImportance:
    """Comprehensive attention head importance metrics"""
    index: int
    attention_entropy: float        # Uniformity of attention patterns
    pattern_diversity: float        # JS divergence from mean pattern
    gradient_sensitivity: float     # Impact on loss function
    combined_score: float          # Weighted combination
    redundancy_group: int          # Cluster assignment for similar heads
    redundancy_score: float        # Maximum similarity to other heads

def analyze_attention_head_importance(
    attention_weights: torch.Tensor,
    attention_gradients: torch.Tensor,
    value_projections: torch.Tensor,
    config: Dict[str, float]
) -> Dict[int, HeadImportance]:
    """
    Comprehensive attention head analysis for structured pruning

    Based on "Are Sixteen Heads Really Better than One?" with enhancements:
    - Multi-factor scoring (entropy + diversity + gradient sensitivity)
    - Redundancy group detection via cosine similarity clustering
    - Training phase adaptive weighting

    Args:
        attention_weights: [batch, num_heads, seq_len, seq_len]
        attention_gradients: Gradients w.r.t. attention weights
        value_projections: Value projection weights for sensitivity analysis
        config: Analysis configuration

    Returns:
        Per-head importance metrics with redundancy analysis
    """
    batch_size, num_heads, seq_len, _ = attention_weights.shape

    # 1. Calculate attention entropy per head (pattern uniformity)
    attention_entropy = calculate_attention_entropy_per_head(attention_weights)

    # 2. Calculate pattern diversity using Jensen-Shannon divergence
    pattern_diversity = calculate_attention_pattern_diversity(attention_weights)

    # 3. Calculate gradient sensitivity (impact on loss)
    gradient_sensitivity = calculate_attention_gradient_sensitivity(
        attention_weights, attention_gradients, value_projections
    )

    # 4. Detect redundancy groups via clustering
    redundancy_groups, redundancy_scores = cluster_attention_heads_by_similarity(
        attention_weights,
        threshold=config.get('similarity_threshold', 0.95)
    )

    # 5. Adaptive phase-based weighting
    training_phase = config.get('training_phase', 'mid')
    phase_weights = get_attention_phase_weights(training_phase)

    # Compile comprehensive head importance metrics
    head_importance = {}

    for h in range(num_heads):
        # Normalize individual metrics
        entropy_norm = attention_entropy[h] / (attention_entropy.max() + 1e-8)
        diversity_norm = pattern_diversity[h] / (pattern_diversity.max() + 1e-8)
        gradient_norm = gradient_sensitivity[h] / (gradient_sensitivity.max() + 1e-8)

        # Phase-adaptive weighted combination
        combined = (
            phase_weights['entropy'] * entropy_norm +
            phase_weights['diversity'] * diversity_norm +
            phase_weights['gradient'] * gradient_norm
        )

        head_importance[h] = HeadImportance(
            index=h,
            attention_entropy=entropy_norm.item(),
            pattern_diversity=diversity_norm.item(),
            gradient_sensitivity=gradient_norm.item(),
            combined_score=combined.item(),
            redundancy_group=redundancy_groups[h],
            redundancy_score=redundancy_scores[h]
        )

    return head_importance

def calculate_attention_entropy_per_head(attention_weights: torch.Tensor) -> torch.Tensor:
    """
    Calculate entropy of attention distributions per head

    Higher entropy = more uniform attention = potentially less specialized
    """
    # Add small epsilon for numerical stability
    attention_weights = attention_weights + 1e-10

    # Calculate entropy: -∑ p * log(p) for each attention distribution
    entropy = -torch.sum(attention_weights * torch.log(attention_weights), dim=-1)

    # Average entropy over batch and sequence positions
    avg_entropy = entropy.mean(dim=(0, 2))  # [num_heads]

    return avg_entropy

def calculate_attention_pattern_diversity(attention_weights: torch.Tensor) -> torch.Tensor:
    """
    Calculate pattern diversity using Jensen-Shannon divergence from mean pattern

    Higher diversity = head produces varied attention patterns = more valuable
    """
    batch_size, num_heads, seq_len, _ = attention_weights.shape
    diversity_scores = torch.zeros(num_heads)

    for h in range(num_heads):
        head_patterns = attention_weights[:, h, :, :].reshape(batch_size, -1)

        # Calculate mean attention pattern for this head
        mean_pattern = head_patterns.mean(dim=0, keepdim=True)

        # JS divergence between each sample and mean
        js_divergences = []
        for b in range(min(batch_size, 32)):  # Limit for efficiency
            pattern = head_patterns[b:b+1]
            m = 0.5 * (pattern + mean_pattern + 1e-10)

            # KL divergences for JS calculation
            kl_pm = torch.nn.functional.kl_div(
                torch.log(pattern + 1e-10), m, reduction='sum'
            )
            kl_mp = torch.nn.functional.kl_div(
                torch.log(m + 1e-10), pattern + 1e-10, reduction='sum'
            )

            js_div = 0.5 * (kl_pm + kl_mp)
            js_divergences.append(js_div)

        diversity_scores[h] = torch.tensor(js_divergences).mean()

    return diversity_scores

def calculate_attention_gradient_sensitivity(
    attention_weights: torch.Tensor,
    attention_gradients: torch.Tensor,
    value_projections: torch.Tensor
) -> torch.Tensor:
    """
    Calculate gradient-based sensitivity of each attention head to loss

    Higher sensitivity = head has more impact on model performance
    """
    # Gradient norm per head (proxy for impact on loss)
    gradient_norms = torch.norm(attention_gradients, dim=(0, 2, 3))  # [num_heads]

    # Weight sensitivity using value projection magnitudes
    num_heads = attention_weights.shape[1]
    head_dim = value_projections.shape[-1] // num_heads

    value_head_weights = value_projections.reshape(-1, num_heads, head_dim)
    value_magnitudes = torch.norm(value_head_weights, dim=(0, 2))  # [num_heads]

    # Combined gradient and weight sensitivity
    sensitivity = gradient_norms * value_magnitudes

    return sensitivity

def cluster_attention_heads_by_similarity(
    attention_weights: torch.Tensor,
    threshold: float = 0.95
) -> Tuple[Dict[int, int], torch.Tensor]:
    """
    Cluster attention heads into redundancy groups based on pattern similarity

    Returns:
        redundancy_groups: Dict mapping head index to group ID
        redundancy_scores: Maximum similarity score for each head
    """
    num_heads = attention_weights.shape[1]

    # Average attention patterns across batch
    avg_patterns = attention_weights.mean(dim=0)  # [num_heads, seq_len, seq_len]
    patterns_flat = avg_patterns.reshape(num_heads, -1)

    # Normalize for cosine similarity
    patterns_norm = torch.nn.functional.normalize(patterns_flat, dim=1)

    # Compute pairwise similarity matrix
    similarity_matrix = torch.matmul(patterns_norm, patterns_norm.t())

    # Find redundancy groups using simple clustering
    redundancy_groups = {}
    group_id = 0
    assigned = set()

    for h in range(num_heads):
        if h in assigned:
            continue

        # Start new redundancy group
        redundancy_groups[h] = group_id
        assigned.add(h)

        # Find heads similar to current head
        similar_heads = (similarity_matrix[h] > threshold).nonzero().flatten()
        for similar_h in similar_heads:
            similar_h = similar_h.item()
            if similar_h not in assigned and similar_h != h:
                redundancy_groups[similar_h] = group_id
                assigned.add(similar_h)

        group_id += 1

    # Calculate maximum redundancy score for each head
    redundancy_scores = torch.zeros(num_heads)
    for h in range(num_heads):
        # Maximum similarity to any other head
        other_similarities = similarity_matrix[h].clone()
        other_similarities[h] = 0  # Exclude self-similarity
        redundancy_scores[h] = other_similarities.max()

    return redundancy_groups, redundancy_scores

def get_attention_phase_weights(training_phase: str) -> Dict[str, float]:
    """Training phase-adaptive weights for attention head analysis"""
    phase_weights = {
        'early': {'entropy': 0.2, 'diversity': 0.3, 'gradient': 0.5},   # Gradient-focused early
        'mid': {'entropy': 0.3, 'diversity': 0.4, 'gradient': 0.3},     # Balanced mid training
        'late': {'entropy': 0.4, 'diversity': 0.4, 'gradient': 0.2}     # Pattern-focused late
    }
    return phase_weights.get(training_phase, phase_weights['mid'])
```

### 2.2 Attention Head Pruning Strategy

```python
def select_attention_heads_to_prune(
    head_importance: Dict[int, HeadImportance],
    target_sparsity: float,
    min_heads_per_layer: int = 2,
    prioritize_redundancy: bool = True
) -> List[int]:
    """
    Intelligent attention head selection with redundancy prioritization

    Strategy:
    1. From each redundancy group, keep only the most important head
    2. Apply global importance-based selection for remaining quota
    3. Ensure minimum head count constraints
    """
    num_heads = len(head_importance)
    num_to_prune = int(num_heads * target_sparsity)
    num_to_keep = max(min_heads_per_layer, num_heads - num_to_prune)

    if num_to_keep >= num_heads:
        return []  # Cannot prune without violating constraints

    heads_to_prune = []

    # Phase 1: Redundancy-based pruning
    if prioritize_redundancy:
        # Group heads by redundancy group
        redundancy_groups = {}
        for h, importance in head_importance.items():
            group = importance.redundancy_group
            if group not in redundancy_groups:
                redundancy_groups[group] = []
            redundancy_groups[group].append((h, importance))

        # From each group with multiple heads, keep only the best
        for group_heads in redundancy_groups.values():
            if len(group_heads) > 1:
                # Sort by combined score (descending - best first)
                group_heads.sort(key=lambda x: x[1].combined_score, reverse=True)

                # Add all but the best to pruning candidates
                for h, _ in group_heads[1:]:
                    if len(heads_to_prune) < num_to_prune:
                        heads_to_prune.append(h)

    # Phase 2: Global importance-based selection
    remaining_heads = [
        (h, importance) for h, importance in head_importance.items()
        if h not in heads_to_prune
    ]

    # Sort by combined importance (ascending - least important first)
    remaining_heads.sort(key=lambda x: x[1].combined_score)

    for h, _ in remaining_heads:
        if len(heads_to_prune) >= num_to_prune:
            break
        if num_heads - len(heads_to_prune) <= min_heads_per_layer:
            break
        if h not in heads_to_prune:
            heads_to_prune.append(h)

    return heads_to_prune
```

## 3. Layer Pruning Algorithms

### 3.1 Layer Importance and Skip Connection Analysis

```python
@dataclass
class LayerImportance:
    """Comprehensive layer-level importance metrics"""
    layer_id: str
    taylor_importance: float        # Layer-level Taylor expansion
    gradient_flow: float           # Gradient flow preservation
    feature_similarity: float      # Input-output feature similarity
    skip_potential: float          # Skip connection feasibility
    architecture_impact: float     # Impact on overall architecture
    can_remove: bool              # Safety assessment for removal
    skip_strategy: str            # Recommended skip connection type

def analyze_layer_removal_potential(
    model: nn.Module,
    layer_id: str,
    layer_inputs: torch.Tensor,
    layer_outputs: torch.Tensor,
    output_gradients: torch.Tensor,
    config: Dict[str, float]
) -> LayerImportance:
    """
    Comprehensive layer analysis for potential removal

    Analysis factors:
    - Taylor importance at layer level: ΔL ≈ |∂L/∂y · y|
    - Gradient flow preservation through potential skip connection
    - Feature similarity between inputs and outputs
    - Architecture compatibility for skip connection establishment

    Args:
        model: Complete neural network model
        layer_id: Unique identifier for the layer
        layer_inputs: Input activations to the layer
        layer_outputs: Output activations from the layer
        output_gradients: Gradients w.r.t. layer outputs
        config: Analysis configuration parameters

    Returns:
        Comprehensive layer importance assessment
    """
    # 1. Layer-level Taylor importance
    taylor_importance = torch.abs(output_gradients * layer_outputs).mean().item()

    # 2. Gradient flow strength analysis
    gradient_flow = calculate_gradient_flow_strength(
        layer_inputs, layer_outputs, output_gradients
    )

    # 3. Feature similarity for skip connection potential
    feature_similarity = calculate_feature_similarity(
        layer_inputs, layer_outputs, config
    )

    # 4. Skip connection potential assessment
    skip_potential, skip_strategy = evaluate_skip_connection_potential(
        model, layer_id, layer_inputs.shape, layer_outputs.shape, config
    )

    # 5. Architecture impact assessment
    architecture_impact = assess_architecture_impact(
        model, layer_id, config
    )

    # 6. Safety assessment for removal
    can_remove = determine_layer_removal_safety(
        taylor_importance, gradient_flow, feature_similarity,
        skip_potential, architecture_impact, config
    )

    return LayerImportance(
        layer_id=layer_id,
        taylor_importance=taylor_importance,
        gradient_flow=gradient_flow,
        feature_similarity=feature_similarity,
        skip_potential=skip_potential,
        architecture_impact=architecture_impact,
        can_remove=can_remove,
        skip_strategy=skip_strategy
    )

def calculate_gradient_flow_strength(
    inputs: torch.Tensor,
    outputs: torch.Tensor,
    output_gradients: torch.Tensor
) -> float:
    """
    Analyze gradient flow strength through the layer

    Strong gradient flow = layer is important for backpropagation
    """
    # Approximate input gradients using chain rule
    if inputs.requires_grad and inputs.grad is not None:
        input_grad_norm = torch.norm(inputs.grad).item()
    else:
        # Fallback: approximate gradient flow
        input_grad_norm = torch.norm(output_gradients).item()

    output_grad_norm = torch.norm(output_gradients).item()

    # Gradient flow ratio (higher = better gradient preservation)
    gradient_flow = output_grad_norm / (input_grad_norm + 1e-8)

    return min(gradient_flow, 10.0)  # Cap for numerical stability

def calculate_feature_similarity(
    inputs: torch.Tensor,
    outputs: torch.Tensor,
    config: Dict[str, float]
) -> float:
    """
    Calculate similarity between layer inputs and outputs

    High similarity suggests layer performs identity-like transformation
    """
    # Handle dimension mismatches
    if inputs.shape != outputs.shape:
        # Try to project to same dimensions for comparison
        if len(inputs.shape) == len(outputs.shape):
            # Same number of dimensions, try adaptive pooling/projection
            if inputs.shape[-1] != outputs.shape[-1]:
                # Different feature dimensions - limited similarity possible
                return 0.1
            else:
                # Same feature dim, different spatial dims - use adaptive pooling
                if len(inputs.shape) == 4:  # Conv layer with spatial dims
                    inputs_pooled = torch.nn.functional.adaptive_avg_pool2d(
                        inputs, outputs.shape[2:]
                    )
                    similarity = torch.nn.functional.cosine_similarity(
                        inputs_pooled.flatten(), outputs.flatten(), dim=0
                    ).item()
                else:
                    similarity = 0.1
        else:
            # Different number of dimensions - very limited similarity
            return 0.05
    else:
        # Direct similarity calculation
        similarity = torch.nn.functional.cosine_similarity(
            inputs.flatten(), outputs.flatten(), dim=0
        ).item()

    return max(0.0, similarity)  # Ensure non-negative

def evaluate_skip_connection_potential(
    model: nn.Module,
    layer_id: str,
    input_shape: torch.Size,
    output_shape: torch.Size,
    config: Dict[str, float]
) -> Tuple[float, str]:
    """
    Evaluate feasibility of establishing skip connection around layer

    Returns:
        skip_potential: Score 0-1 indicating feasibility
        skip_strategy: Recommended skip connection type
    """
    # Perfect dimensional match - direct skip possible
    if input_shape == output_shape:
        return 1.0, "identity"

    # Same number of dimensions but different sizes
    if len(input_shape) == len(output_shape):
        if input_shape[0] == output_shape[0]:  # Same batch size
            if len(input_shape) == 2:  # Linear layer
                # Can use linear projection
                return 0.9, "linear_projection"
            elif len(input_shape) == 4:  # Conv layer
                # Can use 1x1 conv projection
                return 0.8, "conv_projection"

    # Check for existing residual connections
    has_residual = check_existing_residual_connections(model, layer_id)
    if has_residual:
        return 0.95, "existing_residual"

    # Check architectural patterns
    architecture_type = infer_architecture_type(model)
    if architecture_type in ["resnet", "densenet", "efficientnet"]:
        # These architectures support skip connections well
        return 0.7, "learned_adapter"

    # Default case - challenging but possible with adaptation
    return 0.4, "learned_adapter"

def assess_architecture_impact(
    model: nn.Module,
    layer_id: str,
    config: Dict[str, float]
) -> float:
    """
    Assess impact of layer removal on overall architecture

    Lower impact = safer to remove
    """
    total_layers = sum(1 for _ in model.modules() if isinstance(_, (nn.Conv2d, nn.Linear, nn.MultiheadAttention)))

    # Layer depth impact (deeper layers generally more important)
    layer_depth = get_layer_depth(model, layer_id)
    depth_impact = layer_depth / total_layers

    # Layer type impact
    layer_module = get_layer_by_id(model, layer_id)
    if isinstance(layer_module, nn.MultiheadAttention):
        type_impact = 0.8  # Attention layers are important
    elif isinstance(layer_module, nn.Conv2d):
        type_impact = 0.6  # Conv layers moderately important
    elif isinstance(layer_module, nn.Linear):
        type_impact = 0.5  # Linear layers less critical
    else:
        type_impact = 0.3  # Other layer types

    # Connection density impact
    connection_density = calculate_connection_density(model, layer_id)

    # Combined architecture impact
    architecture_impact = 0.4 * depth_impact + 0.4 * type_impact + 0.2 * connection_density

    return architecture_impact

def determine_layer_removal_safety(
    taylor_importance: float,
    gradient_flow: float,
    feature_similarity: float,
    skip_potential: float,
    architecture_impact: float,
    config: Dict[str, float]
) -> bool:
    """
    Make final safety determination for layer removal

    Conservative approach with multiple safety checks
    """
    # Individual thresholds
    taylor_threshold = config.get('taylor_threshold', 0.001)
    gradient_threshold = config.get('gradient_flow_threshold', 0.5)
    similarity_threshold = config.get('similarity_threshold', 0.8)
    skip_threshold = config.get('skip_potential_threshold', 0.7)
    impact_threshold = config.get('architecture_impact_threshold', 0.5)

    # All conditions must be met for safe removal
    safety_conditions = [
        taylor_importance < taylor_threshold,           # Low loss impact
        gradient_flow > gradient_threshold,             # Adequate gradient flow
        feature_similarity > similarity_threshold,      # Identity-like transformation
        skip_potential > skip_threshold,                # Skip connection feasible
        architecture_impact < impact_threshold          # Low architecture impact
    ]

    return all(safety_conditions)

def select_layers_for_removal(
    layer_importance: Dict[str, LayerImportance],
    max_removal_ratio: float = 0.2,
    min_layers_total: int = 3
) -> List[str]:
    """
    Conservative layer selection for removal

    Maximum 20% of layers, prioritizing safest removals
    """
    total_layers = len(layer_importance)

    # Conservative constraints
    max_to_remove = min(
        int(total_layers * max_removal_ratio),
        total_layers - min_layers_total
    )

    if max_to_remove <= 0:
        return []

    # Filter to only removable layers
    removable_layers = [
        (layer_id, importance) for layer_id, importance in layer_importance.items()
        if importance.can_remove
    ]

    if not removable_layers:
        return []

    # Sort by composite safety score (lower = safer to remove)
    def safety_score(importance):
        return (
            importance.taylor_importance * 0.3 +
            (1.0 - importance.feature_similarity) * 0.3 +
            (1.0 - importance.skip_potential) * 0.2 +
            importance.architecture_impact * 0.2
        )

    removable_layers.sort(key=lambda x: safety_score(x[1]))

    # Select safest layers for removal
    layers_to_remove = []
    for layer_id, _ in removable_layers:
        if len(layers_to_remove) >= max_to_remove:
            break
        layers_to_remove.append(layer_id)

    return layers_to_remove
```

## 4. Architecture Modification Implementation

### 4.1 Structured Model Surgery

```python
class StructuralModelSurgeon:
    """
    Safe structural modifications for neural network architectures

    Implements checkpoint-based model surgery with comprehensive rollback capability
    """

    def __init__(self, model: nn.Module):
        self.model = model
        self.original_state = copy.deepcopy(model.state_dict())
        self.modification_log = []
        self.rollback_checkpoints = []

    def apply_channel_pruning(
        self,
        layer_name: str,
        channels_to_remove: List[int],
        strategy: str = "zero_masking"
    ) -> bool:
        """
        Apply channel pruning with safety validation

        Strategies:
        - zero_masking: Zero out channels (preserves dimensions)
        - physical_removal: Actually remove channels (changes dimensions)
        - weight_redistribution: Redistribute weights to remaining channels
        """
        try:
            # Create rollback checkpoint
            self._create_rollback_checkpoint(f"before_channel_pruning_{layer_name}")

            # Get target layer
            layer = self._get_layer_by_name(layer_name)
            if not isinstance(layer, (nn.Conv2d, nn.Linear)):
                raise ValueError(f"Channel pruning not supported for {type(layer)}")

            if strategy == "zero_masking":
                success = self._apply_channel_zero_masking(layer, channels_to_remove)
            elif strategy == "physical_removal":
                success = self._apply_channel_physical_removal(layer_name, layer, channels_to_remove)
            elif strategy == "weight_redistribution":
                success = self._apply_channel_weight_redistribution(layer, channels_to_remove)
            else:
                raise ValueError(f"Unknown channel pruning strategy: {strategy}")

            if success:
                self.modification_log.append({
                    "type": "channel_pruning",
                    "layer": layer_name,
                    "channels_removed": channels_to_remove,
                    "strategy": strategy,
                    "timestamp": time.time()
                })

            return success

        except Exception as e:
            logger.error(f"Channel pruning failed for {layer_name}: {e}")
            self._rollback_last_checkpoint()
            return False

    def apply_attention_head_pruning(
        self,
        layer_name: str,
        heads_to_remove: List[int]
    ) -> bool:
        """
        Apply attention head pruning with dimension consistency
        """
        try:
            self._create_rollback_checkpoint(f"before_head_pruning_{layer_name}")

            layer = self._get_layer_by_name(layer_name)
            if not isinstance(layer, nn.MultiheadAttention):
                raise ValueError(f"Head pruning only supported for MultiheadAttention, got {type(layer)}")

            success = self._apply_head_physical_removal(layer, heads_to_remove)

            if success:
                self.modification_log.append({
                    "type": "head_pruning",
                    "layer": layer_name,
                    "heads_removed": heads_to_remove,
                    "new_num_heads": layer.num_heads,
                    "timestamp": time.time()
                })

            return success

        except Exception as e:
            logger.error(f"Head pruning failed for {layer_name}: {e}")
            self._rollback_last_checkpoint()
            return False

    def apply_layer_removal(
        self,
        layer_name: str,
        skip_strategy: str = "identity"
    ) -> bool:
        """
        Apply layer removal with skip connection establishment
        """
        try:
            self._create_rollback_checkpoint(f"before_layer_removal_{layer_name}")

            if skip_strategy == "identity":
                success = self._replace_layer_with_identity(layer_name)
            elif skip_strategy == "linear_projection":
                success = self._replace_layer_with_projection(layer_name, "linear")
            elif skip_strategy == "conv_projection":
                success = self._replace_layer_with_projection(layer_name, "conv")
            else:
                raise ValueError(f"Unknown skip strategy: {skip_strategy}")

            if success:
                self.modification_log.append({
                    "type": "layer_removal",
                    "layer": layer_name,
                    "skip_strategy": skip_strategy,
                    "timestamp": time.time()
                })

            return success

        except Exception as e:
            logger.error(f"Layer removal failed for {layer_name}: {e}")
            self._rollback_last_checkpoint()
            return False

    def _apply_channel_zero_masking(self, layer: nn.Module, channels_to_remove: List[int]) -> bool:
        """Zero out specified channels while preserving dimensions"""
        with torch.no_grad():
            if isinstance(layer, nn.Conv2d):
                # Zero out output channels
                layer.weight.data[channels_to_remove] = 0
                if layer.bias is not None:
                    layer.bias.data[channels_to_remove] = 0
            elif isinstance(layer, nn.Linear):
                # Zero out output features
                layer.weight.data[channels_to_remove] = 0
                if layer.bias is not None:
                    layer.bias.data[channels_to_remove] = 0
        return True

    def _apply_head_physical_removal(self, layer: nn.MultiheadAttention, heads_to_remove: List[int]) -> bool:
        """Physically remove attention heads and adjust dimensions"""
        num_heads = layer.num_heads
        head_dim = layer.embed_dim // num_heads

        # Create mask for heads to keep
        head_mask = torch.ones(num_heads, dtype=torch.bool)
        head_mask[heads_to_remove] = False
        new_num_heads = head_mask.sum().item()

        if new_num_heads == 0:
            return False  # Cannot remove all heads

        with torch.no_grad():
            # Reshape and filter projections
            if layer.in_proj_weight is not None:
                # Split Q, K, V projections
                w_q, w_k, w_v = layer.in_proj_weight.chunk(3, dim=0)

                # Reshape to heads: [num_heads, head_dim, embed_dim]
                w_q = w_q.view(num_heads, head_dim, layer.embed_dim)
                w_k = w_k.view(num_heads, head_dim, layer.embed_dim)
                w_v = w_v.view(num_heads, head_dim, layer.embed_dim)

                # Keep only non-pruned heads
                w_q = w_q[head_mask].reshape(-1, layer.embed_dim)
                w_k = w_k[head_mask].reshape(-1, layer.embed_dim)
                w_v = w_v[head_mask].reshape(-1, layer.embed_dim)

                # Update in_proj_weight
                layer.in_proj_weight.data = torch.cat([w_q, w_k, w_v], dim=0)

            # Update output projection
            out_weight = layer.out_proj.weight.view(layer.embed_dim, num_heads, head_dim)
            out_weight = out_weight[:, head_mask, :].reshape(layer.embed_dim, -1)
            layer.out_proj.weight.data = out_weight

            # Update num_heads
            layer.num_heads = new_num_heads

        return True
```

## 5. Safety Validation Framework

### 5.1 Progressive Validation Gates

```python
class StructuredPruningValidator:
    """
    Comprehensive safety validation for structured pruning operations

    Multi-level validation gates with progressive safety schedules
    """

    def __init__(self, config: Dict[str, float]):
        self.config = config
        self.validation_history = []

    def validate_pruning_safety(
        self,
        original_model: nn.Module,
        modified_model: nn.Module,
        test_loader: torch.utils.data.DataLoader,
        modification_type: str,
        safety_level: str = "conservative"
    ) -> ValidationResult:
        """
        Comprehensive safety validation for structured pruning modifications
        """
        validation_result = ValidationResult(modification_type=modification_type)

        # 1. Architecture integrity validation
        validation_result.architecture_valid = self._validate_architecture_integrity(
            original_model, modified_model
        )

        # 2. Forward pass validation
        validation_result.forward_pass_valid = self._validate_forward_pass(
            modified_model, test_loader
        )

        # 3. Gradient flow validation
        validation_result.gradient_flow_valid = self._validate_gradient_flow(
            modified_model, test_loader
        )

        # 4. Performance impact validation
        validation_result.performance_impact = self._validate_performance_impact(
            original_model, modified_model, test_loader
        )

        # 5. Safety level compliance
        validation_result.safety_compliant = self._check_safety_compliance(
            validation_result.performance_impact, modification_type, safety_level
        )

        # Overall validation decision
        validation_result.passed = all([
            validation_result.architecture_valid,
            validation_result.forward_pass_valid,
            validation_result.gradient_flow_valid,
            validation_result.safety_compliant
        ])

        self.validation_history.append(validation_result)
        return validation_result

    def _check_safety_compliance(
        self,
        performance_impact: Dict[str, float],
        modification_type: str,
        safety_level: str
    ) -> bool:
        """Check compliance with safety level thresholds"""

        # Safety thresholds by modification type and level
        thresholds = {
            "channel_pruning": {
                "conservative": {"accuracy_drop": 0.02, "loss_increase": 0.05},
                "moderate": {"accuracy_drop": 0.03, "loss_increase": 0.08},
                "aggressive": {"accuracy_drop": 0.05, "loss_increase": 0.12}
            },
            "head_pruning": {
                "conservative": {"accuracy_drop": 0.03, "loss_increase": 0.08},
                "moderate": {"accuracy_drop": 0.05, "loss_increase": 0.12},
                "aggressive": {"accuracy_drop": 0.08, "loss_increase": 0.15}
            },
            "layer_removal": {
                "conservative": {"accuracy_drop": 0.05, "loss_increase": 0.12},
                "moderate": {"accuracy_drop": 0.08, "loss_increase": 0.15},
                "aggressive": {"accuracy_drop": 0.12, "loss_increase": 0.20}
            }
        }

        threshold = thresholds.get(modification_type, thresholds["channel_pruning"])[safety_level]

        return (
            performance_impact["accuracy_drop"] <= threshold["accuracy_drop"] and
            performance_impact["loss_increase"] <= threshold["loss_increase"]
        )

@dataclass
class ValidationResult:
    """Comprehensive validation result for structured pruning"""
    modification_type: str = ""
    architecture_valid: bool = False
    forward_pass_valid: bool = False
    gradient_flow_valid: bool = False
    safety_compliant: bool = False
    passed: bool = False

    # Performance metrics
    performance_impact: Dict[str, float] = field(default_factory=dict)

    # Error details
    validation_errors: List[str] = field(default_factory=list)
    validation_warnings: List[str] = field(default_factory=list)

    # Rollback recommendation
    recommend_rollback: bool = False
    rollback_reason: str = ""
```

## Cross-References

- **Parent Document**: [13-elesh-unified-design.md] - Main Elesh architecture with structured pruning
- **Importance Tracking**: [13.1-elesh-importance-tracking.md] - Enhanced Count-Min Sketch implementation
- **Message Contracts**: [00-leyline-shared-contracts.md] - Structured pruning message specifications
- **Coordination**: [12-emrakul-unified-design.md] - Strategic coordinator for structured pruning
- **Safety Validation**: [07-urabrask-unified-design.md] - Enhanced safety validation with structured pruning gates

---

*Last Updated: 2025-01-14 | Version: 3.0 | Status: PRODUCTION READY*