# Finding Ticket: Variance Calculation Via Python Loop

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B1-PT-04` |
| **Severity** | `P3` |
| **Status** | `open` |
| **Batch** | 1 |
| **Agent** | `pytorch` |
| **Domain** | `tolaria` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/tolaria/governor.py` |
| **Line(s)** | `181-184` |
| **Function/Class** | `TolariaGovernor._detect_statistical_anomaly()` |

---

## Summary

**One-line summary:** Statistical anomaly detection calculates variance via Python loop instead of `statistics.pvariance()`.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [x] Code quality / maintainability

---

## Detailed Description

### What's Wrong

Same pattern as B1-PT-03 - variance computed via manual Python loop. Not a performance concern (history is max 20 items) but reduces clarity.

### Code Evidence

```python
# /home/john/esper-lite/src/esper/tolaria/governor.py:181-184

recent = list(self._loss_history)
avg = sum(recent) / len(recent)
variance = sum((x - avg) ** 2 for x in recent) / len(recent)
```

### Why This Matters

1. **Clarity:** `statistics.pvariance()` is more readable
2. **DRY:** Both `_detect_lobotomy` and `_detect_statistical_anomaly` use the same pattern
3. **Not Performance:** History is max 20 items

---

## Recommended Fix

### Suggested Code Change

```python
import statistics

# In _detect_statistical_anomaly():
recent = list(self._loss_history)
avg = statistics.mean(recent)
variance = statistics.pvariance(recent)
```

### Alternative: Extract Helper

```python
def _compute_loss_stats(self) -> tuple[float, float]:
    """Compute mean and variance of loss history."""
    recent = list(self._loss_history)
    return statistics.mean(recent), statistics.pvariance(recent)
```

---

## Verification

### How to Verify the Fix

- [ ] Unit test: Verify statistical anomaly detection behavior unchanged after refactor

---

## Related Findings

| Ticket ID | Relationship | Notes |
|-----------|--------------|-------|
| `B1-PT-03` | `related` | Same pattern in lobotomy detection |

---

## Cross-Review

| Agent | Verdict | Evaluation |
|-------|---------|------------|
| **DRL** | NEUTRAL | Same as B1-PT-03: manual variance on a 20-item deque has no RL implications whatsoever. Statistical anomaly detection correctness depends on threshold tuning vs loss scales, not whether statistics.pvariance() or a loop computes the variance. |
| **PyTorch** | NEUTRAL | Duplicate of B1-PT-03 pattern; same verdict applies. Refactoring to stdlib is a minor readability improvement with no PyTorch engineering relevance. Consider merging these two tickets into a single "use stdlib for statistics" cleanup task. |
| **CodeReview** | NEUTRAL | Valid DRY concern - two methods compute variance identically. The helper function suggestion (`_compute_loss_stats`) is the right fix if pursued. Should be addressed together with B1-PT-03 as a single refactoring task, but low priority given correctness is unaffected. |

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch1-pytorch.md`
**Section:** "File-by-File Analysis" - governor.py findings table - P3 Line 181-184
