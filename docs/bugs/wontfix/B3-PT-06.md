# Finding Ticket: Alpha Tensor Creation in Forward Path

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B3-PT-06` |
| **Severity** | `P2` |
| **Status** | `wont-fix` |
| **Batch** | 3 |
| **Agent** | `pytorch` |
| **Domain** | `kasmina` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/kasmina/slot.py` |
| **Line(s)** | `1975-1983` |
| **Function/Class** | `SeedSlot.forward()` |

---

## Summary

**One-line summary:** Alpha tensor cache invalidation creates new tensors during forward, potentially causing torch.compile recompilation.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [x] Performance bottleneck
- [ ] Numerical stability
- [x] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

The alpha tensor cache validation happens inside `forward()`. When cache is invalidated (device/dtype change), a new tensor is created, which could cause recompilation if it happens during graph tracing.

### Code Evidence

```python
# /home/john/esper-lite/src/esper/kasmina/slot.py:1975-1983

if (
    self._cached_alpha_tensor is None
    or self._cached_alpha_tensor.device != host_features.device
    or self._cached_alpha_tensor.dtype != host_features.dtype
):
    self._cached_alpha_tensor = torch.tensor(...)
```

### Why This Is Acceptable

The PERF comment on line 1974 acknowledges this. Cache invalidation only happens at:
- `set_alpha()` calls
- Device changes (`.to()`)

During steady-state forward passes, the cache is valid.

---

## Resolution

### Status: WONTFIX

**Closed via Systematic Debugging investigation.**

#### Evidence

| Claim | Status | Evidence |
|-------|--------|----------|
| "Cache validation in forward() at lines 1975-1983" | ⚠️ SHIFTED | Now at lines 2015-2023 |
| "PERF comment acknowledges this" | ✅ TRUE | Line 2007: `# PERF: Use persistent alpha tensor...` |
| "Creates new tensors on cache miss" | ✅ TRUE | Confirmed at line 2020 |
| "Steady-state forward passes are safe" | ✅ TRUE | Cache always valid during training |

#### Why This Is Acceptable Design

1. **Intentional torch.compile-friendly pattern**: Line 2012-2014 explains: "Cache alpha tensor for torch.compile-friendly blending. The cache is invalidated when alpha changes... no fill_() which breaks compile."

2. **Cache invalidation is isolated from forward path**:
   - `.to()` method (device transfers - before training)
   - `prune()` (epoch boundaries)
   - `set_alpha` property (stage advances)
   - Debug context manager (testing only)

3. **Steady-state training is safe**: During PPO rollout collection and gradient updates, cache is always valid. Alpha changes only at epoch boundaries, not mid-batch.

#### Severity Downgrade

- Original: P2 (performance/torch.compile risk)
- Revised: WONTFIX (intentional design, properly documented)
- Resolution: No action required - design is correct

---

## Verification

### How to Verify the Fix

- [ ] Confirm cache invalidation only occurs outside compiled forward passes
- [ ] Test torch.compile behavior when alpha changes mid-training

---

## Related Findings

- B3-CR-06: Scattered cache invalidation (related cache management concern)

---

## Cross-Review: DRL Specialist

| Verdict | **ENDORSE** |
|---------|-------------|

**Evaluation:** The alpha tensor cache invalidation is correctly isolated from training-time forward passes. During PPO rollout collection and gradient updates, alpha changes only at epoch boundaries (advance_stage) or via explicit set_alpha calls, not mid-batch. The cache-check-then-create pattern is compile-safe for steady-state training. The P2 severity is appropriate given the compile recompilation risk if misused.

## Cross-Review: PyTorch Specialist

| Verdict | **NEUTRAL** |
|---------|-------------|

**Evaluation:** The cache invalidation only triggers on device/dtype mismatch which is rare in steady-state; however, the PERF comment at line 1974 already acknowledges this concern. The real risk is that `set_alpha()` calls during training invalidate the cache inside forward context, which could cause recompilation. Consider guarding alpha changes to occur only outside compiled regions.

## Cross-Review: Code Review Specialist

| Verdict | **ENDORSE** |
|---------|-------------|

**Evaluation:** The finding is accurate and well-analyzed. The code at lines 1975-1983 does create new tensors on cache miss, but the PERF comment and cache invalidation strategy (set_alpha, device transfer) ensure this only happens during setup, not steady-state training. The ticket correctly concludes this is acceptable as-is.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch3-pytorch.md`
**Section:** "P2 - Performance"
