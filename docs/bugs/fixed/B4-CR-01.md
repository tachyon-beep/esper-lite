# Finding Ticket: Missing SET_ALPHA_TARGET Test Coverage

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B4-CR-01` |
| **Severity** | `P1` |
| **Status** | `closed` |
| **Batch** | 4 |
| **Agent** | `codereview` |
| **Domain** | `simic` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/tests/simic/test_advantages.py` |
| **Line(s)** | N/A (missing test) |
| **Function/Class** | Test coverage for `compute_per_head_advantages()` |

---

## Summary

**One-line summary:** Test file covers WAIT, GERMINATE, FOSSILIZE, PRUNE, ADVANCE but does NOT have a dedicated test for SET_ALPHA_TARGET operation.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [x] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

The SET_ALPHA_TARGET operation has unique causal masking requirements documented in advantages.py (lines 17-34):
- slot_mask: active
- style_mask: active
- alpha_target_mask: active
- alpha_speed_mask: active
- alpha_curve_mask: active
- blueprint_mask: masked (zero)
- tempo_mask: masked (zero)

While SET_ALPHA_TARGET is partially covered by `test_mixed_ops_correct_masking`, it deserves explicit verification of all mask states.

### Why This Matters

SET_ALPHA_TARGET is a key operation for controlling seed blending dynamics. Incorrect masking would cause:
- Gradient signal leaking to blueprint/tempo heads
- Missing gradient signal for alpha control heads
- Policy learning to adjust wrong action dimensions

---

## Recommended Fix

Add explicit test case:

```python
def test_set_alpha_target_correct_masking(self):
    """When op=SET_ALPHA_TARGET, slot/style/alpha heads should get advantage."""
    op_actions = torch.tensor([LifecycleOp.SET_ALPHA_TARGET])
    base_advantages = torch.tensor([2.0])

    per_head = compute_per_head_advantages(base_advantages, op_actions)

    assert torch.allclose(per_head["op"], base_advantages)
    assert torch.allclose(per_head["slot"], base_advantages)
    assert torch.allclose(per_head["style"], base_advantages)
    assert torch.allclose(per_head["alpha_target"], base_advantages)
    assert torch.allclose(per_head["alpha_speed"], base_advantages)
    assert torch.allclose(per_head["alpha_curve"], base_advantages)
    assert torch.allclose(per_head["blueprint"], torch.zeros(1))
    assert torch.allclose(per_head["tempo"], torch.zeros(1))
```

---

## Verification

### How to Verify the Fix

- [ ] Add dedicated test for SET_ALPHA_TARGET
- [ ] Verify all 8 head masks match documented causal structure
- [ ] Run `pytest tests/simic/test_advantages.py -v`

---

## Related Findings

None.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch4-codereview.md`
**Section:** "P1 (Correctness)" (ADV-1)

---

## Cross-Review (DRL Specialist)

| Verdict | Reviewer | Date |
|---------|----------|------|
| **ENDORSE** | DRL Agent | 2024-12-27 |

SET_ALPHA_TARGET is the only operation that activates both alpha schedule heads (speed/curve) AND style head simultaneously - this unique mask combination must be explicitly tested.
Without dedicated coverage, a regression in alpha control masking would silently corrupt policy gradients for dynamic blend rate adjustment, a critical training capability.

---

## Cross-Review (Code Review Specialist)

| Verdict | Reviewer | Date |
|---------|----------|------|
| **ENDORSE** | Code Review Specialist | 2024-12-27 |

Verified: `test_mixed_ops_correct_masking` does NOT include SET_ALPHA_TARGET in its test vector, contrary to ticket's partial coverage claim.
The proposed test correctly mirrors the style of existing tests and validates all 8 heads against the documented causal structure in advantages.py:20-25.

---

## Cross-Review (PyTorch Specialist)

| Verdict | Reviewer | Date |
|---------|----------|------|
| **ENDORSE** | PyTorch Agent | 2024-12-27 |

Valid test gap with torch.compile implications. SET_ALPHA_TARGET's unique mask combination (slot+style+alpha_*) differs from GERMINATE; missing coverage risks silent regression if mask logic changes.
Test is torch.compile-safe (no dynamic control flow in assertions, pure tensor ops in `compute_per_head_advantages`).

---

## Resolution

### Final Fix Description

Added `test_set_alpha_target_correct_masking()` to explicitly test the unique causal mask combination for SET_ALPHA_TARGET - the only operation that activates slot, style, and all three alpha heads (target/speed/curve) while masking blueprint and tempo.

### Files Changed

- `tests/simic/test_advantages.py` — Added new test method

### Test Added

```python
def test_set_alpha_target_correct_masking(self):
    """When op=SET_ALPHA_TARGET, slot/style/alpha heads get advantage (B4-CR-01)."""
    op_actions = torch.tensor([LifecycleOp.SET_ALPHA_TARGET])
    base_advantages = torch.tensor([2.0])

    per_head = compute_per_head_advantages(base_advantages, op_actions)

    # Active: op, slot, style, alpha_target, alpha_speed, alpha_curve
    # Masked: blueprint, tempo
```

### Verification

- [x] 12/12 advantages tests pass
- [x] Test validates all 8 heads against `leyline/causal_masks.py`
- [x] Test style matches existing operation tests

### Sign-Off

**Code Reviewer:** APPROVED — "The fix fully addresses B4-CR-01. The new test provides explicit coverage for SET_ALPHA_TARGET, correctly validates all 8 heads against documented causal structure, and follows project testing standards."
