# Finding Ticket: O(n_params) GPU Syncs in Debug NaN/Inf Check

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B7-PT-02` |
| **Severity** | `P2` |
| **Status** | `closed` |
| **Batch** | 7 |
| **Agent** | `pytorch` |
| **Domain** | `simic/telemetry` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/telemetry/debug_telemetry.py` |
| **Line(s)** | `196-208` |
| **Function/Class** | `check_numerical_stability()` |

---

## Summary

**One-line summary:** NaN/Inf checking triggers O(n_params) GPU synchronizations in debug mode.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [x] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
for name, param in model.named_parameters():
    if torch.isnan(param.data).any():  # GPU sync
        # ...
    if torch.isinf(param.data).any():  # GPU sync
        # ...
    if param.grad is not None:
        if torch.isnan(param.grad).any():  # GPU sync
            # ...
        if torch.isinf(param.grad).any():  # GPU sync
            # ...
```

Each `.any()` call triggers a GPU-CPU synchronization. For a model with 100 parameters:
- 4 syncs per parameter (nan/inf for weights and grads)
- 400 total sync points
- Each sync adds ~10-50μs latency
- Total: 4-20ms just for sync overhead

While documented as acceptable for debug mode, this could make debug telemetry prohibitively slow for large models.

---

## Recommended Fix

Batch the checks for a single sync point:

```python
def check_numerical_stability(model: nn.Module) -> NumericalStabilityReport:
    # Collect all tensors first
    all_tensors = []
    for name, param in model.named_parameters():
        all_tensors.append(param.data.view(-1))
        if param.grad is not None:
            all_tensors.append(param.grad.view(-1))

    # Single cat + check (1 sync instead of O(n))
    if all_tensors:
        combined = torch.cat(all_tensors)
        has_nan = torch.isnan(combined).any().item()
        has_inf = torch.isinf(combined).any().item()
    else:
        has_nan = has_inf = False
```

Trade-off: Higher memory (temporary tensor) but O(1) syncs.

---

## Verification

### How to Verify the Fix

- [ ] Implement batched check
- [ ] Profile before/after with 100+ parameter model
- [ ] Verify sync count reduced to constant

---

## Related Findings

- B7-PT-03: Same memory vs sync trade-off

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `REFINE` |
| **Reviewer** | DRL Specialist |

**Evaluation:** Valid issue, but proposed fix loses parameter-level granularity. Current code reports *which* parameters have NaN/Inf (valuable for RL debugging - value head vs policy encoder). Better alternative: batch per-device tensor views to reduce syncs while preserving diagnostics. Debug mode caveat is appropriate.

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `REFINE` |
| **Reviewer** | PyTorch Specialist |

**Evaluation:** Code comment acknowledges "acceptable for debug". Proposed fix trades O(n) sync for O(total_params) memory - same trade-off as B7-PT-03. Could be P3 if debug mode is called infrequently. Avoid creating large temporaries.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** Verified: 4 syncs per parameter × 100 params = 400 syncs. Comment acknowledges as "acceptable for debug" but for large models could be prohibitively slow. Valid P2 performance issue.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch7-codereview.md`
**Section:** "check_numerical_stability is O(N) GPU syncs"

**Report file:** `docs/temp/2712reports/batch7-pytorch.md`
**Section:** "O(n_params) GPU syncs for NaN/Inf check"

---

## Resolution

### Status: FIXED

**Fixed by batching NaN/Inf checks into a single GPU sync while preserving per-parameter diagnostics.**

#### The Fix

The key insight is that `torch.isnan().any()` returns a 0-dimensional tensor *without* triggering a GPU sync. The sync only happens when the tensor is evaluated in a Python boolean context (e.g., `if result:`). By collecting all `.any()` check tensors first, then stacking them and transferring to CPU in one operation, we reduce O(4n) syncs to O(1).

**Before (O(4n) syncs):**
```python
for name, param in model.named_parameters():
    if torch.isnan(param.data).any():  # GPU SYNC
        nan_weights.append(name)
    if torch.isinf(param.data).any():  # GPU SYNC
        ...
```

**After (O(1) syncs):**
```python
# Collect check tensors - NO SYNC YET
for name, param in model.named_parameters():
    nan_weight_checks.append(torch.isnan(param.data).any())
    inf_weight_checks.append(torch.isinf(param.data).any())
    ...

# SINGLE GPU SYNC: stack and transfer to CPU
all_checks = torch.stack([
    torch.stack(nan_weight_checks),
    torch.stack(inf_weight_checks),
    torch.stack(nan_grad_checks),
    torch.stack(inf_grad_checks),
]).cpu()

# Map back to parameter names (pure Python, no sync)
for i, name in enumerate(param_names):
    if all_checks[0, i]:
        nan_weights.append(name)
```

**Trade-offs:**
- Memory: Creates 4n 0-d tensors + one (4, n) tensor (~1.6KB for 100 params) - negligible
- Preserves per-parameter granularity (DRL specialist's requirement)
- Reduces sync overhead from 4-20ms to ~50μs for 100 param model

#### Severity Confirmation

- Original: P2 (performance)
- Confirmed: P2 (significant overhead in debug mode for large models)
- Resolution: FIXED
