# Finding Ticket: Large Tensor Allocation in collect_seed_gradients

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B7-PT-03` |
| **Severity** | `P2` |
| **Status** | `open` |
| **Batch** | 7 |
| **Agent** | `pytorch` |
| **Domain** | `simic/telemetry` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/telemetry/gradient_collector.py` |
| **Line(s)** | `299-303` |
| **Function/Class** | `collect_seed_gradients()` |

---

## Summary

**One-line summary:** O(total_params) temporary tensor allocation could spike VRAM on large models.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [x] Memory leak / resource issue
- [x] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
# Lines 299-303
all_grads_flat = torch.cat([g.view(-1) for g in grads])
```

This creates a single tensor containing ALL gradient elements. Memory impact:

| Model Size | Tensor Size (fp32) |
|-----------|-------------------|
| 10M params | 40MB |
| 100M params | 400MB |
| 1B params | 4GB |

The comment at lines 290-298 acknowledges this trade-off but doesn't implement the suggested per-param approach:

```python
# Comment: "For models with 100M+ params, this could spike VRAM"
# Suggestion: "compute per-param then sum"
```

---

## Recommended Fix

Implement per-parameter accumulation to avoid large temporary:

```python
def collect_seed_gradients(...):
    # ... existing grad collection ...

    # Compute stats without large temporary tensor
    nan_count = 0
    inf_count = 0
    total_elements = 0

    for g in grads:
        flat = g.view(-1)
        nan_count += torch.isnan(flat).sum().item()
        inf_count += torch.isinf(flat).sum().item()
        total_elements += flat.numel()

    # Peak memory: O(max_layer_params) instead of O(total_params)
```

---

## Verification

### How to Verify the Fix

- [ ] Implement per-parameter accumulation
- [ ] Profile with 100M+ param model
- [ ] Verify VRAM spike eliminated

---

## Related Findings

- B7-PT-02: Same memory vs sync trade-off

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | DRL Specialist |

**Evaluation:** Valid P2. Seed networks are typically small (10K-1M params) but pattern sets bad precedent. Gradient telemetry runs every PPO update - VRAM spikes could interfere with experience buffer. Code has self-aware comment acknowledging trade-off and suggesting fix. Zero ratio metric is critical for seed fossilization decisions.

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | PyTorch Specialist |

**Evaluation:** Valid P2. 100M params = 400MB temporary. CUDA fragmentation makes this worse - large contiguous allocation may fail even with free memory. Per-param fix must use vectorized ops to avoid torch.compile graph breaks.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** Verified code at lines 299-303. Comment at 290-298 literally describes the fix. Valid but documented trade-off for torch.compile compatibility. Per-param approach would eliminate spike but break graph compilation.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch7-pytorch.md`
**Section:** "O(total_params) memory allocation"

**Report file:** `docs/temp/2712reports/batch7-drl.md`
**Section:** "collect_seed_gradients allocates O(total_params) temp tensor"

**Report file:** `docs/temp/2712reports/batch7-codereview.md`
**Section:** "Large tensor allocation warning in comment"

### Memory Impact Analysis

```
Estimated VRAM overhead per call:

collect_seed_gradients (enhanced=True, 100M params):
  - all_grads_flat: ~400MB (fp32)
  - stat_tensors: ~80 bytes per layer
  - Peak: ~400MB temporary
```
