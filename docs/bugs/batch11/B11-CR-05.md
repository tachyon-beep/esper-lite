# Finding Ticket: Profiler Context Not Guaranteed to Close on Exceptions

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B11-CR-05` |
| **Severity** | `P2` |
| **Status** | `fixed` |
| **Batch** | 11 |
| **Agent** | `correctness` |
| **Domain** | `simic/training` |
| **Assignee** | |
| **Created** | 2026-01-01 |
| **Updated** | 2026-01-01 |
| **Fixed** | 2026-01-01 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/training/vectorized.py` |
| **Line(s)** | `1715-1726` (profiler setup), `3600` (original cleanup location) |
| **Function/Class** | `train_ppo_vectorized()` |

---

## Summary

**One-line summary:** The torch profiler context is opened via `__enter__()` but not protected by exception handling, leaving traces unflushed and resources leaked if training raises an exception before reaching the `__exit__()` call.

**Category:**
- [x] Correctness bug
- [ ] Race condition / concurrency
- [x] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

**Profiler context opened without exception safety:**

```python
# Line 1715-1726: Create and enter profiler context
profiler_cm = training_profiler(
    output_dir=torch_profiler_dir,
    enabled=torch_profiler,
    ...
)
prof = profiler_cm.__enter__()

# Lines 1728-3599: Training loop (NOT in try block)
history = []
# ... thousands of lines of training code ...

# Line 3600: Exit profiler (ONLY if no exception raised)
profiler_cm.__exit__(None, None, None)
```

**Problem:**
- ✅ Profiler entered at line 1726
- ❌ Training loop (lines 1728-3599) NOT protected by try/finally
- ❌ If any exception raised in training loop, `__exit__()` never called
- ❌ Profiler context left open, trace handler never flushes

**Example failure scenarios:**
```python
# Scenario 1: CUDA OOM during training
RuntimeError: CUDA out of memory
  → Training stops at line 2500
  → profiler_cm.__exit__() at line 3600 never reached
  → TensorBoard trace incomplete, resources leaked

# Scenario 2: NaN loss triggers ValueError
ValueError: NaN loss detected
  → Training stops at line 3000
  → Profiler context still open
  → Chrome trace file incomplete/corrupted

# Scenario 3: User KeyboardInterrupt
KeyboardInterrupt
  → Training stops anywhere
  → Profiler not flushed
  → No trace data written to disk
```

### Impact

**Consequences of unclosed profiler:**

1. **Incomplete traces**: TensorBoard profiling data missing or corrupted
2. **Resource leaks**: CUDA event handlers, file handles, memory buffers not released
3. **Silent failures**: No indication that profiling failed, user gets partial/empty traces
4. **Debugging pain**: Can't use profiler to diagnose the very issue that caused the exception

**Example:**
```python
# User enables profiling to debug training crash
train_ppo_vectorized(..., torch_profiler=True)

# Training crashes at epoch 50 with OOM
RuntimeError: CUDA out of memory at line 2500

# User checks TensorBoard → trace file is empty/incomplete
# Profiler was open but never flushed, debugging data lost
```

---

## Fix Applied

**Commit:** `[current commit]`

**Approach:** Wrap training loop in try/finally block to guarantee profiler cleanup

**Changes made:**

1. **Line 1728:** Added `try:` block after profiler entrance
2. **Lines 1728-3600:** Indented entire training loop inside try block
3. **Lines 3601-3608:** Added `finally:` block with profiler cleanup

```python
# BEFORE (vulnerable to exceptions):
prof = profiler_cm.__enter__()

history = []
# ... training loop ...

profiler_cm.__exit__(None, None, None)
if torch_profiler_summary and prof is not None:
    print(prof.key_averages().table(...))

# AFTER (exception-safe):
prof = profiler_cm.__enter__()

try:
    history = []
    # ... entire training loop ...

finally:
    # Ensure profiler context is always closed, even on exceptions
    profiler_cm.__exit__(None, None, None)
    if torch_profiler_summary and prof is not None:
        print(prof.key_averages().table(...))
```

**Execution flow after fix:**

**Normal execution:**
- Line 1726: Enter profiler (`prof = profiler_cm.__enter__()`)
- Line 1728: Enter try block
- Lines 1728-3600: Training loop executes normally
- Line 3601: Enter finally block
- Line 3603: Exit profiler (`profiler_cm.__exit__(None, None, None)`)
- Lines 3604-3608: Print profiler summary
- Line 3610 onwards: Best state restore, save, A/B test summary
- **Result: Profiler properly closed, traces flushed** ✅

**Exception during training:**
- Line 1726: Enter profiler
- Line 1728: Enter try block
- Lines 1728-3600: Training loop → exception raised at line 2500
- Python unwinds stack, **finally block guaranteed to execute**
- Line 3601: Enter finally block
- Line 3603: Exit profiler (`profiler_cm.__exit__(None, None, None)`)
- Lines 3604-3608: Print profiler summary (may skip if prof is None)
- Exception re-raised to caller
- **Result: Profiler properly closed despite exception** ✅

**Rationale:**
- **Exception safety**: `finally` block always executes, even on exceptions
- **Resource cleanup**: Profiler context properly closed in all cases
- **Complete traces**: Trace handler flushes data before function exits
- **No behavior change**: Normal execution path identical
- **Minimal change**: Only added try/finally wrapper, no logic changes

---

## Verification

### How to Verify the Fix

1. **Test normal execution:**
   ```python
   # Enable profiling, run normal training
   train_ppo_vectorized(..., torch_profiler=True)
   # Check TensorBoard trace is complete
   # Check profiler summary is printed
   ```

2. **Test exception handling:**
   ```python
   # Inject exception in training loop (e.g., force OOM)
   try:
       train_ppo_vectorized(..., torch_profiler=True)
   except RuntimeError:
       pass

   # Verify:
   # - Profiler summary printed before exception propagated
   # - Trace file written to disk (may be incomplete but flushed)
   # - No resource leak warnings
   ```

3. **Test KeyboardInterrupt:**
   ```python
   # Start training with profiling
   train_ppo_vectorized(..., torch_profiler=True)
   # Ctrl+C during training
   # Verify profiler cleanup ran (trace file written)
   ```

4. **Verify syntax:**
   ```bash
   python -m py_compile src/esper/simic/training/vectorized.py
   # Should compile without errors
   ```

---

## Root Cause Analysis

### How did this happen?

The profiler integration was added without considering exception safety:

1. **Original code:** No profiler, no cleanup needed
2. **Profiler added:** Manual `__enter__()` and `__exit__()` calls
3. **Mistake:** Didn't wrap training loop in try/finally to guarantee cleanup

**The oversight:**
- Focused on functionality ("does profiling work?")
- Didn't consider failure modes ("what if training crashes?")
- Didn't test exception paths

**Python context manager protocol:**
- `with` statement automatically handles exceptions via try/finally
- Manual `__enter__()` and `__exit__()` require explicit exception handling
- Without try/finally, cleanup only happens on normal exit

### Lesson learned

**When using context managers manually:**
1. Always wrap in try/finally to guarantee `__exit__()` is called
2. Or use `with` statement (handles exceptions automatically)
3. Test exception paths, not just happy path
4. Consider: "What if this code raises an exception?"

**Better pattern (if refactoring):**
```python
# Instead of manual __enter__/__exit__:
with training_profiler(...) as prof:
    # Training loop
    ...
# Automatically exception-safe
```

---

## Related Findings

None (first profiler bug discovered).

---

## Notes

- This bug affects all training runs with profiling enabled that encounter exceptions
- Severity P2 because it causes resource leaks and debugging data loss, but doesn't affect correctness of successful runs
- The fix is backwards compatible (no behavior change for normal execution)
- Consider refactoring to use `with` statement for cleaner code
