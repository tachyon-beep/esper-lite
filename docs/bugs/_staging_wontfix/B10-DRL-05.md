# Finding Ticket: Unused dropout Parameter in LSTMPolicyBundle

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B10-DRL-05` |
| **Severity** | `P3` |
| **Status** | `open` |
| **Batch** | 10 |
| **Agent** | `drl` |
| **Domain** | `tamiyo/policy` |
| **Assignee** | |
| **Created** | 2025-12-27 |
| **Updated** | 2025-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/tamiyo/policy/lstm_bundle.py` |
| **Line(s)** | `__init__` signature |
| **Function/Class** | `LSTMPolicyBundle.__init__()` |

---

## Summary

**One-line summary:** `dropout` parameter is documented as "currently unused by network" but still accepted.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [x] Dead code / unwired functionality
- [x] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

The `LSTMPolicyBundle.__init__()` accepts a `dropout` parameter that is documented as unused:

```python
def __init__(
    self,
    slot_config: SlotConfig,
    feature_dim: int | None = None,
    hidden_dim: int = 256,
    num_lstm_layers: int = 1,
    dropout: float = 0.0,  # Currently unused by network
    ...
)
```

This creates confusion:
1. Users might set dropout expecting it to work
2. The parameter is carried through but never applied
3. Future maintainers must research why it exists

### Impact

- **Low severity**: No functional impact
- **API confusion**: Users expect dropout to work
- **Dead code**: Parameter serves no purpose

---

## Recommended Fix

Options:

1. **Remove the parameter entirely** (per No Legacy Code Policy):
```python
def __init__(
    self,
    slot_config: SlotConfig,
    feature_dim: int | None = None,
    hidden_dim: int = 256,
    num_lstm_layers: int = 1,
    # dropout removed
    ...
)
```

2. **Implement dropout** if it was intended:
```python
# In network construction
self._network = FactoredRecurrentActorCritic(
    ...,
    dropout=dropout,  # Actually use it
)
```

Given that the parameter is explicitly noted as unused, option 1 is preferred unless there's a plan to implement it.

---

## Verification

### How to Verify the Fix

- [ ] Remove dropout parameter from __init__
- [ ] Update any call sites passing dropout
- [ ] Run tests to verify

---

## Related Findings

None.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch10-drl.md`
**Section:** LB-4
