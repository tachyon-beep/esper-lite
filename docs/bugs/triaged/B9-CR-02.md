# Finding Ticket: best_val_loss Name Misleading - Is Window-Best Not Global

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B9-CR-02` |
| **Severity** | `P2` |
| **Status** | `open` |
| **Batch** | 9 |
| **Agent** | `codereview` |
| **Domain** | `tamiyo/tracker` |
| **Assignee** | |
| **Created** | 2025-12-27 |
| **Updated** | 2025-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/tamiyo/tracker.py` |
| **Line(s)** | `186-187` |
| **Function/Class** | `SignalTracker.update()` / `SignalTracker.peek()` |

---

## Summary

**One-line summary:** Field `best_val_loss` suggests global best but is actually window-best (last N epochs).

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [x] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
# Lines 186-187
# NOTE: best_val_loss is "best in window" (last N epochs), not global best
best_val_loss=min(self._loss_history) if self._loss_history else float('inf'),
```

The field name `best_val_loss` in `TrainingMetrics` suggests it's the global best validation loss seen during training. However, it's actually the minimum loss within the sliding window (`_loss_history`).

The code has a comment explaining this, but:
1. The comment is in `tracker.py`, not in `TrainingMetrics` dataclass definition
2. Downstream consumers seeing `best_val_loss` won't know about the window semantics

### Impact

- **Semantic confusion**: Consumers may expect global best, get window best
- **Incorrect comparisons**: Using `best_val_loss` to compare across runs would be misleading
- **Decision errors**: If used for early stopping or checkpointing, could make wrong decisions

---

## Recommended Fix

Either:
1. Rename field to `window_best_val_loss` or `min_recent_val_loss`
2. Add true global `best_val_loss` field like exists for `best_val_accuracy`
3. Document semantics clearly in `TrainingMetrics` dataclass docstring

```python
# Option 1: Rename
@dataclass
class TrainingMetrics:
    window_best_val_loss: float  # Best in last N epochs, not global

# Option 2: Add both
@dataclass
class TrainingMetrics:
    best_val_loss: float  # Global best (all time)
    window_best_val_loss: float  # Best in last N epochs
```

---

## Verification

### How to Verify the Fix

- [ ] Rename field or add documentation in leyline TrainingMetrics
- [ ] Update all consumers to use correct semantics
- [ ] Add test verifying window vs global behavior

---

## Related Findings

- B9-DRL-02: Stabilization edge case (related tracker semantics)
- This finding appears in both CodeReview P2-A and DRL T3

---

## Appendix

### Original Report Reference

**Report files:**
- `docs/temp/2712reports/batch9-codereview.md` Section: P2-A
- `docs/temp/2712reports/batch9-drl.md` Section: T3
