# Finding Ticket: Different Epsilon Values Between Classes

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B5-PT-09` |
| **Severity** | `P4` |
| **Status** | `open` |
| **Batch** | 5 |
| **Agent** | `pytorch` |
| **Domain** | `simic/control` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/control/normalization.py` |
| **Line(s)** | `56, 217` |
| **Function/Class** | `RunningMeanStd`, `RewardNormalizer` |

---

## Summary

**One-line summary:** Different epsilon values (1e-4 vs 1e-8) between `RunningMeanStd` and `RewardNormalizer`.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [x] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
# RunningMeanStd
epsilon: float = 1e-4  # Default

# RewardNormalizer
self.epsilon = 1e-8  # Hardcoded
```

The different epsilon values could cause subtle differences in behavior for near-zero variances. While both are valid choices, the inconsistency is confusing.

---

## Recommended Fix

Either:

1. **Document the difference:**
```python
# RunningMeanStd uses 1e-4 for GPU numerical stability with float32
epsilon: float = 1e-4

# RewardNormalizer uses 1e-8 since it operates on Python floats (float64)
self.epsilon = 1e-8
```

2. **Unify to leyline constant:**
```python
from esper.leyline import NORMALIZATION_EPSILON
```

---

## Verification

### How to Verify the Fix

- [ ] Document rationale or unify constants
- [ ] No functional change needed

---

## Related Findings

- B5-DRL-05: Count initialization differences

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch5-pytorch.md`
**Section:** "P4 - Style/Minor" (epsilon values)

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `OBJECT` |
| **Reviewer** | PyTorch Specialist |
| **Date** | 2024-12-27 |

**Evaluation:** The ticket misses a critical distinction: `RunningMeanStd.epsilon` (1e-4) serves dual purposes -- it initializes `self.count = torch.tensor(epsilon, device=device)` (line 56) to provide Welford algorithm stability on the first batch AND guards division by variance. The 1e-8 in `RewardNormalizer` only guards the `max(self.epsilon, ...)` floor since count starts at 0. Unifying these would be incorrect; `RunningMeanStd` needs a larger epsilon because it seeds the count tensor for GPU numerical stability with float32, while `RewardNormalizer` operates on Python float64 where 1e-8 is appropriate. The current behavior is intentionally different. If anything, add a comment explaining why `RunningMeanStd` uses epsilon for count initialization.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** The finding is valid and the recommended documentation fix is appropriate. The PyTorch Specialist's objection strengthens the case for documentation: the dual-purpose nature of `RunningMeanStd.epsilon` (count initialization + division guard) vs single-purpose `RewardNormalizer.epsilon` (division guard only) is non-obvious and should be explicitly commented. Option 1 (inline documentation) is the correct fix; a unified leyline constant would be incorrect given the intentionally different values.

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | DRL Specialist |

**Evaluation:** The ticket correctly identifies a real inconsistency with practical implications for RL training. From a DRL perspective, `RunningMeanStd` (observation normalization) operates on GPU float32 tensors where 1e-4 prevents underflow in Welford's algorithm, while `RewardNormalizer` (reward scaling for critic stability) uses Python float64 where 1e-8 is appropriate. The PyTorch reviewer's OBJECT verdict adds important detail about dual-purpose count initialization, but documentation (option 1 in the ticket) remains the correct resolution. A leyline constant would be incorrect since these epsilons are intentionally different for valid numerical reasons in their respective RL contexts.
