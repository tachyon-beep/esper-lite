# Finding Ticket: Could Use statistics.mean() for Clarity

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B5-PT-08` |
| **Severity** | `P4` |
| **Status** | `open` |
| **Batch** | 5 |
| **Agent** | `pytorch` |
| **Domain** | `simic/attribution` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/attribution/counterfactual.py` |
| **Line(s)** | `139-143` |
| **Function/Class** | `CounterfactualMatrix` |

---

## Summary

**One-line summary:** Average computation uses `sum()/len()` instead of `statistics.mean()` for small lists.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [x] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
mean = sum(values) / len(values)
```

For small lists, this is fine. However, `statistics.mean()` provides:
- Clearer intent
- Automatic handling of edge cases (empty list raises StatisticsError)
- Potential NaN handling

---

## Recommended Fix

Consider using `statistics.mean()`:

```python
from statistics import mean as stats_mean

mean_value = stats_mean(values)
```

Or keep current code with a comment:

```python
# Simple mean for small lists (typically 20-100 Shapley samples)
mean = sum(values) / len(values)
```

---

## Verification

### How to Verify the Fix

- [ ] Optionally switch to statistics.mean()
- [ ] Or add clarifying comment
- [ ] No functional change needed

---

## Related Findings

None.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch5-pytorch.md`
**Section:** "P4 - Style/Minor" (ID 3)

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `OBJECT` |
| **Reviewer** | PyTorch Specialist |
| **Date** | 2024-12-27 |

**Evaluation:** Recommend closing as "won't fix". The `sum(values)/len(values)` pattern is idiomatic Python for numeric lists and avoids an unnecessary import. `statistics.mean()` provides no benefit here since: (1) empty list handling should be enforced at the caller level, not via exception from mean(), and (2) the Shapley computation already guarantees non-empty value lists. Adding `statistics.mean()` would be churn without value.

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `OBJECT` |
| **Reviewer** | DRL Specialist |

**Evaluation:** This ticket should be closed as "won't fix". In RL attribution code handling Shapley samples, `sum(values)/len(values)` is idiomatic, performant, and clear. The `statistics.mean()` function uses Kahan summation for numerical stability, which is unnecessary overhead for small lists of 20-100 float values where accumulated error is negligible. Additionally, empty list handling should raise explicitly in this context (a Shapley computation with zero samples is a bug), not be hidden behind StatisticsError. The current code is correct and appropriate for the domain.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `OBJECT` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** Switching to `statistics.mean()` would be an anti-improvement. The stdlib function raises `StatisticsError` on empty lists, but the code already guards this with `if values:` (L421). Additionally, `sum()/len()` is idiomatic Python that any developer understands immediately, while `statistics.mean()` adds an import for no functional benefit. The code also computes variance immediately after using the same pattern - consistency matters. Close as WONTFIX.
