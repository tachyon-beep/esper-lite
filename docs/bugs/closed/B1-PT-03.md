# Finding Ticket: Lobotomy Detection Uses Python Loop for History Average

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B1-PT-03` |
| **Severity** | `P3` |
| **Status** | `closed` |
| **Resolution** | `won't fix (low priority polish)` |
| **Batch** | 1 |
| **Agent** | `pytorch` |
| **Domain** | `tolaria` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/tolaria/governor.py` |
| **Line(s)** | `158-172` |
| **Function/Class** | `TolariaGovernor._detect_lobotomy()` |

---

## Summary

**One-line summary:** Lobotomy detection calculates history average using a Python loop instead of `statistics.mean()`.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [x] Code quality / maintainability

---

## Detailed Description

### What's Wrong

The code uses manual `sum() / len()` to compute averages. While functionally correct, this could be replaced with `statistics.mean()` for clarity and consistency.

### Code Evidence

```python
# /home/john/esper-lite/src/esper/tolaria/governor.py:158-172

def _detect_lobotomy(self, loss: float) -> bool:
    """Detect 'lobotomy' - model collapses to constant output."""
    self._loss_history.append(loss)
    if len(self._loss_history) < self.history_window:
        return False

    # Check if loss has stagnated (near-zero variance)
    recent = list(self._loss_history)
    avg = sum(recent) / len(recent)  # Could use statistics.mean()
    variance = sum((x - avg) ** 2 for x in recent) / len(recent)

    # Variance threshold scales with task tolerance
    variance_threshold = self.tolerance * 0.01
    return variance < variance_threshold
```

### Why This Matters

1. **Clarity:** `statistics.mean()` is more readable and self-documenting
2. **Correctness:** Standard library functions are well-tested
3. **Consistency:** Using stdlib makes intent clear
4. **Not Performance:** The history is max 20 items, so performance is not a concern

---

## Recommended Fix

### Suggested Code Change

```python
import statistics

def _detect_lobotomy(self, loss: float) -> bool:
    """Detect 'lobotomy' - model collapses to constant output."""
    self._loss_history.append(loss)
    if len(self._loss_history) < self.history_window:
        return False

    recent = list(self._loss_history)
    variance = statistics.pvariance(recent)  # Population variance

    variance_threshold = self.tolerance * 0.01
    return variance < variance_threshold
```

Note: `statistics.pvariance()` is population variance (divides by N), matching the current behavior. `statistics.variance()` uses sample variance (divides by N-1).

---

## Verification

### How to Verify the Fix

- [ ] Unit test: Verify lobotomy detection behavior unchanged after refactor
- [ ] Confirm `pvariance` (population) vs `variance` (sample) is correct choice

---

## Related Findings

| Ticket ID | Relationship | Notes |
|-----------|--------------|-------|
| `B1-PT-04` | `related` | Same pattern - variance calculation via Python loop |

---

## Cross-Review

| Agent | Verdict | Evaluation |
|-------|---------|------------|
| **DRL** | NEUTRAL | Using sum()/len() for 20-item variance is functionally correct and has zero impact on RL training dynamics, reward signals, or gradient flow. This is purely a code style preference; the lobotomy detection threshold and logic are what matter for training stability, not the averaging implementation. |
| **PyTorch** | NEUTRAL | Pure Python code quality issue with no PyTorch implications; sum()/len() on a 20-item deque has zero impact on torch.compile, CUDA operations, or tensor correctness. Using statistics.pvariance() is marginally cleaner but functionally equivalent for this non-hot path. |
| **CodeReview** | NEUTRAL | The finding is technically valid - `statistics.pvariance()` is cleaner than manual calculation - but the impact is minimal for a 20-item history window. Given this is P3 priority and the code is correct, this is a low-priority polish item that could be bundled with B1-PT-04 if addressed. |

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch1-pytorch.md`
**Section:** "File-by-File Analysis" - governor.py findings table - P3 Line 158-172

---

## Closure Notes

**Closed:** 2024-12-28

**Actual locations:** Lines 192-194 in `check_vital_signs()` and lines 255-257 in `execute_rollback()`. Original ticket referenced phantom `_detect_lobotomy()` method that doesn't exist.

**Resolution rationale:**
- All three cross-reviews NEUTRAL - no significant value in change
- Code is functionally correct; `statistics.pvariance()` would be stylistic preference only
- 20-item history makes performance difference unmeasurable
- Not worth the churn for P3 polish
