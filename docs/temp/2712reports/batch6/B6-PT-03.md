# Finding Ticket: Undocumented Magic Number 0.5 in Synergy Bonus

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B6-PT-03` |
| **Severity** | `P3` |
| **Status** | `open` |
| **Batch** | 6 |
| **Agent** | `pytorch` |
| **Domain** | `simic/rewards` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/rewards/rewards.py` |
| **Line(s)** | `1232` |
| **Function/Class** | `_compute_synergy_bonus()` |

---

## Summary

**One-line summary:** Magic number 0.5 in synergy bonus calculation is undocumented.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [x] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

```python
raw_bonus = math.tanh(interaction_sum * 0.5)  # Why 0.5?
```

The `0.5` scaling factor is undocumented. Unlike `compute_scaffold_hindsight_credit` which documents its 0.1 factor ("The 0.1 scaling factor controls tanh saturation"), this magic number has no explanation.

For context:
- `tanh(0.5) = 0.46` (46% of max)
- `tanh(1.0) = 0.76` (76% of max)
- `tanh(2.0) = 0.96` (96% of max)

So with 0.5 scaling, `interaction_sum=4.0` is needed to reach 96% saturation.

---

## Recommended Fix

Either extract to constant or add inline documentation:

**Option 1 - Named constant:**
```python
SYNERGY_TANH_SCALE = 0.5  # Scales saturation: interaction_sum=4 -> 96% of max bonus

raw_bonus = math.tanh(interaction_sum * SYNERGY_TANH_SCALE)
```

**Option 2 - Inline documentation:**
```python
# 0.5 scaling: interaction_sum=4.0 reaches 96% saturation
# Calibrated to typical seed interaction magnitudes
raw_bonus = math.tanh(interaction_sum * 0.5)
```

---

## Verification

### How to Verify the Fix

- [ ] Document the 0.5 scaling factor
- [ ] No functional change

---

## Related Findings

- B6-CR-04: Magic number 700.0 also undocumented

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch6-pytorch.md`
**Section:** "P3-1: Magic Number in _compute_synergy_bonus"

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | PyTorch Specialist |
| **Date** | 2024-12-27 |

**Evaluation:** The 0.5 tanh scaling factor affects reward magnitude, which has indirect implications for gradient scales during backprop through the value/policy networks. Undocumented scaling factors make hyperparameter tuning difficult - if someone adjusts the synergy weight without understanding the tanh saturation curve, they may get unexpected training dynamics. Extracting to a named constant with documented rationale is the right approach.

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | DRL Specialist |

**Evaluation:** The tanh scaling factor directly controls the saturation curve of the synergy bonus, which affects credit assignment for multi-seed interactions. Undocumented magic numbers in reward shaping are a common source of reproducibility issues and make hyperparameter sensitivity analysis impossible. The 0.5 scaling means interaction_sum must reach 4.0 for near-saturation; if typical values are much lower/higher, the bonus may be effectively constant or always saturated. Document the calibration rationale to enable future tuning.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** Valid documentation issue. The ticket correctly notes that `compute_scaffold_hindsight_credit` documents its 0.1 scaling factor but `_compute_synergy_bonus` does not explain the 0.5 scaling. For a rewards module where tuning parameters significantly affect learning dynamics, undocumented magic numbers are a maintenance hazard. Option 1 (named constant in leyline) is preferred per project conventions.
