# Finding Ticket: torch._dynamo.disable Uses Private API

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B3-PT-03` |
| **Severity** | `P1` |
| **Status** | `open` |
| **Batch** | 3 |
| **Agent** | `pytorch` |
| **Domain** | `kasmina` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/kasmina/blueprints/transformer.py` |
| **Line(s)** | `245` |
| **Function/Class** | `_get_causal_block_mask()` |

---

## Summary

**One-line summary:** Uses private `@torch._dynamo.disable` decorator instead of public `@torch.compiler.disable`.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [x] torch.compile compatibility
- [ ] Dead code / unwired functionality
- [x] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [ ] Legacy code policy violation

---

## Detailed Description

### What's Wrong

The block mask cache function uses `@torch._dynamo.disable` which is a private API (underscore prefix). PyTorch 2.9+ provides the public `@torch.compiler.disable` decorator.

### Code Evidence

```python
# /home/john/esper-lite/src/esper/kasmina/blueprints/transformer.py:245

@torch._dynamo.disable
def _get_causal_block_mask(self, seq_len: int) -> BlockMask:
    ...
```

### Why This Matters

- Private APIs may change without deprecation warnings
- Using public APIs ensures forward compatibility with PyTorch updates

---

## Recommended Fix

```python
# PyTorch 2.9+ compatible
@torch.compiler.disable
def _get_causal_block_mask(self, seq_len: int) -> BlockMask:
    ...
```

---

## Verification

### How to Verify the Fix

- [ ] Verify `torch.compiler.disable` is available in target PyTorch version
- [ ] Run existing tests to ensure cache behavior unchanged
- [ ] Verify no graph breaks in surrounding code

---

## Related Findings

- B3-DRL-13: torch._foreach_norm private API (similar private API concern)

---

## Cross-Review

| Reviewer | Verdict | Date |
|----------|---------|------|
| Code Review Agent | **ENDORSE** | 2024-12-27 |
| DRL Specialist | **NEUTRAL** | 2024-12-27 |
| PyTorch Expert | **ENDORSE** | 2024-12-27 |

**Code Review Evaluation:** Valid finding. Using `torch._dynamo.disable` relies on a private API that may break without notice; `torch.compiler.disable` is the stable public equivalent. Simple one-line fix with clear maintainability benefit.

**DRL Evaluation:** No direct DRL training impact; this is a forward-compatibility hygiene issue. The private API functions identically today. However, given PyTorch's rapid evolution and the project's dependency on torch.compile for performance, migrating to the public API is prudent maintenance to prevent future silent breakage during upgrades.

**PyTorch Expert Evaluation:** Confirmed. `torch.compiler.disable` is the public API since PyTorch 2.1 and remains stable through 2.9. The private `torch._dynamo.disable` may be removed or have signature changes without deprecation warning. One-line mechanical fix with identical runtime semantics.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch3-pytorch.md`
**Section:** "P1 - Correctness"
