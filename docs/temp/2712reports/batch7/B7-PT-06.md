# Finding Ticket: training_profiler Not Integrated

---

## Ticket Metadata

| Field | Value |
|-------|-------|
| **Ticket ID** | `B7-PT-06` |
| **Severity** | `P2` |
| **Status** | `open` |
| **Batch** | 7 |
| **Agent** | `pytorch` |
| **Domain** | `simic/telemetry` |
| **Assignee** | |
| **Created** | 2024-12-27 |
| **Updated** | 2024-12-27 |

---

## Location

| Field | Value |
|-------|-------|
| **File(s)** | `/home/john/esper-lite/src/esper/simic/telemetry/profiler.py` |
| **Line(s)** | All |
| **Function/Class** | `training_profiler()` |

---

## Summary

**One-line summary:** Profiler context manager is exported but never used in training loop.

**Category:**
- [ ] Correctness bug
- [ ] Race condition / concurrency
- [ ] Memory leak / resource issue
- [ ] Performance bottleneck
- [ ] Numerical stability
- [ ] torch.compile compatibility
- [x] Dead code / unwired functionality
- [ ] API design / contract violation
- [ ] Test coverage gap
- [ ] Documentation / naming
- [ ] Defensive programming violation
- [x] Legacy code policy violation

---

## Detailed Description

### What's Wrong

`training_profiler()` is:
1. Exported in `__init__.py` (line 56)
2. Has docstring with example usage
3. Is never called from the training loop
4. Grep confirms no usage:

```bash
grep -r "training_profiler" src/esper/simic/ --include="*.py" | grep -v "__init__\|profiler.py"
# No results
```

The profiler provides:
- torch.profiler integration
- TensorBoard trace export
- CUDA activity tracking

Without integration, there's no way to profile training bottlenecks.

---

## Recommended Fix

**Option 1 - Add CLI flag:**
```python
# In train.py CLI:
@click.option("--profile", is_flag=True, help="Enable torch.profiler")

# In vectorized.py:
if profile_enabled:
    with training_profiler(enabled=True):
        ppo_update(...)
```

**Option 2 - Document as manual tool:**
Add to README that users can wrap training manually:
```python
from esper.simic.telemetry import training_profiler

with training_profiler(enabled=True, output_dir="./traces"):
    train_loop()
```

---

## Verification

### How to Verify the Fix

- [ ] Either wire into training loop OR document as manual tool
- [ ] Test profiler generates TensorBoard traces
- [ ] Verify CUDA activities captured

---

## Related Findings

- B7-DRL-01: GradientEMATracker also never used
- B7-DRL-02: check_performance_degradation() also unwired

---

## Cross-Review (DRL Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `OBJECT` |
| **Reviewer** | DRL Specialist |

**Evaluation:** This misapplies the No Legacy Code Policy. `training_profiler` is intentionally opt-in tooling, not legacy code. Profiling overhead shouldn't be added to every run. Manual invocation is the correct pattern. If anything, add `--profile` CLI flag (P4), but do NOT treat as dead code.

---

## Cross-Review (PyTorch Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `REFINE` |
| **Reviewer** | PyTorch Specialist |

**Evaluation:** Not dead code - intentionally optional. Automatic profiling adds overhead to every run. Current design (reusable context manager) is correct PyTorch practice. This is a documentation gap, not legacy code. **Downgrade to P3** - add README example showing manual usage.

---

## Cross-Review (Code Review Specialist)

| Field | Value |
|-------|-------|
| **Verdict** | `ENDORSE` |
| **Reviewer** | Code Review Specialist |

**Evaluation:** Valid - profiler is exported but never called. However, profilers are typically opt-in. Implementation is well-designed (context manager, CUDA detection, TensorBoard output). Suggested fix: document in README or add `--profile` CLI flag. Not "broken" - just not advertised.

---

## Appendix

### Original Report Reference

**Report file:** `docs/temp/2712reports/batch7-pytorch.md`
**Section:** "Profiler not integrated into training loop"

**Report file:** `docs/temp/2712reports/batch7-drl.md`
**Section:** "Missing tests for training_profiler"
